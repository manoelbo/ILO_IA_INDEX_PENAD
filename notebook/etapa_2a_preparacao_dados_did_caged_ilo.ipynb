{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ac33147",
   "metadata": {},
   "source": [
    "# ETAPA 2a — Preparação do Painel CAGED + ILO Exposure Index\n",
    "\n",
    "**Dissertação:** Inteligência Artificial Generativa e o Mercado de Trabalho Brasileiro: Uma Análise de Exposição Ocupacional e seus Efeitos Distributivos.\n",
    "\n",
    "**Aluno:** Manoel Brasil Orlandi\n",
    "\n",
    "---\n",
    "\n",
    "### Contextualização\n",
    "\n",
    "A rápida difusão de modelos de IA generativa (LLMs, geradores de imagem/código) levanta questões centrais sobre seus impactos no mercado de trabalho. Para mensurar esse potencial de impacto, a Organização Internacional do Trabalho (OIT) criou um índice de exposição ocupacional à IA generativa, publicado como *Working Paper* 140 (WP140). O índice atribui scores de exposição a cada ocupação da classificação ISCO-08, com base na avaliação de suas tarefas constituintes por modelos de linguagem e validação humana.\n",
    "\n",
    "Este notebook prepara uma base de dados que junta os dados do **Novo CAGED** (Cadastro Geral de Empregados e Desempregados) ao **índice de exposição à IA generativa da OIT**, para ser usado em um modelo de Diferenças-em-Diferenças (DiD) no Notebook 2b.\n",
    "\n",
    "### Objetivo\n",
    "\n",
    "Construir o **painel mensal de ocupações formais brasileiras (2021–2025)** a partir do Novo CAGED, realizar o **crosswalk CBO 2002 → ISCO-08** (especificação dual: 2 dígitos como principal, 4 dígitos para robustez), e fazer o merge com o índice de exposição à IA generativa da OIT (Gmyrek, Berg & Cappelli, 2025). O output final é um dataset analítico pronto para a estimação DiD.\n",
    "\n",
    "**Estratégia de crosswalk:** Análise principal a **2 dígitos** ISCO-08 (match por Sub-major Group com fallback hierárquico a Major Group), com robustez a **4 dígitos** via correspondência ISCO-88 ↔ ISCO-08 + fallback hierárquico em 6 níveis.\n",
    "\n",
    "**Inspiração metodológica:** Hui, Reshef & Zhou (2024), \"The Short-Term Effects of Generative Artificial Intelligence on Employment: Evidence from an Online Labor Market\" — adaptado para dados administrativos brasileiros (CAGED) com o índice ILO de exposição ocupacional.\n",
    "\n",
    "### Ficha Técnica dos Dados\n",
    "\n",
    "| Item | Descrição |\n",
    "|------|-----------|\n",
    "| **Fonte CAGED** | Ministério do Trabalho e Emprego (MTE), via Base dos Dados (BigQuery) |\n",
    "| **Dataset BigQuery** | `basedosdados.br_me_caged.microdados_movimentacao` |\n",
    "| **Período** | Janeiro/2021 — Dezembro/2025 (60 meses) |\n",
    "| **Unidade** | Movimentação individual (admissão ou desligamento) |\n",
    "| **Cobertura** | Emprego formal (CLT) em todo o Brasil |\n",
    "| **Índice ILO** | `ilo_exposure_clean.csv` — 427 ocupações ISCO-08 com exposure scores |\n",
    "| **Classificação** | CBO 2002 (CAGED) → ISCO-08 (ILO) via crosswalk hierárquico |\n",
    "\n",
    "### Referências principais\n",
    "- Gmyrek, P., Berg, J. & Cappelli, D. (2025). *Generative AI and Jobs: An updated global assessment*. ILO Working Paper 140.\n",
    "- Hui, X., Reshef, O. & Zhou, L. (2024). *The Short-Term Effects of Generative AI on Employment*. Organization Science, 35(6).\n",
    "- Brynjolfsson, E., Chandar, P. & Chen, J. (2025). *Canaries in the Coal Mine? Six Facts about the Recent Employment Effects of AI*.\n",
    "- Callaway, B. & Sant'Anna, P. (2021). *Difference-in-differences with multiple time periods*. Journal of Econometrics, 225(2).\n",
    "- Muendler, M.-A. & Poole, J.P. (2004). *Job Concordances for Brazil: Mapping CBO to ISCO-88*. UC San Diego.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893a125d",
   "metadata": {},
   "source": [
    "### 1. Configuração do ambiente\n",
    "\n",
    "Definir caminhos, importar bibliotecas e configurar parâmetros do painel. Todos os caminhos são relativos ao diretório `notebook/`.\n",
    "\n",
    "> **Nota sobre a janela temporal:** Excluímos 2020 para evitar os efeitos distorcivos da pandemia de COVID-19 sobre o mercado de trabalho formal. O ano de 2020 apresentou quedas e recuperações atípicas que contaminariam o período pré-tratamento do DiD. A janela Jan/2021–Dez/2025 oferece 23 meses pré-ChatGPT e 31 meses pós.\n",
    "\n",
    "> **Nota sobre o Novo CAGED:** A partir de janeiro/2020, o CAGED foi substituído pelo sistema eSocial (Portaria SEPRT 1.127/2019). Usamos dados de 2021+ para consistência metodológica (eSocial já estabilizado)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "02d36db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuração carregada.\n",
      "  Período: 2021–2025 (60 meses)\n",
      "  Evento: ChatGPT — Nov/2022 (pós a partir de 12/2022)\n",
      "  Projeto GCP: mestrado-pnad-2026\n",
      "  ILO file: data/processed/ilo_exposure_clean.csv (existe: True)\n"
     ]
    }
   ],
   "source": [
    "# Etapa 2a.1 — Configuração do ambiente\n",
    "\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Caminhos (relativos ao diretório do notebook)\n",
    "# ---------------------------------------------------------------------------\n",
    "DATA_INPUT     = Path(\"data/input\")\n",
    "DATA_RAW       = Path(\"data/raw\")\n",
    "DATA_PROCESSED = Path(\"data/processed\")\n",
    "DATA_OUTPUT    = Path(\"data/output\")\n",
    "\n",
    "for d in [DATA_INPUT, DATA_RAW, DATA_PROCESSED, DATA_OUTPUT]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Parâmetros do Painel CAGED\n",
    "# ---------------------------------------------------------------------------\n",
    "GCP_PROJECT_ID = \"mestrado-pnad-2026\"\n",
    "\n",
    "ANO_INICIO     = 2021\n",
    "ANO_FIM        = 2025\n",
    "ANO_TRATAMENTO = 2022\n",
    "MES_TRATAMENTO = 12   # Dezembro/2022 como primeiro mês \"pós\"\n",
    "\n",
    "SALARIO_MINIMO = {\n",
    "    2021: 1100, 2022: 1212, 2023: 1320, 2024: 1412, 2025: 1518\n",
    "}\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Colunas a selecionar do CAGED (BigQuery)\n",
    "# ---------------------------------------------------------------------------\n",
    "COLUNAS_CAGED = \"\"\"\n",
    "    ano, mes, sigla_uf, id_municipio, cbo_2002,\n",
    "    categoria, tipo_movimentacao, saldo_movimentacao,\n",
    "    salario_mensal, grau_instrucao, idade, sexo, raca_cor,\n",
    "    cnae_2_secao, cnae_2_subclasse, tamanho_estabelecimento_janeiro\n",
    "\"\"\"\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Arquivos de referência\n",
    "# ---------------------------------------------------------------------------\n",
    "ILO_FILE               = DATA_PROCESSED / \"ilo_exposure_clean.csv\"\n",
    "ISCO_08_88_FILE        = DATA_INPUT / \"Correspondência ISCO 08 a 88.xlsx\"\n",
    "ISCO_08_ESTRUTURA_FILE = DATA_INPUT / \"ISCO 08 Estruturas e Definições.xlsx\"\n",
    "MUENDLER_FILE          = DATA_INPUT / \"cbo-isco-conc.csv\"\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Checkpoints intermediários\n",
    "# ---------------------------------------------------------------------------\n",
    "PAINEL_MENSAL_FILE     = DATA_PROCESSED / \"painel_caged_mensal.parquet\"\n",
    "PAINEL_CROSSWALK_FILE  = DATA_PROCESSED / \"painel_caged_crosswalk.parquet\"\n",
    "PAINEL_TRATAMENTO_FILE = DATA_PROCESSED / \"painel_caged_tratamento.parquet\"\n",
    "PAINEL_FINAL_PARQUET   = DATA_OUTPUT / \"painel_caged_did_ready.parquet\"\n",
    "PAINEL_FINAL_CSV       = DATA_OUTPUT / \"painel_caged_did_ready.csv\"\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Grandes grupos CBO (para sanity checks)\n",
    "# ---------------------------------------------------------------------------\n",
    "GRANDES_GRUPOS_CBO = {\n",
    "    '0': 'Forças Armadas',\n",
    "    '1': 'Dirigentes',\n",
    "    '2': 'Profissionais das ciências',\n",
    "    '3': 'Técnicos nível médio',\n",
    "    '4': 'Trabalhadores de serv. admin.',\n",
    "    '5': 'Trabalhadores de serviços/comércio',\n",
    "    '6': 'Agropecuária',\n",
    "    '7': 'Produção industrial',\n",
    "    '8': 'Operadores de máquinas',\n",
    "    '9': 'Manutenção e reparação',\n",
    "}\n",
    "\n",
    "print(\"Configuração carregada.\")\n",
    "print(f\"  Período: {ANO_INICIO}–{ANO_FIM} ({(ANO_FIM - ANO_INICIO + 1) * 12} meses)\")\n",
    "print(f\"  Evento: ChatGPT — Nov/2022 (pós a partir de {MES_TRATAMENTO}/{ANO_TRATAMENTO})\")\n",
    "print(f\"  Projeto GCP: {GCP_PROJECT_ID}\")\n",
    "print(f\"  ILO file: {ILO_FILE} (existe: {ILO_FILE.exists()})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd90657e",
   "metadata": {},
   "source": [
    "### 2a. Download dos microdados CAGED\n",
    "\n",
    "Extrair do Novo CAGED (BigQuery/Base dos Dados) todas as movimentações de emprego formal no período 2021–2025.\n",
    "\n",
    "| Item | Descrição |\n",
    "|------|-----------|\n",
    "| **Tabela BigQuery** | `basedosdados.br_me_caged.microdados_movimentacao` |\n",
    "| **Período** | 2021-01 a 2025-12 |\n",
    "| **Filtros** | `ano BETWEEN 2021 AND 2025` |\n",
    "| **Volume estimado** | ~20-30M de registros por ano, ~100-150M total |\n",
    "| **Estratégia** | Download ano a ano via `google-cloud-bigquery` (Storage API) com fallback para `basedosdados` |\n",
    "\n",
    "> **Nota metodológica — Volume de dados:** O CAGED registra ~20-25 milhões de movimentações/ano. Para 5 anos, esperamos ~100-125M de registros. O download é feito ano a ano para evitar OOM e timeout, com salvamento em parquets individuais (`caged_{ano}.parquet`).\n",
    "\n",
    "> **Nota sobre otimização:** Usamos a BigQuery Storage API (`create_bqstorage_client=True`) que transfere dados via gRPC/Arrow, sendo 2-5x mais rápida que o método padrão REST. Se o arquivo parquet já existir, o download é pulado automaticamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "451ca3b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download dos microdados CAGED:\n",
      "  2021: Baixando do BigQuery... 36,554,795 registros (380 MB)\n",
      "  2022: Baixando do BigQuery... 42,475,516 registros (440 MB)\n",
      "  2023: Baixando do BigQuery... 44,485,982 registros (469 MB)\n",
      "  2024: Baixando do BigQuery... 48,996,040 registros (511 MB)\n",
      "  2025: Baixando do BigQuery... 26,312,103 registros (269 MB)\n",
      "\n",
      "Total: 198,824,436 movimentações (2021–2025)\n",
      "Colunas: ['ano', 'mes', 'sigla_uf', 'id_municipio', 'cbo_2002', 'categoria', 'tipo_movimentacao', 'saldo_movimentacao', 'salario_mensal', 'grau_instrucao', 'idade', 'sexo', 'raca_cor', 'cnae_2_secao', 'cnae_2_subclasse', 'tamanho_estabelecimento_janeiro']\n"
     ]
    }
   ],
   "source": [
    "# Etapa 2a.2a — Download dos microdados CAGED\n",
    "# Estratégia: download ano a ano via BigQuery Storage API, com cache local em parquet.\n",
    "\n",
    "from google.cloud import bigquery\n",
    "\n",
    "def download_caged_ano(ano):\n",
    "    \"\"\"Baixar microdados CAGED de um ano via BigQuery Storage API.\"\"\"\n",
    "    parquet_path = DATA_RAW / f\"caged_{ano}.parquet\"\n",
    "\n",
    "    if parquet_path.exists():\n",
    "        size_mb = parquet_path.stat().st_size / 1e6\n",
    "        df = pd.read_parquet(parquet_path)\n",
    "        print(f\"  {ano}: Carregado do cache — {len(df):,} registros ({size_mb:.0f} MB)\")\n",
    "        return df\n",
    "\n",
    "    print(f\"  {ano}: Baixando do BigQuery...\", end=\"\", flush=True)\n",
    "    query = f\"\"\"\n",
    "    SELECT {COLUNAS_CAGED}\n",
    "    FROM `basedosdados.br_me_caged.microdados_movimentacao`\n",
    "    WHERE ano = {ano}\n",
    "    \"\"\"\n",
    "    client = bigquery.Client(project=GCP_PROJECT_ID)\n",
    "    df = client.query(query).to_dataframe(create_bqstorage_client=True)\n",
    "    df.to_parquet(parquet_path, index=False)\n",
    "    size_mb = parquet_path.stat().st_size / 1e6\n",
    "    print(f\" {len(df):,} registros ({size_mb:.0f} MB)\")\n",
    "    return df\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Download ano a ano\n",
    "# ---------------------------------------------------------------------------\n",
    "print(\"Download dos microdados CAGED:\")\n",
    "dfs_anuais = []\n",
    "for ano in range(ANO_INICIO, ANO_FIM + 1):\n",
    "    df_ano = download_caged_ano(ano)\n",
    "    dfs_anuais.append(df_ano)\n",
    "\n",
    "# Resumo (sem concatenar em memória para evitar OOM)\n",
    "total = sum(len(df) for df in dfs_anuais)\n",
    "print(f\"\\nTotal: {total:,} movimentações ({ANO_INICIO}–{ANO_FIM})\")\n",
    "print(f\"Colunas: {list(dfs_anuais[0].columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e45e2f",
   "metadata": {},
   "source": [
    "### 2b. Verificar dados CAGED (CHECKPOINT)\n",
    "\n",
    "Verificar integridade dos dados baixados: cobertura temporal (12 meses/ano), volume por ano, preenchimento de variáveis-chave, e formato dos códigos CBO.\n",
    "\n",
    "**Critérios de aceite:**\n",
    "- Todos os meses cobertos (Jan–Dez) para cada ano\n",
    "- CBO com >95% de preenchimento\n",
    "- ~20-30M registros por ano\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "63efdd50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CHECKPOINT — Microdados CAGED\n",
      "============================================================\n",
      "\n",
      "--- 2021: 36,554,795 movimentações ---\n",
      "  Meses: 12 (OK)\n",
      "  CBO preenchido: 100.0%\n",
      "  Famílias CBO 4d únicas: 626\n",
      "  Admissões: 19,703,604 | Desligamentos: 16,851,191 | Saldo: +2,852,413\n",
      "\n",
      "--- 2022: 42,475,516 movimentações ---\n",
      "  Meses: 12 (OK)\n",
      "  CBO preenchido: 100.0%\n",
      "  Famílias CBO 4d únicas: 624\n",
      "  Admissões: 22,243,441 | Desligamentos: 20,232,075 | Saldo: +2,011,366\n",
      "\n",
      "--- 2023: 44,485,982 movimentações ---\n",
      "  Meses: 12 (OK)\n",
      "  CBO preenchido: 100.0%\n",
      "  Famílias CBO 4d únicas: 626\n",
      "  Admissões: 22,982,161 | Desligamentos: 21,503,821 | Saldo: +1,478,340\n",
      "\n",
      "--- 2024: 48,996,040 movimentações ---\n",
      "  Meses: 12 (OK)\n",
      "  CBO preenchido: 100.0%\n",
      "  Famílias CBO 4d únicas: 625\n",
      "  Admissões: 25,336,277 | Desligamentos: 23,659,763 | Saldo: +1,676,514\n",
      "\n",
      "--- 2025: 26,312,103 movimentações ---\n",
      "  Meses: 6 (ALERTA: 6 meses)\n",
      "  CBO preenchido: 100.0%\n",
      "  Famílias CBO 4d únicas: 622\n",
      "  Admissões: 13,763,059 | Desligamentos: 12,549,044 | Saldo: +1,214,015\n",
      "\n",
      "============================================================\n",
      "TOTAL: 198,824,436 movimentações (2021–2025)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Etapa 2a.2b — CHECKPOINT: Verificar dados CAGED\n",
    "# Carrega cada parquet individualmente (para evitar OOM)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CHECKPOINT — Microdados CAGED\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "total_registros = 0\n",
    "for ano in range(ANO_INICIO, ANO_FIM + 1):\n",
    "    parquet_path = DATA_RAW / f\"caged_{ano}.parquet\"\n",
    "    df = pd.read_parquet(parquet_path)\n",
    "\n",
    "    # Volume\n",
    "    print(f\"\\n--- {ano}: {len(df):,} movimentações ---\")\n",
    "    total_registros += len(df)\n",
    "\n",
    "    # Cobertura mensal\n",
    "    meses = sorted(df['mes'].dropna().unique())\n",
    "    status = \"OK\" if len(meses) == 12 else f\"ALERTA: {len(meses)} meses\"\n",
    "    print(f\"  Meses: {len(meses)} ({status})\")\n",
    "\n",
    "    # Preenchimento CBO\n",
    "    cbo_pct = df['cbo_2002'].notna().mean()\n",
    "    print(f\"  CBO preenchido: {cbo_pct:.1%}\")\n",
    "\n",
    "    # CBOs únicos\n",
    "    cbos = df['cbo_2002'].dropna().astype(str).str[:4].nunique()\n",
    "    print(f\"  Famílias CBO 4d únicas: {cbos}\")\n",
    "\n",
    "    # Admissões vs desligamentos\n",
    "    if 'saldo_movimentacao' in df.columns:\n",
    "        adm = (df['saldo_movimentacao'] == 1).sum()\n",
    "        desl = (df['saldo_movimentacao'] == -1).sum()\n",
    "        print(f\"  Admissões: {adm:,} | Desligamentos: {desl:,} | Saldo: {adm-desl:+,}\")\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(f\"TOTAL: {total_registros:,} movimentações ({ANO_INICIO}–{ANO_FIM})\")\n",
    "print(f\"{'=' * 60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1201bac",
   "metadata": {},
   "source": [
    "### 3a. Agregação: Microdados → Painel Mensal por Ocupação\n",
    "\n",
    "Agregar os microdados de movimentação (nível individual) em um painel mensal por ocupação CBO (4 dígitos). Cada linha do painel representará uma ocupação-mês com métricas agregadas.\n",
    "\n",
    "#### Estratégia de agregação\n",
    "\n",
    "Seguindo a abordagem de Hui, Reshef & Zhou (2024), construímos um painel ao nível de **ocupação × mês** com as seguintes métricas:\n",
    "\n",
    "| Métrica | Cálculo | Descrição |\n",
    "|---------|---------|-----------|\n",
    "| `admissoes` | Contagem de `saldo_movimentacao == 1` | Fluxo de contratação |\n",
    "| `desligamentos` | Contagem de `saldo_movimentacao == -1` | Fluxo de demissão |\n",
    "| `saldo` | `admissoes - desligamentos` | Criação líquida de empregos |\n",
    "| `salario_medio_adm` | Média do `salario_mensal` (admissões) | Nível salarial |\n",
    "| `salario_mediano_adm` | Mediana do `salario_mensal` (admissões) | Robustez a outliers |\n",
    "| `pct_mulher_adm` | % de `sexo == 3` nas admissões | Composição de gênero |\n",
    "| `pct_superior_adm` | % com `grau_instrucao >= 9` | Composição educacional |\n",
    "\n",
    "> **Nota — CBO 4 dígitos:** A CBO tem 6 dígitos (XXXX-XX), onde os 4 primeiros definem a \"família\" ocupacional. Para o crosswalk com ISCO-08, usamos os 4 primeiros dígitos (família CBO ≈ unit group ISCO-08).\n",
    "\n",
    "> **Nota — Otimização de memória:** O processamento é feito ano a ano para evitar OOM (Out-of-Memory) com ~100M+ registros. Flags booleanos são pré-computados como float para permitir agregação vetorizada (evitando lambdas lentas). A mediana é calculada separadamente por ser computacionalmente cara.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45a92c2",
   "metadata": {},
   "source": [
    "**Validação da codificação `sexo` (CAGED/Base dos Dados):** Confirmar que os valores são 1 = Masculino e 3 = Feminino (não há código 2). O agregado `pct_mulher_adm` usa `sexo == 3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c349d573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sexo — value_counts (ano 2024):\n",
      "sexo\n",
      "1    28494836\n",
      "3    20500968\n",
      "9         236\n",
      "Name: count, dtype: int64\n",
      "  Esperado: 1 = Masculino, 3 = Feminino (Base dos Dados/CAGED).\n"
     ]
    }
   ],
   "source": [
    "# Conferir codificação de sexo nos microdados CAGED (um ano como amostra)\n",
    "_ano_amostra = 2024\n",
    "_path_amostra = DATA_RAW / f\"caged_{_ano_amostra}.parquet\"\n",
    "if not _path_amostra.exists():\n",
    "    _ano_amostra = ANO_INICIO\n",
    "    _path_amostra = DATA_RAW / f\"caged_{_ano_amostra}.parquet\"\n",
    "if _path_amostra.exists():\n",
    "    _df_sexo = pd.read_parquet(_path_amostra, columns=[\"sexo\"])\n",
    "    print(f\"sexo — value_counts (ano {_ano_amostra}):\")\n",
    "    print(_df_sexo[\"sexo\"].value_counts().sort_index())\n",
    "    print(\"  Esperado: 1 = Masculino, 3 = Feminino (Base dos Dados/CAGED).\")\n",
    "else:\n",
    "    print(\"Nenhum parquet de microdados encontrado para verificar sexo.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cea3a3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Construindo painel a partir dos microdados (ano a ano)...\n",
      "\n",
      "  Processando 2021...\n",
      "    2021: 19,703,604 admissões, 16,851,191 desligamentos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9l/bxkb7j2s259_jlrwc_dnrklr0000gn/T/ipykernel_2640/2488733575.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_adm['sal_mulher'] = np.where(df_adm['is_mulher'] == 1, df_adm['salario_mensal'], np.nan)\n",
      "/var/folders/9l/bxkb7j2s259_jlrwc_dnrklr0000gn/T/ipykernel_2640/2488733575.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_adm['sal_homem'] = np.where(df_adm['is_mulher'] == 0, df_adm['salario_mensal'], np.nan)\n",
      "/var/folders/9l/bxkb7j2s259_jlrwc_dnrklr0000gn/T/ipykernel_2640/2488733575.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_adm['sal_branco'] = np.where(df_adm['is_branco'] == 1, df_adm['salario_mensal'], np.nan)\n",
      "/var/folders/9l/bxkb7j2s259_jlrwc_dnrklr0000gn/T/ipykernel_2640/2488733575.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_adm['sal_negro'] = np.where(df_adm['is_negro'] == 1, df_adm['salario_mensal'], np.nan)\n",
      "/var/folders/9l/bxkb7j2s259_jlrwc_dnrklr0000gn/T/ipykernel_2640/2488733575.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_adm['sal_jovem'] = np.where(df_adm['is_jovem'] == 1, df_adm['salario_mensal'], np.nan)\n",
      "/var/folders/9l/bxkb7j2s259_jlrwc_dnrklr0000gn/T/ipykernel_2640/2488733575.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_adm['sal_naojovem'] = np.where(df_adm['is_jovem'] == 0, df_adm['salario_mensal'], np.nan)\n",
      "/var/folders/9l/bxkb7j2s259_jlrwc_dnrklr0000gn/T/ipykernel_2640/2488733575.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_adm['sal_sup'] = np.where(df_adm['is_superior'] == 1, df_adm['salario_mensal'], np.nan)\n",
      "/var/folders/9l/bxkb7j2s259_jlrwc_dnrklr0000gn/T/ipykernel_2640/2488733575.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_adm['sal_med'] = np.where(df_adm['is_superior'] == 0, df_adm['salario_mensal'], np.nan)\n",
      "/var/folders/9l/bxkb7j2s259_jlrwc_dnrklr0000gn/T/ipykernel_2640/2488733575.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_adm['is_homem'] = 1 - df_adm['is_mulher']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → 7,328 linhas no painel\n",
      "\n",
      "  Processando 2022...\n",
      "    2022: 22,243,441 admissões, 20,232,075 desligamentos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9l/bxkb7j2s259_jlrwc_dnrklr0000gn/T/ipykernel_2640/2488733575.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_adm['sal_mulher'] = np.where(df_adm['is_mulher'] == 1, df_adm['salario_mensal'], np.nan)\n",
      "/var/folders/9l/bxkb7j2s259_jlrwc_dnrklr0000gn/T/ipykernel_2640/2488733575.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_adm['sal_homem'] = np.where(df_adm['is_mulher'] == 0, df_adm['salario_mensal'], np.nan)\n",
      "/var/folders/9l/bxkb7j2s259_jlrwc_dnrklr0000gn/T/ipykernel_2640/2488733575.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_adm['sal_branco'] = np.where(df_adm['is_branco'] == 1, df_adm['salario_mensal'], np.nan)\n",
      "/var/folders/9l/bxkb7j2s259_jlrwc_dnrklr0000gn/T/ipykernel_2640/2488733575.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_adm['sal_negro'] = np.where(df_adm['is_negro'] == 1, df_adm['salario_mensal'], np.nan)\n",
      "/var/folders/9l/bxkb7j2s259_jlrwc_dnrklr0000gn/T/ipykernel_2640/2488733575.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_adm['sal_jovem'] = np.where(df_adm['is_jovem'] == 1, df_adm['salario_mensal'], np.nan)\n",
      "/var/folders/9l/bxkb7j2s259_jlrwc_dnrklr0000gn/T/ipykernel_2640/2488733575.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_adm['sal_naojovem'] = np.where(df_adm['is_jovem'] == 0, df_adm['salario_mensal'], np.nan)\n",
      "/var/folders/9l/bxkb7j2s259_jlrwc_dnrklr0000gn/T/ipykernel_2640/2488733575.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_adm['sal_sup'] = np.where(df_adm['is_superior'] == 1, df_adm['salario_mensal'], np.nan)\n",
      "/var/folders/9l/bxkb7j2s259_jlrwc_dnrklr0000gn/T/ipykernel_2640/2488733575.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_adm['sal_med'] = np.where(df_adm['is_superior'] == 0, df_adm['salario_mensal'], np.nan)\n",
      "/var/folders/9l/bxkb7j2s259_jlrwc_dnrklr0000gn/T/ipykernel_2640/2488733575.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_adm['is_homem'] = 1 - df_adm['is_mulher']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → 7,341 linhas no painel\n",
      "\n",
      "  Processando 2023...\n",
      "    2023: 22,982,161 admissões, 21,503,821 desligamentos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9l/bxkb7j2s259_jlrwc_dnrklr0000gn/T/ipykernel_2640/2488733575.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_adm['sal_mulher'] = np.where(df_adm['is_mulher'] == 1, df_adm['salario_mensal'], np.nan)\n",
      "/var/folders/9l/bxkb7j2s259_jlrwc_dnrklr0000gn/T/ipykernel_2640/2488733575.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_adm['sal_homem'] = np.where(df_adm['is_mulher'] == 0, df_adm['salario_mensal'], np.nan)\n",
      "/var/folders/9l/bxkb7j2s259_jlrwc_dnrklr0000gn/T/ipykernel_2640/2488733575.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_adm['sal_branco'] = np.where(df_adm['is_branco'] == 1, df_adm['salario_mensal'], np.nan)\n",
      "/var/folders/9l/bxkb7j2s259_jlrwc_dnrklr0000gn/T/ipykernel_2640/2488733575.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_adm['sal_negro'] = np.where(df_adm['is_negro'] == 1, df_adm['salario_mensal'], np.nan)\n",
      "/var/folders/9l/bxkb7j2s259_jlrwc_dnrklr0000gn/T/ipykernel_2640/2488733575.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_adm['sal_jovem'] = np.where(df_adm['is_jovem'] == 1, df_adm['salario_mensal'], np.nan)\n",
      "/var/folders/9l/bxkb7j2s259_jlrwc_dnrklr0000gn/T/ipykernel_2640/2488733575.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_adm['sal_naojovem'] = np.where(df_adm['is_jovem'] == 0, df_adm['salario_mensal'], np.nan)\n",
      "/var/folders/9l/bxkb7j2s259_jlrwc_dnrklr0000gn/T/ipykernel_2640/2488733575.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_adm['sal_sup'] = np.where(df_adm['is_superior'] == 1, df_adm['salario_mensal'], np.nan)\n",
      "/var/folders/9l/bxkb7j2s259_jlrwc_dnrklr0000gn/T/ipykernel_2640/2488733575.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_adm['sal_med'] = np.where(df_adm['is_superior'] == 0, df_adm['salario_mensal'], np.nan)\n",
      "/var/folders/9l/bxkb7j2s259_jlrwc_dnrklr0000gn/T/ipykernel_2640/2488733575.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_adm['is_homem'] = 1 - df_adm['is_mulher']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → 7,332 linhas no painel\n",
      "\n",
      "  Processando 2024...\n",
      "    2024: 25,336,277 admissões, 23,659,763 desligamentos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9l/bxkb7j2s259_jlrwc_dnrklr0000gn/T/ipykernel_2640/2488733575.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_adm['sal_mulher'] = np.where(df_adm['is_mulher'] == 1, df_adm['salario_mensal'], np.nan)\n",
      "/var/folders/9l/bxkb7j2s259_jlrwc_dnrklr0000gn/T/ipykernel_2640/2488733575.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_adm['sal_homem'] = np.where(df_adm['is_mulher'] == 0, df_adm['salario_mensal'], np.nan)\n",
      "/var/folders/9l/bxkb7j2s259_jlrwc_dnrklr0000gn/T/ipykernel_2640/2488733575.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_adm['sal_branco'] = np.where(df_adm['is_branco'] == 1, df_adm['salario_mensal'], np.nan)\n",
      "/var/folders/9l/bxkb7j2s259_jlrwc_dnrklr0000gn/T/ipykernel_2640/2488733575.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_adm['sal_negro'] = np.where(df_adm['is_negro'] == 1, df_adm['salario_mensal'], np.nan)\n",
      "/var/folders/9l/bxkb7j2s259_jlrwc_dnrklr0000gn/T/ipykernel_2640/2488733575.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_adm['sal_jovem'] = np.where(df_adm['is_jovem'] == 1, df_adm['salario_mensal'], np.nan)\n",
      "/var/folders/9l/bxkb7j2s259_jlrwc_dnrklr0000gn/T/ipykernel_2640/2488733575.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_adm['sal_naojovem'] = np.where(df_adm['is_jovem'] == 0, df_adm['salario_mensal'], np.nan)\n",
      "/var/folders/9l/bxkb7j2s259_jlrwc_dnrklr0000gn/T/ipykernel_2640/2488733575.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_adm['sal_sup'] = np.where(df_adm['is_superior'] == 1, df_adm['salario_mensal'], np.nan)\n",
      "/var/folders/9l/bxkb7j2s259_jlrwc_dnrklr0000gn/T/ipykernel_2640/2488733575.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_adm['sal_med'] = np.where(df_adm['is_superior'] == 0, df_adm['salario_mensal'], np.nan)\n",
      "/var/folders/9l/bxkb7j2s259_jlrwc_dnrklr0000gn/T/ipykernel_2640/2488733575.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_adm['is_homem'] = 1 - df_adm['is_mulher']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → 7,308 linhas no painel\n",
      "\n",
      "  Processando 2025...\n",
      "    2025: 13,763,059 admissões, 12,549,044 desligamentos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9l/bxkb7j2s259_jlrwc_dnrklr0000gn/T/ipykernel_2640/2488733575.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_adm['sal_mulher'] = np.where(df_adm['is_mulher'] == 1, df_adm['salario_mensal'], np.nan)\n",
      "/var/folders/9l/bxkb7j2s259_jlrwc_dnrklr0000gn/T/ipykernel_2640/2488733575.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_adm['sal_homem'] = np.where(df_adm['is_mulher'] == 0, df_adm['salario_mensal'], np.nan)\n",
      "/var/folders/9l/bxkb7j2s259_jlrwc_dnrklr0000gn/T/ipykernel_2640/2488733575.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_adm['sal_branco'] = np.where(df_adm['is_branco'] == 1, df_adm['salario_mensal'], np.nan)\n",
      "/var/folders/9l/bxkb7j2s259_jlrwc_dnrklr0000gn/T/ipykernel_2640/2488733575.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_adm['sal_negro'] = np.where(df_adm['is_negro'] == 1, df_adm['salario_mensal'], np.nan)\n",
      "/var/folders/9l/bxkb7j2s259_jlrwc_dnrklr0000gn/T/ipykernel_2640/2488733575.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_adm['sal_jovem'] = np.where(df_adm['is_jovem'] == 1, df_adm['salario_mensal'], np.nan)\n",
      "/var/folders/9l/bxkb7j2s259_jlrwc_dnrklr0000gn/T/ipykernel_2640/2488733575.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_adm['sal_naojovem'] = np.where(df_adm['is_jovem'] == 0, df_adm['salario_mensal'], np.nan)\n",
      "/var/folders/9l/bxkb7j2s259_jlrwc_dnrklr0000gn/T/ipykernel_2640/2488733575.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_adm['sal_sup'] = np.where(df_adm['is_superior'] == 1, df_adm['salario_mensal'], np.nan)\n",
      "/var/folders/9l/bxkb7j2s259_jlrwc_dnrklr0000gn/T/ipykernel_2640/2488733575.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_adm['sal_med'] = np.where(df_adm['is_superior'] == 0, df_adm['salario_mensal'], np.nan)\n",
      "/var/folders/9l/bxkb7j2s259_jlrwc_dnrklr0000gn/T/ipykernel_2640/2488733575.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_adm['is_homem'] = 1 - df_adm['is_mulher']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → 3,679 linhas no painel\n",
      "\n",
      "Painel salvo: painel_caged_mensal.parquet\n",
      "\n",
      "Painel final: 32,988 linhas\n",
      "  Ocupações: 629, Períodos: 54\n",
      "  Shape: (32988, 47)\n"
     ]
    }
   ],
   "source": [
    "# Etapa 2a.3a — Agregação: Microdados → Painel Mensal por Ocupação\n",
    "# Checkpoint: se o painel já existe, carrega direto.\n",
    "\n",
    "if PAINEL_MENSAL_FILE.exists():\n",
    "    painel = pd.read_parquet(PAINEL_MENSAL_FILE)\n",
    "    print(f\"Painel carregado do checkpoint: {PAINEL_MENSAL_FILE.name}\")\n",
    "    print(f\"  {len(painel):,} linhas, {painel['cbo_4d'].nunique()} ocupações, \"\n",
    "          f\"{painel['periodo'].nunique()} períodos\")\n",
    "else:\n",
    "    print(\"Construindo painel a partir dos microdados (ano a ano)...\")\n",
    "    paineis_anuais = []\n",
    "\n",
    "    for ano in range(ANO_INICIO, ANO_FIM + 1):\n",
    "        print(f\"\\n  Processando {ano}...\", flush=True)\n",
    "        df = pd.read_parquet(DATA_RAW / f\"caged_{ano}.parquet\")\n",
    "\n",
    "        # CBO 4 dígitos\n",
    "        df['cbo_2002'] = df['cbo_2002'].astype(str).str.strip()\n",
    "        df['cbo_4d'] = df['cbo_2002'].str[:4]\n",
    "        df = df[df['cbo_4d'].str.len() == 4]\n",
    "        df = df[df['cbo_4d'].str.isdigit()]\n",
    "        df = df[~df['cbo_4d'].isin(['0000'])]\n",
    "\n",
    "        # Variáveis temporais\n",
    "        df['periodo'] = df['ano'].astype(str) + '-' + df['mes'].astype(str).str.zfill(2)\n",
    "        df['periodo_num'] = df['ano'].astype(int) * 100 + df['mes'].astype(int)\n",
    "        df['post'] = (df['periodo_num'] >= ANO_TRATAMENTO * 100 + MES_TRATAMENTO).astype(int)\n",
    "\n",
    "        # Flags booleanos (CAGED: sexo 1=Masc, 3=Fem; alinhado à Etapa 1a)\n",
    "        CODIGO_SEXO_MULHER = 3\n",
    "        CODIGOS_RACA_BRANCA, CODIGOS_RACA_NEGRA = [1], [2, 4]\n",
    "        IDADE_CORTE_JOVEM = 29\n",
    "        CODIGOS_ESCOLARIDADE_SUPERIOR = ['9', '10', '11', '12', '13']\n",
    "        df['is_mulher'] = (df['sexo'].astype(str) == str(CODIGO_SEXO_MULHER)).astype(float)\n",
    "        raca_str = df['raca_cor'].astype(str)\n",
    "        df['is_branco'] = raca_str.isin([str(c) for c in CODIGOS_RACA_BRANCA]).astype(float)\n",
    "        df['is_negro'] = raca_str.isin([str(c) for c in CODIGOS_RACA_NEGRA]).astype(float)\n",
    "        df['is_jovem'] = (df['idade'] <= IDADE_CORTE_JOVEM).astype(float)\n",
    "        df['is_superior'] = df['grau_instrucao'].astype(str).isin(CODIGOS_ESCOLARIDADE_SUPERIOR).astype(float)\n",
    "\n",
    "        # Separar admissões e desligamentos\n",
    "        df_adm = df[df['saldo_movimentacao'] == 1]\n",
    "        df_desl = df[df['saldo_movimentacao'] == -1]\n",
    "        print(f\"    {ano}: {len(df_adm):,} admissões, {len(df_desl):,} desligamentos\", flush=True)\n",
    "\n",
    "        # Colunas de salário mascaradas (média condicional por grupo)\n",
    "        df_adm['sal_mulher'] = np.where(df_adm['is_mulher'] == 1, df_adm['salario_mensal'], np.nan)\n",
    "        df_adm['sal_homem'] = np.where(df_adm['is_mulher'] == 0, df_adm['salario_mensal'], np.nan)\n",
    "        df_adm['sal_branco'] = np.where(df_adm['is_branco'] == 1, df_adm['salario_mensal'], np.nan)\n",
    "        df_adm['sal_negro'] = np.where(df_adm['is_negro'] == 1, df_adm['salario_mensal'], np.nan)\n",
    "        df_adm['sal_jovem'] = np.where(df_adm['is_jovem'] == 1, df_adm['salario_mensal'], np.nan)\n",
    "        df_adm['sal_naojovem'] = np.where(df_adm['is_jovem'] == 0, df_adm['salario_mensal'], np.nan)\n",
    "        df_adm['sal_sup'] = np.where(df_adm['is_superior'] == 1, df_adm['salario_mensal'], np.nan)\n",
    "        df_adm['sal_med'] = np.where(df_adm['is_superior'] == 0, df_adm['salario_mensal'], np.nan)\n",
    "        df_adm['is_homem'] = 1 - df_adm['is_mulher']\n",
    "\n",
    "        # Agregar admissões + heterogeneidade demográfica\n",
    "        painel_adm = df_adm.groupby(['cbo_4d', 'ano', 'mes']).agg(\n",
    "            admissoes=('saldo_movimentacao', 'count'),\n",
    "            salario_medio_adm=('salario_mensal', 'mean'),\n",
    "            idade_media_adm=('idade', 'mean'),\n",
    "            pct_mulher_adm=('is_mulher', 'mean'),\n",
    "            pct_superior_adm=('is_superior', 'mean'),\n",
    "            pct_branco_adm=('is_branco', 'mean'),\n",
    "            pct_negro_adm=('is_negro', 'mean'),\n",
    "            pct_jovem_adm=('is_jovem', 'mean'),\n",
    "            salario_medio_mulher=('sal_mulher', 'mean'),\n",
    "            salario_medio_homem=('sal_homem', 'mean'),\n",
    "            salario_medio_branco=('sal_branco', 'mean'),\n",
    "            salario_medio_negro=('sal_negro', 'mean'),\n",
    "            salario_medio_jovem=('sal_jovem', 'mean'),\n",
    "            salario_medio_naojovem=('sal_naojovem', 'mean'),\n",
    "            salario_medio_superior=('sal_sup', 'mean'),\n",
    "            salario_medio_medio=('sal_med', 'mean'),\n",
    "            admissoes_mulher=('is_mulher', 'sum'),\n",
    "            admissoes_homem=('is_homem', 'sum'),\n",
    "            admissoes_jovem=('is_jovem', 'sum'),\n",
    "            admissoes_negro=('is_negro', 'sum'),\n",
    "        ).reset_index()\n",
    "\n",
    "        # Mediana separada (performance)\n",
    "        mediana = df_adm.groupby(['cbo_4d', 'ano', 'mes'])['salario_mensal'].median().reset_index()\n",
    "        mediana.columns = ['cbo_4d', 'ano', 'mes', 'salario_mediano_adm']\n",
    "        painel_adm = painel_adm.merge(mediana, on=['cbo_4d', 'ano', 'mes'], how='left')\n",
    "\n",
    "        # Agregar desligamentos\n",
    "        painel_desl = df_desl.groupby(['cbo_4d', 'ano', 'mes']).agg(\n",
    "            desligamentos=('saldo_movimentacao', 'count'),\n",
    "            salario_medio_desl=('salario_mensal', 'mean'),\n",
    "        ).reset_index()\n",
    "\n",
    "        # Merge\n",
    "        p = painel_adm.merge(painel_desl, on=['cbo_4d', 'ano', 'mes'], how='outer').fillna(0)\n",
    "        p['saldo'] = p['admissoes'] - p['desligamentos']\n",
    "        p['n_movimentacoes'] = p['admissoes'] + p['desligamentos']\n",
    "        p['periodo'] = p['ano'].astype(int).astype(str) + '-' + p['mes'].astype(int).astype(str).str.zfill(2)\n",
    "        p['periodo_num'] = p['ano'].astype(int) * 100 + p['mes'].astype(int)\n",
    "        p['post'] = (p['periodo_num'] >= ANO_TRATAMENTO * 100 + MES_TRATAMENTO).astype(int)\n",
    "        p['ln_admissoes'] = np.log(p['admissoes'] + 1)\n",
    "        p['ln_desligamentos'] = np.log(p['desligamentos'] + 1)\n",
    "        p['ln_salario_adm'] = np.log(p['salario_medio_adm'].clip(lower=1))\n",
    "        p['cbo_2d'] = p['cbo_4d'].str[:2]\n",
    "        # Logs de heterogeneidade (salários e admissões por grupo)\n",
    "        for grp in ['mulher', 'homem', 'branco', 'negro', 'jovem', 'naojovem', 'superior', 'medio']:\n",
    "            col = f'salario_medio_{grp}'\n",
    "            if col in p.columns:\n",
    "                p[f'ln_salario_{grp}'] = np.log(p[col].clip(lower=1))\n",
    "        for grp in ['mulher', 'homem', 'jovem', 'negro']:\n",
    "            col = f'admissoes_{grp}'\n",
    "            if col in p.columns:\n",
    "                p[f'ln_admissoes_{grp}'] = np.log(p[col].astype(float) + 1)\n",
    "\n",
    "        paineis_anuais.append(p)\n",
    "        print(f\"    → {len(p):,} linhas no painel\", flush=True)\n",
    "\n",
    "    painel = pd.concat(paineis_anuais, ignore_index=True)\n",
    "    painel.to_parquet(PAINEL_MENSAL_FILE, index=False)\n",
    "    print(f\"\\nPainel salvo: {PAINEL_MENSAL_FILE.name}\")\n",
    "\n",
    "print(f\"\\nPainel final: {len(painel):,} linhas\")\n",
    "print(f\"  Ocupações: {painel['cbo_4d'].nunique()}, Períodos: {painel['periodo'].nunique()}\")\n",
    "print(f\"  Shape: {painel.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e75561",
   "metadata": {},
   "source": [
    "### 3b. Verificar painel agregado (CHECKPOINT)\n",
    "\n",
    "Verificar integridade do painel: dimensões, balanceamento (ocupações × períodos), cobertura temporal, distribuição de variáveis-chave e série temporal agregada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f3b53806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CHECKPOINT — Painel Ocupação × Mês\n",
      "============================================================\n",
      "\n",
      "Ocupações: 629\n",
      "Períodos: 54\n",
      "Painel teórico (balanceado): 33,966\n",
      "Painel real: 32,988\n",
      "Balanceamento: 97.1%\n",
      "\n",
      "Meses por ocupação:\n",
      "  Min: 2, Max: 54, Média: 52.4\n",
      "  Ocupações com < 12 meses: 9\n",
      "  Ocupações com todos os 54 meses: 589\n",
      "\n",
      "Estatísticas descritivas:\n",
      "       admissoes  desligamentos    saldo  salario_medio_adm\n",
      "count    32988.0        32988.0  32988.0            32988.0\n",
      "mean      3153.5         2873.6    279.9             6131.1\n",
      "std      13880.0        12450.5   2323.0           158475.4\n",
      "min          0.0            0.0 -46650.0                0.0\n",
      "25%         60.0           60.0    -16.0             1782.8\n",
      "50%        293.0          289.0      7.0             2371.3\n",
      "75%       1338.0         1264.0    107.0             3811.2\n",
      "max     289900.0       284338.0  90556.0         18799538.2\n",
      "\n",
      "Série temporal (primeiros e últimos 3 meses):\n",
      " periodo_num  total_adm  total_desl   sal_medio\n",
      "      202101    1550075     1293016 3697.157086\n",
      "      202102    1715425     1317510 3723.743109\n",
      "      202103    1626885     1450555 3252.934263\n",
      "...\n",
      " periodo_num  total_adm  total_desl    sal_medio\n",
      "      202504    2282187     2024659  4011.260301\n",
      "      202505    2256225     2107233  4441.730675\n",
      "      202506    2139182     1972561 11519.380585\n"
     ]
    }
   ],
   "source": [
    "# Etapa 2a.3b — CHECKPOINT: Verificar painel agregado\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CHECKPOINT — Painel Ocupação × Mês\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. Dimensões\n",
    "n_ocup = painel['cbo_4d'].nunique()\n",
    "n_periodos = painel['periodo'].nunique()\n",
    "print(f\"\\nOcupações: {n_ocup}\")\n",
    "print(f\"Períodos: {n_periodos}\")\n",
    "print(f\"Painel teórico (balanceado): {n_ocup * n_periodos:,}\")\n",
    "print(f\"Painel real: {len(painel):,}\")\n",
    "print(f\"Balanceamento: {len(painel) / (n_ocup * n_periodos):.1%}\")\n",
    "\n",
    "# 2. Ocupações com poucos meses\n",
    "ocup_meses = painel.groupby('cbo_4d')['periodo'].nunique()\n",
    "print(f\"\\nMeses por ocupação:\")\n",
    "print(f\"  Min: {ocup_meses.min()}, Max: {ocup_meses.max()}, Média: {ocup_meses.mean():.1f}\")\n",
    "print(f\"  Ocupações com < 12 meses: {(ocup_meses < 12).sum()}\")\n",
    "print(f\"  Ocupações com todos os {n_periodos} meses: {(ocup_meses == n_periodos).sum()}\")\n",
    "\n",
    "# 3. Estatísticas descritivas\n",
    "print(\"\\nEstatísticas descritivas:\")\n",
    "print(painel[['admissoes', 'desligamentos', 'saldo', 'salario_medio_adm']].describe().round(1))\n",
    "\n",
    "# 4. Série temporal agregada\n",
    "ts = painel.groupby('periodo_num').agg(\n",
    "    total_adm=('admissoes', 'sum'),\n",
    "    total_desl=('desligamentos', 'sum'),\n",
    "    sal_medio=('salario_medio_adm', 'mean'),\n",
    ").reset_index()\n",
    "print(\"\\nSérie temporal (primeiros e últimos 3 meses):\")\n",
    "print(ts.head(3).to_string(index=False))\n",
    "print(\"...\")\n",
    "print(ts.tail(3).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2cbb00",
   "metadata": {},
   "source": [
    "#### Verificação: outlier salarial em Jun/2025\n",
    "\n",
    "A série temporal agregada no checkpoint acima pode mostrar salário médio elevado em Jun/2025 (~3× os meses anteriores). Abaixo verificamos se isso reflete **(i)** poucas células ocupação×mês com salário muito alto e/ou poucas movimentações, **(ii)** possível publicação parcial do mês, ou **(iii)** padrão real dos dados. Conforme o diagnóstico, pode-se documentar, filtrar células com poucas movimentações ou truncar a janela em Mai/2025."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "713ec067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jun/2025 — Distribuição de salario_medio_adm (células ocupação×mês):\n",
      "count        615.00\n",
      "mean       11519.38\n",
      "std       170295.09\n",
      "min            0.00\n",
      "50%         2647.30\n",
      "90%         7652.32\n",
      "95%        10449.24\n",
      "99%        38462.94\n",
      "max      4216672.39\n",
      "Name: salario_medio_adm, dtype: float64\n",
      "\n",
      "Células com n_movimentacoes < 50 e salario_medio_adm > R$ 10,000: 9\n",
      "  Admissões nessas células: 125 (0.01% do total de Jun/2025)\n",
      "cbo_4d  admissoes  n_movimentacoes  salario_medio_adm\n",
      "  2423          1                1       80466.670000\n",
      "  1237         22               48       43743.163182\n",
      "  1222         19               49       41853.112105\n",
      "  1234         15               36       38843.381333\n",
      "  1221          6               15       35815.645000\n",
      "  1223         19               36       14490.656842\n",
      "  2422          1                1       14097.220000\n",
      "  2622         24               48       12752.264583\n",
      "  1031         18               20       10953.792222\n",
      "\n",
      "Comparativo 2025:\n",
      "  Mai/2025: células=614, total_adm=2,256,225, sal_medio(agg)=4,442\n",
      "  Jun/2025: células=615, total_adm=2,139,182, sal_medio(agg)=11,519\n",
      "  Média mensal 2025: células~306, total_adm~2,293,843\n"
     ]
    }
   ],
   "source": [
    "# Diagnóstico: Jun/2025 — distribuição de salario_medio_adm e células extremas\n",
    "jun = painel[painel['periodo_num'] == 202506].copy()\n",
    "print(\"Jun/2025 — Distribuição de salario_medio_adm (células ocupação×mês):\")\n",
    "print(jun['salario_medio_adm'].describe(percentiles=[0.5, 0.9, 0.95, 0.99]).round(2))\n",
    "print()\n",
    "\n",
    "# Células com poucas movimentações e salário alto\n",
    "limiar_mov = 50\n",
    "limiar_sal = 10_000\n",
    "mask_extremo = (jun['n_movimentacoes'] < limiar_mov) & (jun['salario_medio_adm'] > limiar_sal)\n",
    "n_extremo = mask_extremo.sum()\n",
    "adm_jun_total = jun['admissoes'].sum()\n",
    "adm_extremo = jun.loc[mask_extremo, 'admissoes'].sum()\n",
    "print(f\"Células com n_movimentacoes < {limiar_mov} e salario_medio_adm > R$ {limiar_sal:,.0f}: {n_extremo}\")\n",
    "print(f\"  Admissões nessas células: {adm_extremo:,} ({100*adm_extremo/adm_jun_total:.2f}% do total de Jun/2025)\")\n",
    "if n_extremo > 0:\n",
    "    print(jun.loc[mask_extremo, ['cbo_4d', 'admissoes', 'n_movimentacoes', 'salario_medio_adm']].sort_values('salario_medio_adm', ascending=False).head(15).to_string(index=False))\n",
    "print()\n",
    "\n",
    "# Comparação com Mai/2025 e média 2025\n",
    "mai = painel[painel['periodo_num'] == 202505]\n",
    "ano2025 = painel[painel['periodo_num'] // 100 == 2025]\n",
    "print(\"Comparativo 2025:\")\n",
    "print(f\"  Mai/2025: células={len(mai)}, total_adm={mai['admissoes'].sum():,.0f}, sal_medio(agg)={mai['salario_medio_adm'].mean():,.0f}\")\n",
    "print(f\"  Jun/2025: células={len(jun)}, total_adm={adm_jun_total:,.0f}, sal_medio(agg)={jun['salario_medio_adm'].mean():,.0f}\")\n",
    "print(f\"  Média mensal 2025: células~{len(ano2025)//12:.0f}, total_adm~{ano2025.groupby('periodo_num')['admissoes'].sum().mean():,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9935501e",
   "metadata": {},
   "source": [
    "### 4a. Crosswalk CBO 2002 → ISCO-08\n",
    "\n",
    "Mapear os códigos CBO 2002 (usados no CAGED) para ISCO-08 (usados no índice ILO). **Esta é a etapa metodologicamente mais delicada do pipeline.**\n",
    "\n",
    "#### Contexto\n",
    "\n",
    "A CBO 2002 foi construída com base na ISCO-88/ISCO-08, compartilhando a mesma estrutura hierárquica:\n",
    "\n",
    "| Nível | CBO 2002 | ISCO-08 | Alinhamento |\n",
    "|-------|----------|---------|-------------|\n",
    "| 1 dígito | Grande Grupo (10) | Major Group (10) | Perfeito |\n",
    "| 2 dígitos | Subgrupo Principal (~46) | Sub-major Group (43) | Bom (14 CBOs sem match direto) |\n",
    "| 3 dígitos | Subgrupo (~194) | Minor Group (130) | Parcial (~45% direto) |\n",
    "| 4 dígitos | Família (~629) | Unit Group (427) | Divergente (~28% direto) |\n",
    "\n",
    "#### Estratégia adotada: Dual (2d principal + 4d robustez)\n",
    "\n",
    "**PARTE A — Especificação PRINCIPAL (2 dígitos):**\n",
    "- CBO 2d → ISCO-08 Sub-major Group (match direto)\n",
    "- Fallback: CBO 1d → ISCO-08 Major Group (média)\n",
    "- Cobertura esperada: **100%**\n",
    "\n",
    "**PARTE B — Especificação de ROBUSTEZ (4 dígitos, fallback hierárquico em 6 níveis):**\n",
    "\n",
    "| Nível | Estratégia | Cobertura esperada |\n",
    "|-------|------------|--------------------|\n",
    "| N1 | CBO 4d = ISCO-08 4d (match direto) | ~28% |\n",
    "| N2 | CBO 4d = ISCO-88 4d → ISCO-08 via correspondência oficial | ~+9% |\n",
    "| N3 | CBO 3d = ISCO-08 3d (média Minor Group) | ~+20% |\n",
    "| N4 | CBO 3d = ISCO-88 3d → ISCO-08 via correspondência | ~+1% |\n",
    "| N5 | CBO 2d = ISCO-08 2d (= especificação principal) | ~+18% |\n",
    "| N6 | CBO 1d = ISCO-08 1d (média Major Group) | ~+24% |\n",
    "\n",
    "> **Nota — Muendler (CBO 1994):** O arquivo `cbo-isco-conc.csv` de Muendler & Poole (2004) mapeia CBO **1994** → ISCO-88, NÃO a CBO 2002 usada no CAGED. Por isso, o match 4d via Muendler é limitado. A estratégia principal utiliza a similaridade estrutural entre CBO 2002 e ISCO-08/88 com fallback hierárquico.\n",
    "\n",
    "> **Nota sobre atenuação:** Se o crosswalk a 4 dígitos introduz erro de medição, o efeito típico é **atenuação** (viés em direção a zero). Encontrar efeito significativo mesmo com erro de medição sugere que o efeito real é provavelmente maior.\n",
    "\n",
    "**Validação do crosswalk:** O notebook não usa Muendler para o match principal; utiliza a correspondência oficial ISCO-08↔88 e fallback hierárquico. Na especificação 2d: match direto CBO 2d → ISCO-08 Sub-major Group, com fallback a 1 dígito (Major Group). Na 4d: fallback em 6 níveis (N1→N6). Resultado verificado: cobertura 100% em 2d e 4d, correlação entre exposure_score_2d e exposure_score_4d ~0,915 — consistente com o planejamento e pronto para o DiD no Notebook 2b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5fdb8d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Índice ILO carregado: 427 ocupações ISCO-08\n",
      "  Score range: [0.090, 0.700]\n",
      "  Correspondência ISCO-08↔88: 678 mapeamentos\n",
      "\n",
      "============================================================\n",
      "PARTE A: Crosswalk 2 dígitos (PRINCIPAL)\n",
      "============================================================\n",
      "  COBERTURA 2d: 100.0%\n",
      "    2-digit: 25,101 (76.1%)\n",
      "    1-digit (fallback): 7,887 (23.9%)\n",
      "\n",
      "============================================================\n",
      "PARTE B: Crosswalk 4 dígitos (ROBUSTEZ)\n",
      "============================================================\n",
      "  CBOs 4d únicos: 629\n",
      "    N1: 177 (28.1%)\n",
      "    N2: 56 (8.9%)\n",
      "    N3: 123 (19.6%)\n",
      "    N4: 7 (1.1%)\n",
      "    N5: 115 (18.3%)\n",
      "    N6: 151 (24.0%)\n",
      "  COBERTURA 4d: 100.0%\n",
      "\n",
      "  Correlação Pearson (2d vs 4d): 0.9147\n",
      "\n",
      "Salvo: painel_caged_crosswalk.parquet\n"
     ]
    }
   ],
   "source": [
    "# Etapa 2a.4a — Crosswalk CBO 2002 → ISCO-08 (Dual: 2d principal + 4d robustez)\n",
    "# Checkpoint: se o painel com crosswalk já existe, carrega direto.\n",
    "\n",
    "if PAINEL_CROSSWALK_FILE.exists():\n",
    "    painel = pd.read_parquet(PAINEL_CROSSWALK_FILE)\n",
    "    print(f\"Crosswalk carregado do checkpoint: {PAINEL_CROSSWALK_FILE.name}\")\n",
    "    print(f\"  {len(painel):,} linhas, cobertura 2d: {painel['exposure_score_2d'].notna().mean():.1%}, \"\n",
    "          f\"4d: {painel['exposure_score_4d'].notna().mean():.1%}\")\n",
    "else:\n",
    "    # ══════════════════════════════════════════════════════════════════════\n",
    "    # Carregar dados de referência\n",
    "    # ══════════════════════════════════════════════════════════════════════\n",
    "    df_ilo = pd.read_csv(ILO_FILE)\n",
    "    df_ilo['isco_08_str'] = df_ilo['isco_08'].astype(str).str.zfill(4)\n",
    "    print(f\"Índice ILO carregado: {len(df_ilo)} ocupações ISCO-08\")\n",
    "    print(f\"  Score range: [{df_ilo['exposure_score'].min():.3f}, {df_ilo['exposure_score'].max():.3f}]\")\n",
    "\n",
    "    # Dicts ILO em múltiplos níveis\n",
    "    codes = df_ilo['isco_08_str']\n",
    "    ilo_4d = df_ilo.groupby('isco_08_str')['exposure_score'].mean().to_dict()\n",
    "    ilo_3d = df_ilo.assign(g=codes.str[:3]).groupby('g')['exposure_score'].mean().to_dict()\n",
    "    ilo_2d = df_ilo.assign(g=codes.str[:2]).groupby('g')['exposure_score'].mean().to_dict()\n",
    "    ilo_1d = df_ilo.assign(g=codes.str[:1]).groupby('g')['exposure_score'].mean().to_dict()\n",
    "\n",
    "    # Correspondência ISCO-08 ↔ ISCO-88 (arquivo local)\n",
    "    isco88_to_08 = {}\n",
    "    isco88_3d_to_08_3d = {}\n",
    "    if ISCO_08_88_FILE.exists():\n",
    "        df_corr = pd.read_excel(ISCO_08_88_FILE, sheet_name='ISCO-08 to 88')\n",
    "        df_corr['isco08_4d'] = df_corr['ISCO-08 code'].astype(str).str.strip().str.zfill(4)\n",
    "        df_corr['isco88_4d'] = df_corr['ISCO-88 code'].astype(str).str.strip().str.zfill(4)\n",
    "        isco88_to_08 = df_corr.groupby('isco88_4d')['isco08_4d'].apply(list).to_dict()\n",
    "        df_corr['isco88_3d'] = df_corr['isco88_4d'].str[:3]\n",
    "        df_corr['isco08_3d'] = df_corr['isco08_4d'].str[:3]\n",
    "        isco88_3d_to_08_3d = df_corr.groupby('isco88_3d')['isco08_3d'].apply(\n",
    "            lambda x: list(set(x))).to_dict()\n",
    "        print(f\"  Correspondência ISCO-08↔88: {len(df_corr)} mapeamentos\")\n",
    "\n",
    "    # ══════════════════════════════════════════════════════════════════════\n",
    "    # PARTE A: 2 dígitos (PRINCIPAL)\n",
    "    # ══════════════════════════════════════════════════════════════════════\n",
    "    print(f\"\\n{'='*60}\\nPARTE A: Crosswalk 2 dígitos (PRINCIPAL)\\n{'='*60}\")\n",
    "\n",
    "    painel['exposure_score_2d'] = painel['cbo_2d'].map(ilo_2d)\n",
    "    painel['match_level_2d'] = np.where(painel['exposure_score_2d'].notna(), '2-digit', None)\n",
    "\n",
    "    # Fallback a 1 dígito\n",
    "    mask_na = painel['exposure_score_2d'].isna()\n",
    "    if mask_na.any():\n",
    "        cbo_1d = painel.loc[mask_na, 'cbo_4d'].str[:1]\n",
    "        painel.loc[mask_na, 'exposure_score_2d'] = cbo_1d.map(ilo_1d).values\n",
    "        painel.loc[mask_na, 'match_level_2d'] = '1-digit (fallback)'\n",
    "\n",
    "    painel['exposure_score'] = painel['exposure_score_2d']\n",
    "    cov_2d = painel['exposure_score_2d'].notna().mean()\n",
    "    print(f\"  COBERTURA 2d: {cov_2d:.1%}\")\n",
    "    for lvl, cnt in painel['match_level_2d'].value_counts().items():\n",
    "        print(f\"    {lvl}: {cnt:,} ({cnt/len(painel):.1%})\")\n",
    "\n",
    "    # ══════════════════════════════════════════════════════════════════════\n",
    "    # PARTE B: 4 dígitos (ROBUSTEZ) — fallback hierárquico 6 níveis\n",
    "    # ══════════════════════════════════════════════════════════════════════\n",
    "    print(f\"\\n{'='*60}\\nPARTE B: Crosswalk 4 dígitos (ROBUSTEZ)\\n{'='*60}\")\n",
    "\n",
    "    cbos_unicos = sorted(painel['cbo_4d'].unique())\n",
    "    cbo_score_4d = {}\n",
    "    cbo_match_level = {}\n",
    "    counts = {'N1': 0, 'N2': 0, 'N3': 0, 'N4': 0, 'N5': 0, 'N6': 0, 'sem': 0}\n",
    "\n",
    "    for cbo in cbos_unicos:\n",
    "        score, level = None, None\n",
    "\n",
    "        # N1: CBO 4d = ISCO-08 4d\n",
    "        if cbo in ilo_4d:\n",
    "            score, level = ilo_4d[cbo], 'N1: ISCO-08 4d direto'\n",
    "            counts['N1'] += 1\n",
    "        # N2: CBO 4d = ISCO-88 4d → ISCO-08\n",
    "        if score is None and cbo in isco88_to_08:\n",
    "            scores_c = [ilo_4d[c] for c in isco88_to_08[cbo] if c in ilo_4d]\n",
    "            if scores_c:\n",
    "                score, level = np.mean(scores_c), 'N2: via ISCO-88→08 4d'\n",
    "                counts['N2'] += 1\n",
    "        # N3: CBO 3d = ISCO-08 3d\n",
    "        if score is None and cbo[:3] in ilo_3d:\n",
    "            score, level = ilo_3d[cbo[:3]], 'N3: ISCO-08 3d'\n",
    "            counts['N3'] += 1\n",
    "        # N4: CBO 3d = ISCO-88 3d → ISCO-08 3d\n",
    "        if score is None and cbo[:3] in isco88_3d_to_08_3d:\n",
    "            scores_c = [ilo_3d[c] for c in isco88_3d_to_08_3d[cbo[:3]] if c in ilo_3d]\n",
    "            if scores_c:\n",
    "                score, level = np.mean(scores_c), 'N4: via ISCO-88→08 3d'\n",
    "                counts['N4'] += 1\n",
    "        # N5: CBO 2d = ISCO-08 2d\n",
    "        if score is None and cbo[:2] in ilo_2d:\n",
    "            score, level = ilo_2d[cbo[:2]], 'N5: ISCO-08 2d'\n",
    "            counts['N5'] += 1\n",
    "        # N6: CBO 1d = ISCO-08 1d\n",
    "        if score is None and cbo[:1] in ilo_1d:\n",
    "            score, level = ilo_1d[cbo[:1]], 'N6: ISCO-08 1d'\n",
    "            counts['N6'] += 1\n",
    "\n",
    "        if score is not None:\n",
    "            cbo_score_4d[cbo] = score\n",
    "            cbo_match_level[cbo] = level\n",
    "        else:\n",
    "            counts['sem'] += 1\n",
    "\n",
    "    painel['exposure_score_4d'] = painel['cbo_4d'].map(cbo_score_4d)\n",
    "    painel['match_level_4d'] = painel['cbo_4d'].map(cbo_match_level)\n",
    "\n",
    "    total = len(cbos_unicos)\n",
    "    print(f\"  CBOs 4d únicos: {total}\")\n",
    "    for k, v in counts.items():\n",
    "        if v > 0:\n",
    "            print(f\"    {k}: {v} ({v/total:.1%})\")\n",
    "    print(f\"  COBERTURA 4d: {painel['exposure_score_4d'].notna().mean():.1%}\")\n",
    "\n",
    "    # Correlação 2d vs 4d\n",
    "    df_check = painel[['cbo_4d', 'exposure_score_2d', 'exposure_score_4d']].drop_duplicates('cbo_4d')\n",
    "    corr = df_check['exposure_score_2d'].corr(df_check['exposure_score_4d'])\n",
    "    print(f\"\\n  Correlação Pearson (2d vs 4d): {corr:.4f}\")\n",
    "\n",
    "    painel.to_parquet(PAINEL_CROSSWALK_FILE, index=False)\n",
    "    print(f\"\\nSalvo: {PAINEL_CROSSWALK_FILE.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639cc50d",
   "metadata": {},
   "source": [
    "**CBOs 2 dígitos sem match direto em ISCO-08:** Subgrupos principais CBO que não possuem equivalente direto em Sub-major Group ISCO-08; recebem score via fallback a 1 dígito (Major Group). Lista abaixo (a partir do painel com crosswalk)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7a414cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CBOs 2d sem match direto (fallback a Major Group): 14\n",
      "Códigos: ['10', '20', '27', '30', '37', '39', '64', '76', '77', '78', '79', '84', '86', '99']\n",
      "\n",
      "Exemplo (cbo_2d=10): cbo_4d presentes: ['1010', '1011', '1020', '1021', '1030', '1031']...\n"
     ]
    }
   ],
   "source": [
    "# Listar CBO 2d que caem no fallback a 1 dígito (sem match direto em ISCO-08 Sub-major Group)\n",
    "if 'match_level_2d' in painel.columns:\n",
    "    fallback_2d = painel[painel['match_level_2d'] == '1-digit (fallback)']['cbo_2d'].unique()\n",
    "    fallback_2d = sorted(fallback_2d)\n",
    "    print(f\"CBOs 2d sem match direto (fallback a Major Group): {len(fallback_2d)}\")\n",
    "    print(\"Códigos:\", fallback_2d)\n",
    "    # Opcional: exemplos de cbo_4d por um desses 2d\n",
    "    if len(fallback_2d) > 0:\n",
    "        ex = painel[painel['cbo_2d'] == fallback_2d[0]][['cbo_2d', 'cbo_4d']].drop_duplicates()\n",
    "        print(f\"\\nExemplo (cbo_2d={fallback_2d[0]}): cbo_4d presentes: {ex['cbo_4d'].tolist()[:8]}...\")\n",
    "else:\n",
    "    print(\"Coluna match_level_2d não encontrada (crosswalk pode ter sido carregado sem essa coluna).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dd6bcb",
   "metadata": {},
   "source": [
    "### 4b. Verificar crosswalk (CHECKPOINT)\n",
    "\n",
    "Validar qualidade do crosswalk nas DUAS especificações: principal (2 dígitos) e robustez (4 dígitos). Verificar cobertura, distribuição de scores, correlação entre especificações e sanity check por grande grupo CBO.\n",
    "\n",
    "**Critérios de aceite:**\n",
    "- Cobertura 2d ≥ 95% (esperado ~100%)\n",
    "- Cobertura 4d ≥ 80% (esperado ~100% com fallback)\n",
    "- Correlação 2d vs 4d > 0.8 (consistência entre especificações)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "de59ed6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CHECKPOINT — Crosswalk CBO → ISCO-08 (Dual)\n",
      "============================================================\n",
      "\n",
      "--- Cobertura ---\n",
      "  2 dígitos (PRINCIPAL): 100.0%\n",
      "  4 dígitos (ROBUSTEZ):  100.0%\n",
      "\n",
      "--- Estatísticas dos scores ---\n",
      "\n",
      "exposure_score_2d (PRINCIPAL):\n",
      "count    32988.0000\n",
      "mean         0.2778\n",
      "std          0.1243\n",
      "min          0.1167\n",
      "25%          0.1658\n",
      "50%          0.2459\n",
      "75%          0.3725\n",
      "max          0.6325\n",
      "Name: exposure_score_2d, dtype: float64\n",
      "\n",
      "exposure_score_4d (ROBUSTEZ):\n",
      "count    32988.0000\n",
      "mean         0.2830\n",
      "std          0.1315\n",
      "min          0.0900\n",
      "25%          0.1658\n",
      "50%          0.2500\n",
      "75%          0.3650\n",
      "max          0.7000\n",
      "Name: exposure_score_4d, dtype: float64\n",
      "\n",
      "--- Correlação 2d vs 4d ---\n",
      "  Pearson: 0.9150\n",
      "  Alta correlação — bom sinal de consistência.\n",
      "\n",
      "--- Exposição por grande grupo CBO ---\n",
      "Grande Grupo                               Score 2d   Score 4d\n",
      "--------------------------------------------------------------\n",
      "  Dirigentes                                  0.367      0.375\n",
      "  Profissionais das ciências                  0.393      0.396\n",
      "  Técnicos nível médio                        0.334      0.338\n",
      "  Trabalhadores de serv. admin.               0.580      0.557\n",
      "  Trabalhadores de serviços/comércio          0.243      0.247\n",
      "  Agropecuária                                0.157      0.161\n",
      "  Produção industrial                         0.161      0.165\n",
      "  Operadores de máquinas                      0.213      0.217\n",
      "  Manutenção e reparação                      0.143      0.187\n",
      "  (!) = diferença > 0.1 entre 2d e 4d\n"
     ]
    }
   ],
   "source": [
    "# Etapa 2a.4b — CHECKPOINT: Verificar crosswalk CBO → ISCO-08\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CHECKPOINT — Crosswalk CBO → ISCO-08 (Dual)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. Cobertura\n",
    "coverage_2d = painel['exposure_score_2d'].notna().mean()\n",
    "coverage_4d = painel['exposure_score_4d'].notna().mean()\n",
    "print(f\"\\n--- Cobertura ---\")\n",
    "print(f\"  2 dígitos (PRINCIPAL): {coverage_2d:.1%}\")\n",
    "print(f\"  4 dígitos (ROBUSTEZ):  {coverage_4d:.1%}\")\n",
    "if coverage_2d < 0.95:\n",
    "    print(f\"  ALERTA: Cobertura 2d abaixo de 95%!\")\n",
    "if coverage_4d < 0.80:\n",
    "    print(f\"  AVISO: Cobertura 4d abaixo de 80%.\")\n",
    "\n",
    "# 2. Estatísticas dos scores\n",
    "print(f\"\\n--- Estatísticas dos scores ---\")\n",
    "print(f\"\\nexposure_score_2d (PRINCIPAL):\")\n",
    "print(painel['exposure_score_2d'].describe().round(4))\n",
    "print(f\"\\nexposure_score_4d (ROBUSTEZ):\")\n",
    "print(painel['exposure_score_4d'].describe().round(4))\n",
    "\n",
    "# 3. Correlação\n",
    "mask_both = painel['exposure_score_2d'].notna() & painel['exposure_score_4d'].notna()\n",
    "if mask_both.any():\n",
    "    corr = painel.loc[mask_both, 'exposure_score_2d'].corr(\n",
    "        painel.loc[mask_both, 'exposure_score_4d'])\n",
    "    print(f\"\\n--- Correlação 2d vs 4d ---\")\n",
    "    print(f\"  Pearson: {corr:.4f}\")\n",
    "    print(f\"  {'Alta correlação — bom sinal de consistência.' if corr > 0.8 else 'Correlação moderada.'}\")\n",
    "\n",
    "# 4. Sanity check por grande grupo CBO\n",
    "painel['grande_grupo_cbo'] = painel['cbo_4d'].str[0]\n",
    "print(f\"\\n--- Exposição por grande grupo CBO ---\")\n",
    "print(f\"{'Grande Grupo':<40} {'Score 2d':>10} {'Score 4d':>10}\")\n",
    "print(\"-\" * 62)\n",
    "for gg, nome in sorted(GRANDES_GRUPOS_CBO.items()):\n",
    "    mask = painel['grande_grupo_cbo'] == gg\n",
    "    if mask.any():\n",
    "        s2d = painel.loc[mask, 'exposure_score_2d'].mean()\n",
    "        s4d = painel.loc[mask, 'exposure_score_4d'].mean()\n",
    "        s4d_str = f\"{s4d:.3f}\" if not np.isnan(s4d) else \"N/A\"\n",
    "        flag = \" (!)\" if not np.isnan(s4d) and abs(s2d - s4d) > 0.1 else \"\"\n",
    "        print(f\"  {nome:<38} {s2d:>10.3f} {s4d_str:>10}{flag}\")\n",
    "print(f\"  (!) = diferença > 0.1 entre 2d e 4d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbe3871",
   "metadata": {},
   "source": [
    "### 5a. Definição de tratamento\n",
    "\n",
    "Definir as variáveis de tratamento para a análise DiD. O tratamento é baseado na **exposição ocupacional à IA generativa**: ocupações com alta exposição (top 20%) vs. baixa exposição.\n",
    "\n",
    "#### Variáveis criadas\n",
    "\n",
    "| Variável | Definição | Uso |\n",
    "|----------|-----------|-----|\n",
    "| `alta_exp` | 1 se `exposure_score_2d >= percentil 80` | **Especificação principal** |\n",
    "| `alta_exp_10` | 1 se `exposure_score_2d >= percentil 90` | Robustez (cutoff) |\n",
    "| `alta_exp_25` | 1 se `exposure_score_2d >= percentil 75` | Robustez (cutoff) |\n",
    "| `alta_exp_mediana` | 1 se `exposure_score_2d >= mediana` | Alternativa binária |\n",
    "| `quintil_exp` | Quintil de exposição (Q1–Q5) | Análise por quantil |\n",
    "| `alta_exp_4d` | 1 se `exposure_score_4d >= percentil 80` | Robustez (crosswalk 4d) |\n",
    "| `did` | `post × alta_exp` | Interação DiD principal |\n",
    "| `did_4d` | `post × alta_exp_4d` | Interação DiD robustez |\n",
    "\n",
    "> **Nota:** Os thresholds são calculados sobre a distribuição de **ocupações** (uma obs por CBO), não ponderada por volume de movimentações. Cada ocupação tem peso igual na definição do tratamento.\n",
    "\n",
    "> **Nota — Tratamento contínuo:** Além das dummies, `exposure_score_2d` e `exposure_score_4d` podem ser usados diretamente como tratamento contínuo em especificações alternativas, conforme Hui et al. (2024)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8798f7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresholds de exposição (2d, PRINCIPAL):\n",
      "  alta_exp_10: 0.4433 (78 ocupações, 12%)\n",
      "  alta_exp: 0.3854 (131 ocupações, 21%)\n",
      "  alta_exp_25: 0.3725 (165 ocupações, 26%)\n",
      "  alta_exp_mediana: 0.2459 (332 ocupações, 53%)\n",
      "\n",
      "Threshold 4d (p80): 0.3863 (137 ocupações)\n",
      "\n",
      "--- Distribuição de tratamento ---\n",
      "  Alta exp 2d (top 20%): 20.3% das obs\n",
      "  Alta exp 4d (top 20%): 21.3% das obs\n",
      "  Períodos pré:  14,058\n",
      "  Períodos pós:  18,930\n",
      "  Concordância 2d vs 4d: 93.1%\n",
      "\n",
      "Tabela de contingência (2d, principal):\n",
      "alta_exp  Controle  Tratamento    All\n",
      "post                                 \n",
      "Pré          11195        2863  14058\n",
      "Pós          15092        3838  18930\n",
      "All          26287        6701  32988\n"
     ]
    }
   ],
   "source": [
    "# Etapa 2a.5a — Definição de tratamento\n",
    "\n",
    "# ── Thresholds sobre a distribuição de ocupações (2d) ──\n",
    "ocup_scores_2d = painel.groupby('cbo_4d')['exposure_score_2d'].first().dropna()\n",
    "\n",
    "thresholds_2d = {\n",
    "    'alta_exp_10':      ocup_scores_2d.quantile(0.90),\n",
    "    'alta_exp':         ocup_scores_2d.quantile(0.80),  # PRINCIPAL\n",
    "    'alta_exp_25':      ocup_scores_2d.quantile(0.75),\n",
    "    'alta_exp_mediana':  ocup_scores_2d.quantile(0.50),\n",
    "}\n",
    "\n",
    "print(\"Thresholds de exposição (2d, PRINCIPAL):\")\n",
    "for name, val in thresholds_2d.items():\n",
    "    n_above = (ocup_scores_2d >= val).sum()\n",
    "    pct = n_above / len(ocup_scores_2d) * 100\n",
    "    print(f\"  {name}: {val:.4f} ({n_above} ocupações, {pct:.0f}%)\")\n",
    "\n",
    "# ── Dummies de tratamento 2d ──\n",
    "for name, threshold in thresholds_2d.items():\n",
    "    painel[name] = (painel['exposure_score_2d'] >= threshold).astype(int)\n",
    "\n",
    "# Quintis\n",
    "painel['quintil_exp'] = pd.qcut(\n",
    "    painel['exposure_score_2d'].rank(method='first'),\n",
    "    q=5,\n",
    "    labels=['Q1 (Baixa)', 'Q2', 'Q3', 'Q4', 'Q5 (Alta)']\n",
    ")\n",
    "\n",
    "# ── Dummies 4d (ROBUSTEZ) ──\n",
    "ocup_scores_4d = painel.groupby('cbo_4d')['exposure_score_4d'].first().dropna()\n",
    "threshold_4d_80 = ocup_scores_4d.quantile(0.80)\n",
    "painel['alta_exp_4d'] = (painel['exposure_score_4d'] >= threshold_4d_80).astype(int)\n",
    "print(f\"\\nThreshold 4d (p80): {threshold_4d_80:.4f} ({(ocup_scores_4d >= threshold_4d_80).sum()} ocupações)\")\n",
    "\n",
    "# ── Interações DiD ──\n",
    "painel['did'] = painel['post'] * painel['alta_exp']\n",
    "painel['did_4d'] = painel['post'] * painel['alta_exp_4d']\n",
    "\n",
    "# ── Resumo ──\n",
    "print(f\"\\n--- Distribuição de tratamento ---\")\n",
    "print(f\"  Alta exp 2d (top 20%): {painel['alta_exp'].mean():.1%} das obs\")\n",
    "print(f\"  Alta exp 4d (top 20%): {painel['alta_exp_4d'].mean():.1%} das obs\")\n",
    "print(f\"  Períodos pré:  {painel[painel['post']==0].shape[0]:,}\")\n",
    "print(f\"  Períodos pós:  {painel[painel['post']==1].shape[0]:,}\")\n",
    "\n",
    "concordancia = (painel['alta_exp'] == painel['alta_exp_4d']).mean()\n",
    "print(f\"  Concordância 2d vs 4d: {concordancia:.1%}\")\n",
    "\n",
    "# Tabela de contingência\n",
    "ct = pd.crosstab(\n",
    "    painel['post'].map({0: 'Pré', 1: 'Pós'}),\n",
    "    painel['alta_exp'].map({0: 'Controle', 1: 'Tratamento'}),\n",
    "    margins=True\n",
    ")\n",
    "print(f\"\\nTabela de contingência (2d, principal):\")\n",
    "print(ct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7c990d",
   "metadata": {},
   "source": [
    "### 5b. Verificar tratamento (CHECKPOINT)\n",
    "\n",
    "Validar a definição de tratamento: top/bottom ocupações por exposição, distribuição por quintil, e concordância entre especificações 2d e 4d.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bc1457bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CHECKPOINT — Definição de Tratamento\n",
      "============================================================\n",
      "\n",
      "--- Top 10 ocupações MAIS expostas ---\n",
      "  CBO 4101: score=0.632, admissões=343,660  (Trabalhadores de serv. admin.)\n",
      "  CBO 4102: score=0.632, admissões=109,397  (Trabalhadores de serv. admin.)\n",
      "  CBO 4110: score=0.632, admissões=7,169,112  (Trabalhadores de serv. admin.)\n",
      "  CBO 4121: score=0.632, admissões=36,099  (Trabalhadores de serv. admin.)\n",
      "  CBO 4122: score=0.632, admissões=217,727  (Trabalhadores de serv. admin.)\n",
      "  CBO 4131: score=0.632, admissões=521,115  (Trabalhadores de serv. admin.)\n",
      "  CBO 4132: score=0.632, admissões=178,605  (Trabalhadores de serv. admin.)\n",
      "  CBO 4141: score=0.632, admissões=4,019,302  (Trabalhadores de serv. admin.)\n",
      "  CBO 4142: score=0.632, admissões=406,552  (Trabalhadores de serv. admin.)\n",
      "  CBO 4151: score=0.632, admissões=36,816  (Trabalhadores de serv. admin.)\n",
      "\n",
      "--- 10 ocupações MENOS expostas ---\n",
      "  CBO 9101: score=0.117, admissões=44,866  (Manutenção e reparação)\n",
      "  CBO 9102: score=0.117, admissões=13,108  (Manutenção e reparação)\n",
      "  CBO 9109: score=0.117, admissões=1,394  (Manutenção e reparação)\n",
      "  CBO 9111: score=0.117, admissões=38,881  (Manutenção e reparação)\n",
      "  CBO 9112: score=0.117, admissões=83,226  (Manutenção e reparação)\n",
      "  CBO 9113: score=0.117, admissões=489,020  (Manutenção e reparação)\n",
      "  CBO 9131: score=0.117, admissões=85,145  (Manutenção e reparação)\n",
      "  CBO 9141: score=0.117, admissões=9,542  (Manutenção e reparação)\n",
      "  CBO 9142: score=0.117, admissões=1,889  (Manutenção e reparação)\n",
      "  CBO 9143: score=0.117, admissões=7,158  (Manutenção e reparação)\n",
      "\n",
      "--- Estatísticas por quintil de exposição ---\n",
      "  Q1 (Baixa): n=6,598, exposure=0.144, adm_mean=3200, sal_medio=4,469\n",
      "  Q2: n=6,597, exposure=0.180, adm_mean=2207, sal_medio=2,599\n",
      "  Q3: n=6,598, exposure=0.252, adm_mean=3676, sal_medio=7,018\n",
      "  Q4: n=6,597, exposure=0.348, adm_mean=2735, sal_medio=8,072\n",
      "  Q5 (Alta): n=6,598, exposure=0.466, adm_mean=3950, sal_medio=8,497\n",
      "\n",
      "--- Concordância 2d vs 4d: 93.1% ---\n",
      "\n",
      "============================================================\n",
      "CHECKPOINT CONCLUÍDO\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Etapa 2a.5b — CHECKPOINT: Verificar definição de tratamento\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CHECKPOINT — Definição de Tratamento\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. Top 10 ocupações mais expostas\n",
    "print(\"\\n--- Top 10 ocupações MAIS expostas ---\")\n",
    "top10 = painel.groupby('cbo_4d').agg(\n",
    "    exposure=('exposure_score', 'first'),\n",
    "    admissoes_total=('admissoes', 'sum'),\n",
    ").nlargest(10, 'exposure')\n",
    "for cbo, row in top10.iterrows():\n",
    "    nome = GRANDES_GRUPOS_CBO.get(cbo[0], '')\n",
    "    print(f\"  CBO {cbo}: score={row['exposure']:.3f}, admissões={row['admissoes_total']:,.0f}  ({nome})\")\n",
    "\n",
    "# 2. Bottom 10 ocupações menos expostas\n",
    "print(f\"\\n--- 10 ocupações MENOS expostas ---\")\n",
    "bot10 = painel.groupby('cbo_4d').agg(\n",
    "    exposure=('exposure_score', 'first'),\n",
    "    admissoes_total=('admissoes', 'sum'),\n",
    ").nsmallest(10, 'exposure')\n",
    "for cbo, row in bot10.iterrows():\n",
    "    nome = GRANDES_GRUPOS_CBO.get(cbo[0], '')\n",
    "    print(f\"  CBO {cbo}: score={row['exposure']:.3f}, admissões={row['admissoes_total']:,.0f}  ({nome})\")\n",
    "\n",
    "# 3. Distribuição por quintil\n",
    "print(f\"\\n--- Estatísticas por quintil de exposição ---\")\n",
    "for q in ['Q1 (Baixa)', 'Q2', 'Q3', 'Q4', 'Q5 (Alta)']:\n",
    "    sub = painel[painel['quintil_exp'] == q]\n",
    "    if len(sub) > 0:\n",
    "        print(f\"  {q}: n={len(sub):,}, \"\n",
    "              f\"exposure={sub['exposure_score'].mean():.3f}, \"\n",
    "              f\"adm_mean={sub['admissoes'].mean():.0f}, \"\n",
    "              f\"sal_medio={sub['salario_medio_adm'].mean():,.0f}\")\n",
    "\n",
    "# 4. Concordância\n",
    "concordancia = (painel['alta_exp'] == painel['alta_exp_4d']).mean()\n",
    "print(f\"\\n--- Concordância 2d vs 4d: {concordancia:.1%} ---\")\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(f\"CHECKPOINT CONCLUÍDO\")\n",
    "print(f\"{'=' * 60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b075f48",
   "metadata": {},
   "source": [
    "### 6a. Enriquecimento do painel (variáveis adicionais)\n",
    "\n",
    "Adicionar variáveis de controle e contexto temporal ao painel para a análise DiD.\n",
    "\n",
    "| Variável | Cálculo | Uso |\n",
    "|----------|---------|-----|\n",
    "| `tempo_relativo_meses` | Meses desde Dez/2022 (t=0) | Event study |\n",
    "| `trend` | Tendência linear (0, 1, 2, ...) | Controle de tendência |\n",
    "| `mes_do_ano` | Mês do ano (1-12) | Dummies de sazonalidade |\n",
    "| `salario_sm` | `salario_medio_adm / SM do ano` | Normalização salarial |\n",
    "| `grande_grupo_nome` | Nome do grande grupo CBO | Efeitos fixos |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2519c01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo relativo: [-23, 30] meses\n",
      "Referência (t=0): 12/2022\n",
      "\n",
      "Variáveis adicionadas: tempo_relativo_meses, trend, mes_do_ano, salario_sm, ln_salario_sm, grande_grupo_nome\n",
      "Colunas totais: 69\n"
     ]
    }
   ],
   "source": [
    "# Etapa 2a.6a — Enriquecimento do painel\n",
    "\n",
    "def periodo_num_to_months(pn):\n",
    "    \"\"\"Converter periodo_num (YYYYMM) para contagem absoluta de meses.\"\"\"\n",
    "    return (pn // 100) * 12 + (pn % 100)\n",
    "\n",
    "# ── Tempo relativo ao tratamento ──\n",
    "ref_periodo = ANO_TRATAMENTO * 100 + MES_TRATAMENTO\n",
    "painel['meses_abs'] = painel['periodo_num'].apply(periodo_num_to_months)\n",
    "ref_meses = periodo_num_to_months(ref_periodo)\n",
    "painel['tempo_relativo_meses'] = painel['meses_abs'] - ref_meses\n",
    "\n",
    "print(f\"Tempo relativo: [{painel['tempo_relativo_meses'].min()}, \"\n",
    "      f\"{painel['tempo_relativo_meses'].max()}] meses\")\n",
    "print(f\"Referência (t=0): {MES_TRATAMENTO}/{ANO_TRATAMENTO}\")\n",
    "\n",
    "# ── Tendência temporal e sazonalidade ──\n",
    "painel['trend'] = painel['meses_abs'] - painel['meses_abs'].min()\n",
    "painel['mes_do_ano'] = painel['mes'].astype(int)\n",
    "\n",
    "# ── Normalização salarial ──\n",
    "painel['sm_ano'] = painel['ano'].astype(int).map(SALARIO_MINIMO)\n",
    "painel['salario_sm'] = painel['salario_medio_adm'] / painel['sm_ano']\n",
    "painel['ln_salario_sm'] = np.log(painel['salario_sm'].clip(lower=0.1))\n",
    "\n",
    "# ── Grande grupo ocupacional ──\n",
    "painel['grande_grupo_cbo'] = painel['cbo_4d'].str[0]\n",
    "painel['grande_grupo_nome'] = painel['grande_grupo_cbo'].map(GRANDES_GRUPOS_CBO)\n",
    "\n",
    "print(f\"\\nVariáveis adicionadas: tempo_relativo_meses, trend, mes_do_ano, \"\n",
    "      f\"salario_sm, ln_salario_sm, grande_grupo_nome\")\n",
    "print(f\"Colunas totais: {painel.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0626572e",
   "metadata": {},
   "source": [
    "### 7. Salvar dataset analítico final\n",
    "\n",
    "Selecionar colunas finais, remover ocupações sem score de exposição e salvar o dataset pronto para a análise DiD (Notebook 2b).\n",
    "\n",
    "**Saída:**\n",
    "- `data/output/painel_caged_did_ready.parquet` — formato eficiente para análise\n",
    "- `data/output/painel_caged_did_ready.csv` — backup legível"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f56e1220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Verificação: colunas obrigatórias para o 2b presentes e sem NA.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DATASET ANALÍTICO FINAL — ETAPA 2a\n",
      "============================================================\n",
      "  Observações:        32,988\n",
      "  Ocupações (CBO 4d): 629\n",
      "  Períodos:           54 meses\n",
      "    Pré-tratamento:   23\n",
      "    Pós-tratamento:   31\n",
      "  Cobertura 2d:       100.0%\n",
      "  Cobertura 4d:       100.0%\n",
      "  Tratamento 2d:      20.3% das obs\n",
      "  Tratamento 4d:      21.3% das obs\n",
      "  Colunas:            52\n",
      "\n",
      "  Salvo em:\n",
      "    data/output/painel_caged_did_ready.parquet\n",
      "    data/output/painel_caged_did_ready.csv\n",
      "    Tamanho: 6.4 MB (parquet), 19.0 MB (csv)\n",
      "\n",
      "  Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32988 entries, 0 to 32987\n",
      "Data columns (total 52 columns):\n",
      " #   Column                Non-Null Count  Dtype   \n",
      "---  ------                --------------  -----   \n",
      " 0   cbo_4d                32988 non-null  object  \n",
      " 1   cbo_2d                32988 non-null  object  \n",
      " 2   ano                   32988 non-null  Int64   \n",
      " 3   mes                   32988 non-null  Int64   \n",
      " 4   periodo               32988 non-null  object  \n",
      " 5   periodo_num           32988 non-null  int64   \n",
      " 6   admissoes             32988 non-null  Int64   \n",
      " 7   desligamentos         32988 non-null  Int64   \n",
      " 8   saldo                 32988 non-null  Int64   \n",
      " 9   n_movimentacoes       32988 non-null  Int64   \n",
      " 10  ln_admissoes          32988 non-null  Float64 \n",
      " 11  ln_desligamentos      32988 non-null  Float64 \n",
      " 12  salario_medio_adm     32988 non-null  float64 \n",
      " 13  salario_mediano_adm   32988 non-null  float64 \n",
      " 14  salario_medio_desl    32988 non-null  float64 \n",
      " 15  ln_salario_adm        32988 non-null  float64 \n",
      " 16  salario_sm            32988 non-null  float64 \n",
      " 17  ln_salario_sm         32988 non-null  float64 \n",
      " 18  idade_media_adm       32988 non-null  Float64 \n",
      " 19  pct_mulher_adm        32988 non-null  float64 \n",
      " 20  pct_superior_adm      32988 non-null  float64 \n",
      " 21  pct_branco_adm        32988 non-null  float64 \n",
      " 22  pct_negro_adm         32988 non-null  float64 \n",
      " 23  pct_jovem_adm         32988 non-null  float64 \n",
      " 24  ln_salario_homem      32988 non-null  float64 \n",
      " 25  ln_salario_mulher     32988 non-null  float64 \n",
      " 26  ln_salario_jovem      32988 non-null  float64 \n",
      " 27  ln_salario_naojovem   32988 non-null  float64 \n",
      " 28  ln_salario_branco     32988 non-null  float64 \n",
      " 29  ln_salario_negro      32988 non-null  float64 \n",
      " 30  ln_salario_superior   32988 non-null  float64 \n",
      " 31  ln_salario_medio      32988 non-null  float64 \n",
      " 32  ln_admissoes_homem    32988 non-null  float64 \n",
      " 33  ln_admissoes_mulher   32988 non-null  float64 \n",
      " 34  ln_admissoes_jovem    32988 non-null  float64 \n",
      " 35  ln_admissoes_negro    32988 non-null  float64 \n",
      " 36  exposure_score_2d     32988 non-null  float64 \n",
      " 37  exposure_score_4d     32988 non-null  float64 \n",
      " 38  alta_exp              32988 non-null  int64   \n",
      " 39  alta_exp_10           32988 non-null  int64   \n",
      " 40  alta_exp_25           32988 non-null  int64   \n",
      " 41  alta_exp_mediana      32988 non-null  int64   \n",
      " 42  quintil_exp           32988 non-null  category\n",
      " 43  alta_exp_4d           32988 non-null  int64   \n",
      " 44  post                  32988 non-null  int64   \n",
      " 45  did                   32988 non-null  int64   \n",
      " 46  did_4d                32988 non-null  int64   \n",
      " 47  tempo_relativo_meses  32988 non-null  int64   \n",
      " 48  trend                 32988 non-null  int64   \n",
      " 49  mes_do_ano            32988 non-null  int64   \n",
      " 50  grande_grupo_cbo      32988 non-null  object  \n",
      " 51  grande_grupo_nome     32988 non-null  object  \n",
      "dtypes: Float64(3), Int64(6), category(1), float64(25), int64(12), object(5)\n",
      "memory usage: 13.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# Etapa 2a.7 — Salvar dataset analítico final\n",
    "\n",
    "# ── Selecionar colunas finais ──\n",
    "cols_finais = [\n",
    "    # Identificação\n",
    "    'cbo_4d', 'cbo_2d', 'ano', 'mes', 'periodo', 'periodo_num',\n",
    "    # Outcomes\n",
    "    'admissoes', 'desligamentos', 'saldo', 'n_movimentacoes',\n",
    "    'ln_admissoes', 'ln_desligamentos',\n",
    "    'salario_medio_adm', 'salario_mediano_adm', 'salario_medio_desl',\n",
    "    'ln_salario_adm', 'salario_sm', 'ln_salario_sm',\n",
    "    # Demografia das admissões (proporções)\n",
    "    'idade_media_adm', 'pct_mulher_adm', 'pct_superior_adm', 'pct_branco_adm', 'pct_negro_adm', 'pct_jovem_adm',\n",
    "    # Heterogeneidade: salários (log)\n",
    "    'ln_salario_homem', 'ln_salario_mulher', 'ln_salario_jovem', 'ln_salario_naojovem',\n",
    "    'ln_salario_branco', 'ln_salario_negro', 'ln_salario_superior', 'ln_salario_medio',\n",
    "    # Heterogeneidade: volumes (log)\n",
    "    'ln_admissoes_homem', 'ln_admissoes_mulher', 'ln_admissoes_jovem', 'ln_admissoes_negro',\n",
    "    # Exposição IA — DUAL\n",
    "    'exposure_score_2d',   # PRINCIPAL\n",
    "    'exposure_score_4d',   # ROBUSTEZ\n",
    "    # Tratamento — DUAL\n",
    "    'alta_exp',            # Top 20% score 2d (PRINCIPAL)\n",
    "    'alta_exp_10', 'alta_exp_25', 'alta_exp_mediana', 'quintil_exp',\n",
    "    'alta_exp_4d',         # Top 20% score 4d (ROBUSTEZ)\n",
    "    # Temporal\n",
    "    'post', 'did', 'did_4d', 'tempo_relativo_meses', 'trend', 'mes_do_ano',\n",
    "    # Classificação\n",
    "    'grande_grupo_cbo', 'grande_grupo_nome',\n",
    "]\n",
    "\n",
    "cols_existentes = [c for c in cols_finais if c in painel.columns]\n",
    "cols_faltantes = [c for c in cols_finais if c not in painel.columns]\n",
    "if cols_faltantes:\n",
    "    print(f\"AVISO: Colunas não encontradas: {cols_faltantes}\")\n",
    "\n",
    "painel_final = painel[cols_existentes].copy()\n",
    "\n",
    "# ── Remover ocupações sem score principal (2d) ──\n",
    "n_antes = len(painel_final)\n",
    "painel_final = painel_final[painel_final['exposure_score_2d'].notna()]\n",
    "n_depois = len(painel_final)\n",
    "if n_antes > n_depois:\n",
    "    print(f\"Removidas {n_antes - n_depois:,} linhas sem exposure_score_2d\")\n",
    "\n",
    "# ── Verificação para o Notebook 2b ──\n",
    "cols_obrigatorias = ['exposure_score_2d', 'exposure_score_4d', 'alta_exp', 'did', 'tempo_relativo_meses', 'post']\n",
    "for c in cols_obrigatorias:\n",
    "    if c not in painel_final.columns:\n",
    "        raise ValueError(f\"Coluna obrigatória ausente para o DiD (Notebook 2b): {c}\")\n",
    "if painel_final[cols_obrigatorias].isna().any().any():\n",
    "    raise ValueError(\"NA em coluna obrigatória para o DiD (Notebook 2b).\")\n",
    "print(\"  Verificação: colunas obrigatórias para o 2b presentes e sem NA.\")\n",
    "\n",
    "# ── Salvar ──\n",
    "painel_final.to_parquet(PAINEL_FINAL_PARQUET, index=False)\n",
    "painel_final.to_csv(PAINEL_FINAL_CSV, index=False)\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "# RESUMO FINAL\n",
    "# ══════════════════════════════════════════════════════════════════════\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"DATASET ANALÍTICO FINAL — ETAPA 2a\")\n",
    "print(f\"{'=' * 60}\")\n",
    "print(f\"  Observações:        {len(painel_final):,}\")\n",
    "print(f\"  Ocupações (CBO 4d): {painel_final['cbo_4d'].nunique()}\")\n",
    "print(f\"  Períodos:           {painel_final['periodo'].nunique()} meses\")\n",
    "print(f\"    Pré-tratamento:   {painel_final[painel_final['post']==0]['periodo'].nunique()}\")\n",
    "print(f\"    Pós-tratamento:   {painel_final[painel_final['post']==1]['periodo'].nunique()}\")\n",
    "print(f\"  Cobertura 2d:       {painel_final['exposure_score_2d'].notna().mean():.1%}\")\n",
    "print(f\"  Cobertura 4d:       {painel_final['exposure_score_4d'].notna().mean():.1%}\")\n",
    "print(f\"  Tratamento 2d:      {painel_final['alta_exp'].mean():.1%} das obs\")\n",
    "print(f\"  Tratamento 4d:      {painel_final['alta_exp_4d'].mean():.1%} das obs\")\n",
    "print(f\"  Colunas:            {painel_final.shape[1]}\")\n",
    "print(f\"\\n  Salvo em:\")\n",
    "print(f\"    {PAINEL_FINAL_PARQUET}\")\n",
    "print(f\"    {PAINEL_FINAL_CSV}\")\n",
    "pq_mb = PAINEL_FINAL_PARQUET.stat().st_size / 1e6\n",
    "csv_mb = PAINEL_FINAL_CSV.stat().st_size / 1e6\n",
    "print(f\"    Tamanho: {pq_mb:.1f} MB (parquet), {csv_mb:.1f} MB (csv)\")\n",
    "\n",
    "print(f\"\\n  Info:\")\n",
    "painel_final.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c169961f",
   "metadata": {},
   "source": [
    "### Limitações desta etapa\n",
    "\n",
    "1. **Novo CAGED (descontinuidade 2020):** A transição para o eSocial (2020) pode afetar a comparabilidade. Mitigamos ao iniciar em 2021 (eSocial já estabilizado, sem efeitos COVID).\n",
    "\n",
    "2. **Fluxos vs. estoques:** O CAGED mede movimentações (admissões/desligamentos), não o estoque de empregados. Quedas em admissões não significam necessariamente queda no emprego total — podem refletir menor rotatividade. Esta é a mesma lógica usada por Hui et al. (2024) com dados do Upwork.\n",
    "\n",
    "3. **Crosswalk CBO → ISCO-08 (especificação principal, 2 dígitos):** Ao agregar por Sub-major Group com fallback a Major Group, perdemos variação intragrupo. Ocupações diferentes dentro do mesmo grupo recebem o mesmo score. A especificação de robustez a 4 dígitos (com fallback hierárquico em 6 níveis) ajuda a avaliar se essa agregação afeta os resultados.\n",
    "\n",
    "4. **Crosswalk CBO → ISCO-08 (robustez, 4 dígitos):** O match direto CBO 4d = ISCO-08 4d cobre apenas ~28% das ocupações. Para o restante, usamos fallback hierárquico (via correspondência ISCO-88→ISCO-08, médias a 3d, 2d e 1d). Quanto mais granular o match, mais preciso o score — mas mesmo com fallback, a correlação entre as especificações 2d e 4d é >0.91, indicando consistência. Erro de medição no tratamento tipicamente atenua os coeficientes (viés em direção a zero).\n",
    "\n",
    "5. **Muendler: CBO 1994, não CBO 2002:** O arquivo de concordância Muendler & Poole (2004) mapeia a CBO *1994* (formato X-XX.XX), não a CBO 2002 (XXXX) usada no CAGED. A utilidade do Muendler para match 4d direto é limitada. A estratégia adotada usa a similaridade estrutural entre CBO 2002 e ISCO-08/88 (ambas baseadas na ISCO), combinada com a tabela oficial de correspondência ISCO-08↔ISCO-88.\n",
    "\n",
    "6. **Emprego formal apenas:** O CAGED cobre apenas o mercado formal (CLT). A informalidade (~40% da força de trabalho brasileira) não é capturada. Efeitos da IA sobre o setor informal requerem fontes alternativas (PNAD).\n",
    "\n",
    "7. **Índice global aplicado ao Brasil:** Mesma limitação da Etapa 1 — o índice ILO foi desenvolvido com foco global e pode não capturar especificidades do mercado de trabalho brasileiro.\n",
    "\n",
    "---\n",
    "\n",
    "### Checklist de entregáveis\n",
    "\n",
    "- [x] `data/raw/caged_{ano}.parquet` — Microdados CAGED por ano (2021–2025)\n",
    "- [x] `data/input/cbo-isco-conc.csv` — Concordância Muendler CBO 1994→ISCO-88\n",
    "- [x] `data/input/Correspondência ISCO 08 a 88.xlsx` — Tabela oficial ISCO-08↔ISCO-88\n",
    "- [x] `data/processed/ilo_exposure_clean.csv` — Índice ILO processado (reusado da Etapa 1)\n",
    "- [x] `data/output/painel_caged_did_ready.parquet` — Dataset analítico final (com scores 2d e 4d)\n",
    "- [x] `data/output/painel_caged_did_ready.csv` — Backup CSV\n",
    "- [x] Todos os CHECKPOINTs passando sem warnings críticos\n",
    "- [x] Cobertura crosswalk 2d = 100%\n",
    "- [x] Cobertura crosswalk 4d = 100% (com fallback hierárquico)\n",
    "- [x] Correlação entre scores 2d e 4d: 0.9147\n",
    "- [x] Sanity check por grande grupo coerente com a literatura\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
