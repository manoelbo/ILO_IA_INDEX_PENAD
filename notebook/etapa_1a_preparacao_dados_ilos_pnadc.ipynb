{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6deeebd6",
   "metadata": {},
   "source": [
    "# ETAPA 1 - Análise Descritiva da Exposição de IA Generativa com ILO Index e PNADc\n",
    "## PREPARAÇÃO DOS DADOS \n",
    "\n",
    "\n",
    "**Dissertação:** Inteligência Artificial Generativa e o Mercado de Trabalho Brasileiro: Uma Análise de Exposição Ocupacional e seus Efeitos Distributivos.\n",
    "**Aluno:** Manoel Brasil Orlandi\n",
    "\n",
    "### Obejtivo\n",
    "\n",
    "Construir a base analítica que une PNAD Contínua e o índice de exposição à IA (ILO), com ocupações em COD e ISCO-08.\n",
    "\n",
    "**Entradas:** Microdados PNAD (BigQuery), planilha ILO, estrutura COD.  \n",
    "**Saída principal:** `data/output/pnad_ilo_merged.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab46382",
   "metadata": {},
   "source": [
    "### 1. Configuração do ambiente\n",
    "Definir caminhos, importar bibliotecas e configurar logs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bseat3wbbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Instalar dependências no kernel atual (executar apenas uma vez)\n",
    "%pip install pandas numpy pyarrow openpyxl --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80796a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuração carregada com sucesso.\n",
      "  PNAD: 2025 Q3\n",
      "  Projeto GCP: mestrado-pnad-2026\n",
      "  ILO file: data/input/Final_Scores_ISCO08_Gmyrek_et_al_2025.xlsx (existe: True)\n"
     ]
    }
   ],
   "source": [
    "# Etapa 1.1 - Preparação de Dados - Configuração do ambiente\n",
    "\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Caminhos (relativos ao diretório do notebook)\n",
    "# ---------------------------------------------------------------------------\n",
    "DATA_INPUT     = Path(\"data/input\")\n",
    "DATA_RAW       = Path(\"data/raw\")\n",
    "DATA_PROCESSED = Path(\"data/processed\")\n",
    "DATA_OUTPUT    = Path(\"data/output\")\n",
    "\n",
    "for d in [DATA_RAW, DATA_PROCESSED, DATA_OUTPUT]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Parâmetros PNAD / GCP\n",
    "# ---------------------------------------------------------------------------\n",
    "GCP_PROJECT_ID  = \"mestrado-pnad-2026\"\n",
    "PNAD_ANO        = 2025\n",
    "PNAD_TRIMESTRE  = 3\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Arquivo ILO (já copiado para data/input)\n",
    "# ---------------------------------------------------------------------------\n",
    "ILO_FILE = DATA_INPUT / \"Final_Scores_ISCO08_Gmyrek_et_al_2025.xlsx\"\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Mapeamentos\n",
    "# ---------------------------------------------------------------------------\n",
    "REGIAO_MAP = {\n",
    "    'RO': 'Norte', 'AC': 'Norte', 'AM': 'Norte', 'RR': 'Norte',\n",
    "    'PA': 'Norte', 'AP': 'Norte', 'TO': 'Norte',\n",
    "    'MA': 'Nordeste', 'PI': 'Nordeste', 'CE': 'Nordeste', 'RN': 'Nordeste',\n",
    "    'PB': 'Nordeste', 'PE': 'Nordeste', 'AL': 'Nordeste', 'SE': 'Nordeste', 'BA': 'Nordeste',\n",
    "    'MG': 'Sudeste', 'ES': 'Sudeste', 'RJ': 'Sudeste', 'SP': 'Sudeste',\n",
    "    'PR': 'Sul', 'SC': 'Sul', 'RS': 'Sul',\n",
    "    'MS': 'Centro-Oeste', 'MT': 'Centro-Oeste', 'GO': 'Centro-Oeste', 'DF': 'Centro-Oeste',\n",
    "}\n",
    "\n",
    "GRANDES_GRUPOS = {\n",
    "    '1': 'Dirigentes e gerentes',\n",
    "    '2': 'Profissionais das ciências',\n",
    "    '3': 'Técnicos nível médio',\n",
    "    '4': 'Apoio administrativo',\n",
    "    '5': 'Serviços e vendedores',\n",
    "    '6': 'Agropecuária qualificada',\n",
    "    '7': 'Indústria qualificada',\n",
    "    '8': 'Operadores de máquinas',\n",
    "    '9': 'Ocupações elementares',\n",
    "}\n",
    "\n",
    "RACA_AGREGADA_MAP = {\n",
    "    '1': 'Branca',\n",
    "    '2': 'Negra',   # Preta\n",
    "    '4': 'Negra',   # Parda\n",
    "    '3': 'Outras',  # Amarela\n",
    "    '5': 'Outras',  # Indígena\n",
    "    '9': 'Outras',  # Sem declaração\n",
    "}\n",
    "\n",
    "POSICAO_FORMAL = ['1', '3', '5']  # Empregado c/ carteira, Militar, Empregador\n",
    "\n",
    "IDADE_BINS   = [0, 25, 35, 45, 55, 100]\n",
    "IDADE_LABELS = ['18-24', '25-34', '35-44', '45-54', '55+']\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Funções utilitárias – estatísticas ponderadas\n",
    "# ---------------------------------------------------------------------------\n",
    "def weighted_mean(values, weights):\n",
    "    \"\"\"Média ponderada (ignora NaN).\"\"\"\n",
    "    mask = ~(pd.isna(values) | pd.isna(weights))\n",
    "    if mask.sum() == 0:\n",
    "        return np.nan\n",
    "    return np.average(values[mask], weights=weights[mask])\n",
    "\n",
    "def weighted_std(values, weights):\n",
    "    \"\"\"Desvio-padrão ponderado (ignora NaN).\"\"\"\n",
    "    mask = ~(pd.isna(values) | pd.isna(weights))\n",
    "    if mask.sum() == 0:\n",
    "        return np.nan\n",
    "    avg = np.average(values[mask], weights=weights[mask])\n",
    "    variance = np.average((values[mask] - avg) ** 2, weights=weights[mask])\n",
    "    return np.sqrt(variance)\n",
    "\n",
    "print(\"Configuração carregada com sucesso.\")\n",
    "print(f\"  PNAD: {PNAD_ANO} Q{PNAD_TRIMESTRE}\")\n",
    "print(f\"  Projeto GCP: {GCP_PROJECT_ID}\")\n",
    "print(f\"  ILO file: {ILO_FILE} (existe: {ILO_FILE.exists()})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd41833d",
   "metadata": {},
   "source": [
    "### 2a. Download dos microdados PNAD\n",
    "Extrair da PNAD Contínua (BigQuery) as variáveis necessárias para o trimestre/ano definido.\n",
    "**Saída:** `data/raw/pnad_*.parquet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dae0a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo PNAD encontrado localmente: pnad_2025q2.parquet\n",
      "Carregado: 202,339 observações\n",
      "\n",
      "df_pnad_raw: 202,339 linhas x 14 colunas\n"
     ]
    }
   ],
   "source": [
    "# Etapa 1.2a - Preparação de Dados - Download dos microdados PNAD\n",
    "# Lógica: se o parquet já existe em data/raw/, carrega direto; senão, baixa do BigQuery.\n",
    "\n",
    "pnad_files = sorted(DATA_RAW.glob(\"pnad_*.parquet\"))\n",
    "\n",
    "if pnad_files:\n",
    "    # --- Caminho rápido: arquivo local já disponível ---\n",
    "    pnad_path = pnad_files[-1]  # mais recente\n",
    "    print(f\"Arquivo PNAD encontrado localmente: {pnad_path.name}\")\n",
    "    df_pnad_raw = pd.read_parquet(pnad_path)\n",
    "    print(f\"Carregado: {len(df_pnad_raw):,} observações\")\n",
    "\n",
    "else:\n",
    "    # --- Caminho completo: download via BigQuery ---\n",
    "    print(\"Nenhum arquivo PNAD local encontrado. Iniciando download do BigQuery...\")\n",
    "    import basedosdados as bd\n",
    "\n",
    "    # Verificar trimestres disponíveis\n",
    "    query_check = \"\"\"\n",
    "    SELECT DISTINCT ano, trimestre, COUNT(*) as n_obs\n",
    "    FROM `basedosdados.br_ibge_pnadc.microdados`\n",
    "    WHERE ano >= 2024\n",
    "    GROUP BY ano, trimestre\n",
    "    ORDER BY ano DESC, trimestre DESC\n",
    "    LIMIT 5\n",
    "    \"\"\"\n",
    "    df_check = bd.read_sql(query_check, billing_project_id=GCP_PROJECT_ID)\n",
    "    print(f\"Trimestres disponíveis:\\n{df_check}\")\n",
    "\n",
    "    trimestre_existe = len(\n",
    "        df_check[(df_check['ano'] == PNAD_ANO) & (df_check['trimestre'] == PNAD_TRIMESTRE)]\n",
    "    ) > 0\n",
    "\n",
    "    if trimestre_existe:\n",
    "        ano_usar, trim_usar = PNAD_ANO, PNAD_TRIMESTRE\n",
    "    else:\n",
    "        ano_usar = int(df_check.iloc[0]['ano'])\n",
    "        trim_usar = int(df_check.iloc[0]['trimestre'])\n",
    "        print(f\"AVISO: {PNAD_ANO} Q{PNAD_TRIMESTRE} indisponível. Usando {ano_usar} Q{trim_usar}\")\n",
    "\n",
    "    # Query principal\n",
    "    query = f\"\"\"\n",
    "    SELECT\n",
    "        ano,\n",
    "        trimestre,\n",
    "        sigla_uf,\n",
    "        v2007  AS sexo,\n",
    "        v2009  AS idade,\n",
    "        v2010  AS raca_cor,\n",
    "        vd3004 AS nivel_instrucao,\n",
    "        v4010  AS cod_ocupacao,\n",
    "        v4013  AS grupamento_atividade,\n",
    "        vd4009 AS posicao_ocupacao,\n",
    "        vd4020 AS rendimento_habitual,\n",
    "        vd4016 AS rendimento_todos,\n",
    "        v4019  AS horas_trabalhadas,\n",
    "        v1028  AS peso\n",
    "    FROM `basedosdados.br_ibge_pnadc.microdados`\n",
    "    WHERE ano = {ano_usar}\n",
    "      AND trimestre = {trim_usar}\n",
    "      AND v4010 IS NOT NULL\n",
    "      AND vd4020 > 0\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"Executando query para {ano_usar} Q{trim_usar} (pode demorar 2-5 min)...\")\n",
    "    df_pnad_raw = bd.read_sql(query, billing_project_id=GCP_PROJECT_ID)\n",
    "\n",
    "    # Salvar parquet\n",
    "    ano_real = int(df_pnad_raw['ano'].iloc[0])\n",
    "    trim_real = int(df_pnad_raw['trimestre'].iloc[0])\n",
    "    output_path = DATA_RAW / f\"pnad_{ano_real}q{trim_real}.parquet\"\n",
    "    df_pnad_raw.to_parquet(output_path, index=False)\n",
    "    print(f\"Salvo em: {output_path}\")\n",
    "\n",
    "print(f\"\\ndf_pnad_raw: {df_pnad_raw.shape[0]:,} linhas x {df_pnad_raw.shape[1]} colunas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9f4041",
   "metadata": {},
   "source": [
    "### 2b. Verificar dados microdados PNAD (CHECKPOINT)\n",
    "Verificar dados gerados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a02ceeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CHECKPOINT - Microdados PNAD\n",
      "============================================================\n",
      "\n",
      "Shape: (202339, 14)\n",
      "Colunas: ['ano', 'trimestre', 'sigla_uf', 'sexo', 'idade', 'raca_cor', 'nivel_instrucao', 'cod_ocupacao', 'grupamento_atividade', 'posicao_ocupacao', 'rendimento_habitual', 'rendimento_todos', 'horas_trabalhadas', 'peso']\n",
      "\n",
      "UFs presentes: 27\n",
      "População representada: 99.0 milhões\n",
      "\n",
      "Dtypes:\n",
      "ano                       Int64\n",
      "trimestre                 Int64\n",
      "sigla_uf                 object\n",
      "sexo                     object\n",
      "idade                     Int64\n",
      "raca_cor                 object\n",
      "nivel_instrucao          object\n",
      "cod_ocupacao             object\n",
      "grupamento_atividade     object\n",
      "posicao_ocupacao         object\n",
      "rendimento_habitual     float64\n",
      "rendimento_todos        float64\n",
      "horas_trabalhadas        object\n",
      "peso                    float64\n",
      "dtype: object\n",
      "\n",
      "Primeiras linhas:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ano</th>\n",
       "      <th>trimestre</th>\n",
       "      <th>sigla_uf</th>\n",
       "      <th>sexo</th>\n",
       "      <th>idade</th>\n",
       "      <th>raca_cor</th>\n",
       "      <th>nivel_instrucao</th>\n",
       "      <th>cod_ocupacao</th>\n",
       "      <th>grupamento_atividade</th>\n",
       "      <th>posicao_ocupacao</th>\n",
       "      <th>rendimento_habitual</th>\n",
       "      <th>rendimento_todos</th>\n",
       "      <th>horas_trabalhadas</th>\n",
       "      <th>peso</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025</td>\n",
       "      <td>2</td>\n",
       "      <td>SP</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5223</td>\n",
       "      <td>48030</td>\n",
       "      <td>1</td>\n",
       "      <td>1650.0</td>\n",
       "      <td>1650.0</td>\n",
       "      <td>None</td>\n",
       "      <td>819.403494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025</td>\n",
       "      <td>2</td>\n",
       "      <td>SC</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4321</td>\n",
       "      <td>29002</td>\n",
       "      <td>1</td>\n",
       "      <td>2300.0</td>\n",
       "      <td>2300.0</td>\n",
       "      <td>None</td>\n",
       "      <td>247.272091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025</td>\n",
       "      <td>2</td>\n",
       "      <td>MS</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>7231</td>\n",
       "      <td>45020</td>\n",
       "      <td>1</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>None</td>\n",
       "      <td>544.629439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025</td>\n",
       "      <td>2</td>\n",
       "      <td>DF</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5223</td>\n",
       "      <td>48071</td>\n",
       "      <td>1</td>\n",
       "      <td>1518.0</td>\n",
       "      <td>1518.0</td>\n",
       "      <td>None</td>\n",
       "      <td>392.977263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025</td>\n",
       "      <td>2</td>\n",
       "      <td>RS</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>8211</td>\n",
       "      <td>15020</td>\n",
       "      <td>1</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>None</td>\n",
       "      <td>570.385886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ano  trimestre sigla_uf sexo  idade raca_cor nivel_instrucao cod_ocupacao  \\\n",
       "0  2025          2       SP    1     18        1               4         5223   \n",
       "1  2025          2       SC    1     17        4               4         4321   \n",
       "2  2025          2       MS    1     18        2               5         7231   \n",
       "3  2025          2       DF    1     19        1               5         5223   \n",
       "4  2025          2       RS    1     18        4               5         8211   \n",
       "\n",
       "  grupamento_atividade posicao_ocupacao  rendimento_habitual  \\\n",
       "0                48030                1               1650.0   \n",
       "1                29002                1               2300.0   \n",
       "2                45020                1               1900.0   \n",
       "3                48071                1               1518.0   \n",
       "4                15020                1               2000.0   \n",
       "\n",
       "   rendimento_todos horas_trabalhadas        peso  \n",
       "0            1650.0              None  819.403494  \n",
       "1            2300.0              None  247.272091  \n",
       "2            1900.0              None  544.629439  \n",
       "3            1518.0              None  392.977263  \n",
       "4            2000.0              None  570.385886  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Etapa 1.2b - Preparação de Dados - Verificar dados microdados PNAD\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CHECKPOINT - Microdados PNAD\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nShape: {df_pnad_raw.shape}\")\n",
    "print(f\"Colunas: {list(df_pnad_raw.columns)}\")\n",
    "\n",
    "# UFs\n",
    "n_ufs = df_pnad_raw['sigla_uf'].nunique()\n",
    "print(f\"\\nUFs presentes: {n_ufs}\")\n",
    "if n_ufs != 27:\n",
    "    print(f\"  WARNING: Esperado 27 UFs, encontrado {n_ufs}\")\n",
    "\n",
    "# População\n",
    "pop_milhoes = df_pnad_raw['peso'].sum() / 1e6\n",
    "print(f\"População representada: {pop_milhoes:.1f} milhões\")\n",
    "\n",
    "# Linhas\n",
    "if len(df_pnad_raw) < 100_000:\n",
    "    print(f\"  WARNING: Apenas {len(df_pnad_raw):,} linhas (esperado > 100.000)\")\n",
    "\n",
    "# Tipos\n",
    "print(f\"\\nDtypes:\\n{df_pnad_raw.dtypes}\")\n",
    "\n",
    "# Amostra\n",
    "print(\"\\nPrimeiras linhas:\")\n",
    "df_pnad_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c102868b",
   "metadata": {},
   "source": [
    "### 3a. Processar índice de exposição ILO\n",
    "Lê a planilha ILO com scores de exposição por ISCO-08, padroniza e gera níveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67346cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lendo arquivo ILO: data/input/Final_Scores_ISCO08_Gmyrek_et_al_2025.xlsx\n",
      "Linhas raw (tarefas): 3,265\n",
      "Colunas disponíveis: ['label4d', 'label1d', 'ISCO_08', 'Title', 'taskID', 'Task_ISCO', 'score_2023', 'Weaviate Status', 'predicted_score_2025_gpt4o', 'prediction_justification_gpt4o', 'weaviate_status_gemini', 'predicted_score_2025_gemini', 'prediction_justification_gemini', 'score_2025', 'source', 'mean_score_2023', 'mean_score_2025', 'SD_2023', 'SD_2025', 'potential25', 'potential23']\n",
      "Colunas mapeadas: ['ISCO_08', 'Title', 'mean_score_2025', 'SD_2025', 'potential25']\n",
      "\n",
      "Ocupações únicas: 427\n",
      "Score médio: 0.297\n",
      "Score range: [0.090, 0.700]\n",
      "\n",
      "Salvo em: data/processed/ilo_exposure_clean.csv\n"
     ]
    }
   ],
   "source": [
    "# Etapa 1.3a - Preparação de Dados - Processar índice de exposição ILO\n",
    "\n",
    "print(f\"Lendo arquivo ILO: {ILO_FILE}\")\n",
    "df_ilo_raw = pd.read_excel(ILO_FILE)\n",
    "print(f\"Linhas raw (tarefas): {len(df_ilo_raw):,}\")\n",
    "print(f\"Colunas disponíveis: {list(df_ilo_raw.columns)}\")\n",
    "\n",
    "# Mapeamento de colunas\n",
    "col_mapping = {\n",
    "    'ISCO_08': 'isco_08',\n",
    "    'Title': 'occupation_title',\n",
    "    'mean_score_2025': 'exposure_score',\n",
    "    'SD_2025': 'exposure_sd',\n",
    "    'potential25': 'exposure_gradient',\n",
    "}\n",
    "\n",
    "available_cols = [c for c in col_mapping.keys() if c in df_ilo_raw.columns]\n",
    "print(f\"Colunas mapeadas: {available_cols}\")\n",
    "\n",
    "df_ilo_renamed = df_ilo_raw.rename(\n",
    "    columns={k: v for k, v in col_mapping.items() if k in df_ilo_raw.columns}\n",
    ")\n",
    "\n",
    "# Agregar por ocupação (arquivo original tem múltiplas tarefas por ocupação)\n",
    "df_ilo = df_ilo_renamed.groupby('isco_08').agg({\n",
    "    'occupation_title': 'first',\n",
    "    'exposure_score': 'mean',\n",
    "    'exposure_sd': 'mean',\n",
    "    'exposure_gradient': 'first',\n",
    "}).reset_index()\n",
    "\n",
    "# Garantir formato string com 4 dígitos\n",
    "df_ilo['isco_08_str'] = df_ilo['isco_08'].astype(str).str.zfill(4)\n",
    "\n",
    "print(f\"\\nOcupações únicas: {len(df_ilo):,}\")\n",
    "print(f\"Score médio: {df_ilo['exposure_score'].mean():.3f}\")\n",
    "print(f\"Score range: [{df_ilo['exposure_score'].min():.3f}, {df_ilo['exposure_score'].max():.3f}]\")\n",
    "\n",
    "# Salvar processado\n",
    "ilo_output = DATA_PROCESSED / \"ilo_exposure_clean.csv\"\n",
    "df_ilo.to_csv(ilo_output, index=False)\n",
    "print(f\"\\nSalvo em: {ilo_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d914cc02",
   "metadata": {},
   "source": [
    "### 3b. Verificar índice de exposição ILO\n",
    "Verificar: número de ocupações, coluna de score, distribuição por gradiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fae4169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CHECKPOINT - Índice ILO\n",
      "============================================================\n",
      "\n",
      "Ocupações: 427\n",
      "Score range: [0.090, 0.700]\n",
      "\n",
      "Distribuição por gradiente:\n",
      "  Not Exposed: 231 ocupações\n",
      "  Minimal Exposure: 84 ocupações\n",
      "  Exposed: Gradient 2: 44 ocupações\n",
      "  Exposed: Gradient 3: 38 ocupações\n",
      "  Exposed: Gradient 1: 17 ocupações\n",
      "  Exposed: Gradient 4: 13 ocupações\n",
      "\n",
      "Amostra (5 maiores scores):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isco_08_str</th>\n",
       "      <th>occupation_title</th>\n",
       "      <th>exposure_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>4132</td>\n",
       "      <td>Data Entry Clerks</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>4131</td>\n",
       "      <td>Typists and Word Processing Operators</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>4311</td>\n",
       "      <td>Accounting and Bookkeeping Clerks</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>4312</td>\n",
       "      <td>Statistical, Finance and Insurance Clerks</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>3311</td>\n",
       "      <td>Securities and Finance Dealers and Brokers</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    isco_08_str                            occupation_title  exposure_score\n",
       "207        4132                           Data Entry Clerks            0.70\n",
       "206        4131       Typists and Word Processing Operators            0.65\n",
       "220        4311           Accounting and Bookkeeping Clerks            0.64\n",
       "221        4312   Statistical, Finance and Insurance Clerks            0.64\n",
       "164        3311  Securities and Finance Dealers and Brokers            0.63"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Etapa 1.3b - Preparação de Dados - Verificar índice de exposição ILO\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CHECKPOINT - Índice ILO\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Número de ocupações\n",
    "n_ocup = len(df_ilo)\n",
    "print(f\"\\nOcupações: {n_ocup}\")\n",
    "if n_ocup < 400:\n",
    "    print(f\"  WARNING: Poucas ocupações ({n_ocup}). Esperado ~427.\")\n",
    "\n",
    "# Range de scores\n",
    "score_min = df_ilo['exposure_score'].min()\n",
    "score_max = df_ilo['exposure_score'].max()\n",
    "print(f\"Score range: [{score_min:.3f}, {score_max:.3f}]\")\n",
    "if score_min < 0 or score_max > 1:\n",
    "    print(f\"  WARNING: Scores fora do intervalo [0, 1]\")\n",
    "\n",
    "# Distribuição por gradiente\n",
    "print(\"\\nDistribuição por gradiente:\")\n",
    "for grad, count in df_ilo['exposure_gradient'].value_counts().items():\n",
    "    print(f\"  {grad}: {count} ocupações\")\n",
    "\n",
    "# Amostra\n",
    "print(\"\\nAmostra (5 maiores scores):\")\n",
    "df_ilo.nlargest(5, 'exposure_score')[['isco_08_str', 'occupation_title', 'exposure_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01ab1f0",
   "metadata": {},
   "source": [
    "### 4a. Limpeza e variáveis derivadas – PNAD\n",
    "\n",
    "Filtra população de interesse, cria variáveis derivadas (região, grandes grupos COD, quintis de renda, etc.) e padroniza códigos de ocupação.\n",
    "\n",
    "**Entrada:** `data/raw/pnad_*.parquet`.  \n",
    "**Saída:** `data/processed/pnad_clean.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a0dfa0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observações iniciais: 202,339\n",
      "Após remover missings críticos: 202,339 (100.0%)\n",
      "Após filtrar 18-65 anos: 192,245 (95.0%)\n",
      "Após remover ocupações inválidas: 192,235\n",
      "\n",
      "Taxa de formalidade: 38.2%\n",
      "Percentil 99 renda: R$ 21,500\n",
      "\n",
      "Salvo em: data/processed/pnad_clean.csv\n",
      "df_pnad: 192,235 linhas x 21 colunas\n"
     ]
    }
   ],
   "source": [
    "# Etapa 1.4a - Preparação de Dados - Limpeza e variáveis derivadas\n",
    "\n",
    "df_pnad = df_pnad_raw.copy()\n",
    "n_inicial = len(df_pnad)\n",
    "print(f\"Observações iniciais: {n_inicial:,}\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# LIMPEZA\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "# 1. Converter tipos\n",
    "df_pnad['cod_ocupacao'] = df_pnad['cod_ocupacao'].astype(str).str.zfill(4)\n",
    "df_pnad['idade'] = pd.to_numeric(df_pnad['idade'], errors='coerce')\n",
    "df_pnad['rendimento_habitual'] = pd.to_numeric(df_pnad['rendimento_habitual'], errors='coerce')\n",
    "df_pnad['peso'] = pd.to_numeric(df_pnad['peso'], errors='coerce')\n",
    "\n",
    "# 2. Remover missings críticos\n",
    "df_pnad = df_pnad.dropna(subset=['cod_ocupacao', 'idade', 'peso'])\n",
    "print(f\"Após remover missings críticos: {len(df_pnad):,} ({len(df_pnad)/n_inicial:.1%})\")\n",
    "\n",
    "# 3. Filtrar faixa etária (18-65)\n",
    "df_pnad = df_pnad[(df_pnad['idade'] >= 18) & (df_pnad['idade'] <= 65)]\n",
    "print(f\"Após filtrar 18-65 anos: {len(df_pnad):,} ({len(df_pnad)/n_inicial:.1%})\")\n",
    "\n",
    "# 4. Remover ocupações inválidas\n",
    "df_pnad = df_pnad[~df_pnad['cod_ocupacao'].isin(['0000', '9999'])]\n",
    "print(f\"Após remover ocupações inválidas: {len(df_pnad):,}\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# VARIÁVEIS DERIVADAS\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "# Formalidade\n",
    "df_pnad['formal'] = df_pnad['posicao_ocupacao'].astype(str).isin(POSICAO_FORMAL).astype(int)\n",
    "print(f\"\\nTaxa de formalidade: {df_pnad['formal'].mean():.1%}\")\n",
    "\n",
    "# Faixas etárias\n",
    "df_pnad['faixa_etaria'] = pd.cut(\n",
    "    df_pnad['idade'], bins=IDADE_BINS, labels=IDADE_LABELS\n",
    ")\n",
    "\n",
    "# Região\n",
    "df_pnad['regiao'] = df_pnad['sigla_uf'].map(REGIAO_MAP)\n",
    "\n",
    "# Raça agregada\n",
    "df_pnad['raca_agregada'] = df_pnad['raca_cor'].astype(str).map(RACA_AGREGADA_MAP)\n",
    "\n",
    "# Grande grupo ocupacional\n",
    "df_pnad['grande_grupo'] = df_pnad['cod_ocupacao'].str[0].map(GRANDES_GRUPOS)\n",
    "\n",
    "# Sexo como texto\n",
    "df_pnad['sexo_texto'] = df_pnad['sexo'].map({1: 'Homem', 2: 'Mulher', '1': 'Homem', '2': 'Mulher'})\n",
    "\n",
    "# Winsorização de renda (percentil 99)\n",
    "p99 = df_pnad['rendimento_habitual'].quantile(0.99)\n",
    "df_pnad['rendimento_winsor'] = df_pnad['rendimento_habitual'].clip(upper=p99)\n",
    "print(f\"Percentil 99 renda: R$ {p99:,.0f}\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# SALVAR\n",
    "# ---------------------------------------------------------------------------\n",
    "pnad_clean_path = DATA_PROCESSED / \"pnad_clean.csv\"\n",
    "df_pnad.to_csv(pnad_clean_path, index=False)\n",
    "print(f\"\\nSalvo em: {pnad_clean_path}\")\n",
    "print(f\"df_pnad: {df_pnad.shape[0]:,} linhas x {df_pnad.shape[1]} colunas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2021a5",
   "metadata": {},
   "source": [
    "### 4b. Verificar Limpeza e variáveis derivadas – PNAD\n",
    "Verificar: número de linhas, colunas criadas, valores faltantes em COD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7aca2b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CHECKPOINT - Limpeza PNAD\n",
      "============================================================\n",
      "\n",
      "Observações: 202,339 -> 192,235 (perda: 5.0%)\n",
      "  WARNING: grande_grupo tem 1,684 valores faltantes\n",
      "\n",
      "Ocupações únicas (COD): 431\n",
      "UFs: 27\n",
      "População representada: 94.9 milhões\n",
      "\n",
      "Distribuição por sexo:\n",
      "  Homem: 53.4 milhões\n",
      "  Mulher: 41.5 milhões\n",
      "\n",
      "Distribuição por região:\n",
      "  Sudeste: 42.9 milhões\n",
      "  Nordeste: 21.3 milhões\n",
      "  Sul: 15.2 milhões\n",
      "  Centro-Oeste: 8.3 milhões\n",
      "  Norte: 7.2 milhões\n",
      "\n",
      "Distribuição por faixa etária:\n",
      "faixa_etaria\n",
      "18-24    27371\n",
      "25-34    45008\n",
      "35-44    51730\n",
      "45-54    42650\n",
      "55+      25476\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Etapa 1.4b - Preparação de Dados - Verificar Limpeza e variáveis derivadas\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CHECKPOINT - Limpeza PNAD\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Perda de observações\n",
    "pct_perda = 1 - len(df_pnad) / n_inicial\n",
    "print(f\"\\nObservações: {n_inicial:,} -> {len(df_pnad):,} (perda: {pct_perda:.1%})\")\n",
    "if pct_perda > 0.20:\n",
    "    print(f\"  WARNING: Perda de {pct_perda:.1%} das observações (> 20%)\")\n",
    "\n",
    "# Missings em variáveis derivadas\n",
    "for col in ['regiao', 'raca_agregada', 'grande_grupo', 'faixa_etaria', 'sexo_texto']:\n",
    "    n_miss = df_pnad[col].isna().sum()\n",
    "    if n_miss > 0:\n",
    "        print(f\"  WARNING: {col} tem {n_miss:,} valores faltantes\")\n",
    "\n",
    "# Distribuição por sexo\n",
    "print(f\"\\nOcupações únicas (COD): {df_pnad['cod_ocupacao'].nunique()}\")\n",
    "print(f\"UFs: {df_pnad['sigla_uf'].nunique()}\")\n",
    "print(f\"População representada: {df_pnad['peso'].sum()/1e6:.1f} milhões\")\n",
    "\n",
    "print(\"\\nDistribuição por sexo:\")\n",
    "for sexo, peso in df_pnad.groupby('sexo_texto')['peso'].sum().items():\n",
    "    print(f\"  {sexo}: {peso/1e6:.1f} milhões\")\n",
    "\n",
    "print(\"\\nDistribuição por região:\")\n",
    "for regiao, peso in df_pnad.groupby('regiao')['peso'].sum().sort_values(ascending=False).items():\n",
    "    print(f\"  {regiao}: {peso/1e6:.1f} milhões\")\n",
    "\n",
    "print(\"\\nDistribuição por faixa etária:\")\n",
    "print(df_pnad['faixa_etaria'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c33c32",
   "metadata": {},
   "source": [
    "### 5a. Crosswalk COD → ISCO-08\n",
    "Mapear códigos de ocupação COD (PNAD) para ISCO-08 para permitir o merge com o índice ILO. Pode ser hierárquico (4 → 3 → 2 → 1 dígito) conforme implementado no script.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69e6612d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNAD: 192,235 observações\n",
      "ILO:  427 ocupações ISCO-08\n",
      "\n",
      "Códigos ILO: 4d=427, 3d=127, 2d=40, 1d=9\n",
      "\n",
      "Match 4-digit: 188,206 (97.9%)\n",
      "Match 3-digit: 2,345 (1.2%)\n",
      "Match 2-digit: 0 (0.0%)\n",
      "Match 1-digit: 0 (0.0%)\n",
      "Sem match:     1,684 (0.9%)\n"
     ]
    }
   ],
   "source": [
    "# Etapa 1.5a - Preparação de Dados - Crosswalk COD → ISCO-08\n",
    "\n",
    "# Garantir formatos string\n",
    "df_ilo['isco_08_str'] = df_ilo['isco_08_str'].astype(str).str.zfill(4)\n",
    "df_pnad['cod_ocupacao'] = df_pnad['cod_ocupacao'].astype(str).str.zfill(4)\n",
    "\n",
    "print(f\"PNAD: {len(df_pnad):,} observações\")\n",
    "print(f\"ILO:  {len(df_ilo):,} ocupações ISCO-08\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Criar dicionários de lookup em cada nível hierárquico\n",
    "# ---------------------------------------------------------------------------\n",
    "ilo_4d = df_ilo.groupby('isco_08_str')['exposure_score'].mean().to_dict()\n",
    "ilo_3d = df_ilo.groupby(df_ilo['isco_08_str'].str[:3])['exposure_score'].mean().to_dict()\n",
    "ilo_2d = df_ilo.groupby(df_ilo['isco_08_str'].str[:2])['exposure_score'].mean().to_dict()\n",
    "ilo_1d = df_ilo.groupby(df_ilo['isco_08_str'].str[:1])['exposure_score'].mean().to_dict()\n",
    "\n",
    "print(f\"\\nCódigos ILO: 4d={len(ilo_4d)}, 3d={len(ilo_3d)}, 2d={len(ilo_2d)}, 1d={len(ilo_1d)}\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Crosswalk hierárquico (4 → 3 → 2 → 1 dígito)\n",
    "# ---------------------------------------------------------------------------\n",
    "df_crosswalked = df_pnad.copy()\n",
    "df_crosswalked['exposure_score'] = np.nan\n",
    "df_crosswalked['match_level'] = None\n",
    "\n",
    "# Nível 4-digit\n",
    "mask_4d = df_crosswalked['cod_ocupacao'].isin(ilo_4d.keys())\n",
    "df_crosswalked.loc[mask_4d, 'exposure_score'] = df_crosswalked.loc[mask_4d, 'cod_ocupacao'].map(ilo_4d)\n",
    "df_crosswalked.loc[mask_4d, 'match_level'] = '4-digit'\n",
    "print(f\"\\nMatch 4-digit: {mask_4d.sum():,} ({mask_4d.mean():.1%})\")\n",
    "\n",
    "# Nível 3-digit\n",
    "mask_missing = df_crosswalked['exposure_score'].isna()\n",
    "cod_3d = df_crosswalked.loc[mask_missing, 'cod_ocupacao'].str[:3]\n",
    "mask_3d = cod_3d.isin(ilo_3d.keys())\n",
    "idx_3d = mask_missing[mask_missing].index[mask_3d.values]\n",
    "df_crosswalked.loc[idx_3d, 'exposure_score'] = cod_3d[mask_3d].map(ilo_3d).values\n",
    "df_crosswalked.loc[idx_3d, 'match_level'] = '3-digit'\n",
    "print(f\"Match 3-digit: {len(idx_3d):,} ({len(idx_3d)/len(df_crosswalked):.1%})\")\n",
    "\n",
    "# Nível 2-digit\n",
    "mask_missing = df_crosswalked['exposure_score'].isna()\n",
    "cod_2d = df_crosswalked.loc[mask_missing, 'cod_ocupacao'].str[:2]\n",
    "mask_2d = cod_2d.isin(ilo_2d.keys())\n",
    "idx_2d = mask_missing[mask_missing].index[mask_2d.values]\n",
    "df_crosswalked.loc[idx_2d, 'exposure_score'] = cod_2d[mask_2d].map(ilo_2d).values\n",
    "df_crosswalked.loc[idx_2d, 'match_level'] = '2-digit'\n",
    "print(f\"Match 2-digit: {len(idx_2d):,} ({len(idx_2d)/len(df_crosswalked):.1%})\")\n",
    "\n",
    "# Nível 1-digit\n",
    "mask_missing = df_crosswalked['exposure_score'].isna()\n",
    "cod_1d = df_crosswalked.loc[mask_missing, 'cod_ocupacao'].str[:1]\n",
    "mask_1d = cod_1d.isin(ilo_1d.keys())\n",
    "idx_1d = mask_missing[mask_missing].index[mask_1d.values]\n",
    "df_crosswalked.loc[idx_1d, 'exposure_score'] = cod_1d[mask_1d].map(ilo_1d).values\n",
    "df_crosswalked.loc[idx_1d, 'match_level'] = '1-digit'\n",
    "print(f\"Match 1-digit: {len(idx_1d):,} ({len(idx_1d)/len(df_crosswalked):.1%})\")\n",
    "\n",
    "# Sem match\n",
    "n_sem_match = df_crosswalked['exposure_score'].isna().sum()\n",
    "print(f\"Sem match:     {n_sem_match:,} ({n_sem_match/len(df_crosswalked):.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28851550",
   "metadata": {},
   "source": [
    "### 5a. Verificar Crosswalk COD → ISCO-08\n",
    "Verificar: cobertura do crosswalk (percentual de linhas com ISCO preenchido)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae624efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CHECKPOINT - Crosswalk COD → ISCO-08\n",
      "============================================================\n",
      "\n",
      "Cobertura total: 99.1%\n",
      "\n",
      "Distribuição por nível de match:\n",
      "  4-digit: 188,206 (97.9%)\n",
      "  3-digit: 2,345 (1.2%)\n",
      "\n",
      "Estatísticas do exposure_score:\n",
      "  Média:  0.267\n",
      "  Std:    0.145\n",
      "  Min:    0.090\n",
      "  Max:    0.700\n",
      "\n",
      "Exposição média por grande grupo (sanity check):\n",
      "  Apoio administrativo: 0.553\n",
      "  Dirigentes e gerentes: 0.400\n",
      "  Profissionais das ciências: 0.352\n",
      "  Técnicos nível médio: 0.345\n",
      "  Serviços e vendedores: 0.306\n",
      "  Operadores de máquinas: 0.223\n",
      "  Agropecuária qualificada: 0.174\n",
      "  Indústria qualificada: 0.152\n",
      "  Ocupações elementares: 0.131\n",
      "\n",
      "VALIDAÇÃO DE SANIDADE:\n",
      "  OK - Profissionais das ciências com exposição ALTA (0.352)\n",
      "  OK - Ocupações elementares com exposição BAIXA (0.131)\n"
     ]
    }
   ],
   "source": [
    "# Etapa 1.5b - Preparação de Dados - Verificar Crosswalk COD → ISCO-08\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CHECKPOINT - Crosswalk COD → ISCO-08\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Cobertura total\n",
    "coverage = df_crosswalked['exposure_score'].notna().mean()\n",
    "print(f\"\\nCobertura total: {coverage:.1%}\")\n",
    "if coverage < 0.90:\n",
    "    print(f\"  WARNING: Cobertura {coverage:.1%} abaixo de 90%\")\n",
    "\n",
    "# Distribuição por nível de match\n",
    "print(\"\\nDistribuição por nível de match:\")\n",
    "for level, count in df_crosswalked['match_level'].value_counts().items():\n",
    "    pct = count / len(df_crosswalked) * 100\n",
    "    print(f\"  {level}: {count:,} ({pct:.1f}%)\")\n",
    "\n",
    "# Estatísticas de score\n",
    "print(f\"\\nEstatísticas do exposure_score:\")\n",
    "print(f\"  Média:  {df_crosswalked['exposure_score'].mean():.3f}\")\n",
    "print(f\"  Std:    {df_crosswalked['exposure_score'].std():.3f}\")\n",
    "print(f\"  Min:    {df_crosswalked['exposure_score'].min():.3f}\")\n",
    "print(f\"  Max:    {df_crosswalked['exposure_score'].max():.3f}\")\n",
    "\n",
    "# Sanity check: exposição por grande grupo\n",
    "print(\"\\nExposição média por grande grupo (sanity check):\")\n",
    "exp_grupos = df_crosswalked.groupby('grande_grupo').apply(\n",
    "    lambda x: weighted_mean(x['exposure_score'].dropna(), x.loc[x['exposure_score'].notna(), 'peso'])\n",
    ").sort_values(ascending=False)\n",
    "\n",
    "for grupo, score in exp_grupos.items():\n",
    "    print(f\"  {grupo}: {score:.3f}\")\n",
    "\n",
    "# Validações de sanidade\n",
    "print(\"\\nVALIDAÇÃO DE SANIDADE:\")\n",
    "if 'Profissionais das ciências' in exp_grupos.index:\n",
    "    val = exp_grupos['Profissionais das ciências']\n",
    "    if val > 0.30:\n",
    "        print(f\"  OK - Profissionais das ciências com exposição ALTA ({val:.3f})\")\n",
    "    else:\n",
    "        print(f\"  WARNING: Profissionais das ciências com exposição BAIXA ({val:.3f}). Esperado > 0.30\")\n",
    "\n",
    "if 'Ocupações elementares' in exp_grupos.index:\n",
    "    val = exp_grupos['Ocupações elementares']\n",
    "    if val < 0.20:\n",
    "        print(f\"  OK - Ocupações elementares com exposição BAIXA ({val:.3f})\")\n",
    "    else:\n",
    "        print(f\"  WARNING: Ocupações elementares com exposição ALTA ({val:.3f}). Esperado < 0.20\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1e60d6",
   "metadata": {},
   "source": [
    "### 6. Merge final – PNAD + índice ILO\n",
    "Juntar a base PNAD (com ISCO-08) ao índice ILO por código de ocupação. Gera a base analítica final da Etapa 1.\n",
    "**Saída:** `data/output/pnad_ilo_merged.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "l5medrxgu7r",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribuição por gradiente:\n",
      "  Not Exposed: 41.5 milhões\n",
      "  Minimal Exposure: 21.1 milhões\n",
      "  Gradient 1-2: 18.1 milhões\n",
      "  Gradient 4 (Alta): 8.0 milhões\n",
      "  Gradient 3: 5.4 milhões\n",
      "  Sem classificação: 0.8 milhões\n",
      "\n",
      "============================================================\n",
      "BASE FINAL CONSOLIDADA\n",
      "============================================================\n",
      "Observações:       192,235\n",
      "Com score:         190,551\n",
      "Cobertura:         99.1%\n",
      "Colunas:           27\n",
      "População:         94.9 milhões\n",
      "Salvo em:          data/output/pnad_ilo_merged.csv\n",
      "Tamanho em disco:  32.9 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 192235 entries, 0 to 202220\n",
      "Data columns (total 27 columns):\n",
      " #   Column                Non-Null Count   Dtype   \n",
      "---  ------                --------------   -----   \n",
      " 0   ano                   192235 non-null  Int64   \n",
      " 1   trimestre             192235 non-null  Int64   \n",
      " 2   sigla_uf              192235 non-null  object  \n",
      " 3   regiao                192235 non-null  object  \n",
      " 4   sexo                  192235 non-null  object  \n",
      " 5   sexo_texto            192235 non-null  object  \n",
      " 6   idade                 192235 non-null  Int64   \n",
      " 7   faixa_etaria          192235 non-null  category\n",
      " 8   raca_cor              192235 non-null  object  \n",
      " 9   raca_agregada         192235 non-null  object  \n",
      " 10  nivel_instrucao       192235 non-null  object  \n",
      " 11  cod_ocupacao          192235 non-null  object  \n",
      " 12  grande_grupo          190551 non-null  object  \n",
      " 13  grupamento_atividade  192235 non-null  object  \n",
      " 14  setor_agregado        192235 non-null  object  \n",
      " 15  posicao_ocupacao      192235 non-null  object  \n",
      " 16  formal                192235 non-null  int64   \n",
      " 17  rendimento_habitual   192235 non-null  float64 \n",
      " 18  rendimento_winsor     192235 non-null  float64 \n",
      " 19  rendimento_todos      192199 non-null  float64 \n",
      " 20  horas_trabalhadas     58663 non-null   object  \n",
      " 21  peso                  192235 non-null  float64 \n",
      " 22  exposure_score        190551 non-null  float64 \n",
      " 23  exposure_gradient     192235 non-null  object  \n",
      " 24  match_level           190551 non-null  object  \n",
      " 25  quintil_exposure      190551 non-null  category\n",
      " 26  decil_exposure        190551 non-null  category\n",
      "dtypes: Int64(3), category(3), float64(5), int64(1), object(15)\n",
      "memory usage: 41.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# Etapa 1.6 - Preparação de Dados - Merge final PNAD + ILO\n",
    "\n",
    "df_final = df_crosswalked.copy()\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Classificação por gradiente ILO\n",
    "# ---------------------------------------------------------------------------\n",
    "def classify_gradient(score):\n",
    "    if pd.isna(score):\n",
    "        return 'Sem classificação'\n",
    "    elif score < 0.22:\n",
    "        return 'Not Exposed'\n",
    "    elif score < 0.36:\n",
    "        return 'Minimal Exposure'\n",
    "    elif score < 0.45:\n",
    "        return 'Gradient 1-2'\n",
    "    elif score < 0.55:\n",
    "        return 'Gradient 3'\n",
    "    else:\n",
    "        return 'Gradient 4 (Alta)'\n",
    "\n",
    "df_final['exposure_gradient'] = df_final['exposure_score'].apply(classify_gradient)\n",
    "\n",
    "print(\"Distribuição por gradiente:\")\n",
    "for grad, peso in df_final.groupby('exposure_gradient')['peso'].sum().sort_values(ascending=False).items():\n",
    "    print(f\"  {grad}: {peso/1e6:.1f} milhões\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Quintis e decis de exposição\n",
    "# ---------------------------------------------------------------------------\n",
    "mask_valid = df_final['exposure_score'].notna()\n",
    "\n",
    "df_final.loc[mask_valid, 'quintil_exposure'] = pd.qcut(\n",
    "    df_final.loc[mask_valid, 'exposure_score'],\n",
    "    q=5,\n",
    "    labels=['Q1 (Baixa)', 'Q2', 'Q3', 'Q4', 'Q5 (Alta)'],\n",
    "    duplicates='drop',\n",
    ")\n",
    "\n",
    "df_final.loc[mask_valid, 'decil_exposure'] = pd.qcut(\n",
    "    df_final.loc[mask_valid, 'exposure_score'],\n",
    "    q=10,\n",
    "    labels=[f'D{i}' for i in range(1, 11)],\n",
    "    duplicates='drop',\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Agregação setorial\n",
    "# ---------------------------------------------------------------------------\n",
    "setor_map = {\n",
    "    '01': 'Agropecuária', '02': 'Agropecuária', '03': 'Agropecuária',\n",
    "    '05': 'Indústria', '06': 'Indústria', '07': 'Indústria', '08': 'Indústria',\n",
    "    '10': 'Indústria', '11': 'Indústria', '12': 'Indústria', '13': 'Indústria',\n",
    "    '14': 'Indústria', '15': 'Indústria', '16': 'Indústria', '17': 'Indústria',\n",
    "    '18': 'Indústria', '19': 'Indústria', '20': 'Indústria', '21': 'Indústria',\n",
    "    '22': 'Indústria', '23': 'Indústria', '24': 'Indústria', '25': 'Indústria',\n",
    "    '26': 'Indústria', '27': 'Indústria', '28': 'Indústria', '29': 'Indústria',\n",
    "    '30': 'Indústria', '31': 'Indústria', '32': 'Indústria', '33': 'Indústria',\n",
    "    '41': 'Construção', '42': 'Construção', '43': 'Construção',\n",
    "    '45': 'Comércio', '46': 'Comércio', '47': 'Comércio',\n",
    "    '49': 'Serviços', '50': 'Serviços', '51': 'Serviços', '52': 'Serviços',\n",
    "    '53': 'Serviços', '55': 'Serviços', '56': 'Serviços',\n",
    "    '58': 'TIC e Serviços Prof.', '59': 'TIC e Serviços Prof.', '60': 'TIC e Serviços Prof.',\n",
    "    '61': 'TIC e Serviços Prof.', '62': 'TIC e Serviços Prof.', '63': 'TIC e Serviços Prof.',\n",
    "    '64': 'TIC e Serviços Prof.', '65': 'TIC e Serviços Prof.', '66': 'TIC e Serviços Prof.',\n",
    "    '69': 'TIC e Serviços Prof.', '70': 'TIC e Serviços Prof.', '71': 'TIC e Serviços Prof.',\n",
    "    '72': 'TIC e Serviços Prof.', '73': 'TIC e Serviços Prof.', '74': 'TIC e Serviços Prof.',\n",
    "    '75': 'TIC e Serviços Prof.',\n",
    "    '84': 'Administração Pública',\n",
    "    '85': 'Educação',\n",
    "    '86': 'Saúde', '87': 'Saúde', '88': 'Saúde',\n",
    "}\n",
    "\n",
    "df_final['cnae_2d'] = df_final['grupamento_atividade'].astype(str).str[:2]\n",
    "df_final['setor_agregado'] = df_final['cnae_2d'].map(setor_map).fillna('Outros Serviços')\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Selecionar colunas finais e salvar\n",
    "# ---------------------------------------------------------------------------\n",
    "cols_output = [\n",
    "    'ano', 'trimestre', 'sigla_uf', 'regiao',\n",
    "    'sexo', 'sexo_texto', 'idade', 'faixa_etaria',\n",
    "    'raca_cor', 'raca_agregada', 'nivel_instrucao',\n",
    "    'cod_ocupacao', 'grande_grupo',\n",
    "    'grupamento_atividade', 'setor_agregado',\n",
    "    'posicao_ocupacao', 'formal',\n",
    "    'rendimento_habitual', 'rendimento_winsor', 'rendimento_todos',\n",
    "    'horas_trabalhadas', 'peso',\n",
    "    'exposure_score', 'exposure_gradient', 'match_level',\n",
    "    'quintil_exposure', 'decil_exposure',\n",
    "]\n",
    "\n",
    "df_final = df_final[[c for c in cols_output if c in df_final.columns]]\n",
    "\n",
    "output_path = DATA_OUTPUT / \"pnad_ilo_merged.csv\"\n",
    "df_final.to_csv(output_path, index=False)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Resumo final\n",
    "# ---------------------------------------------------------------------------\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"BASE FINAL CONSOLIDADA\")\n",
    "print(f\"{'=' * 60}\")\n",
    "print(f\"Observações:       {len(df_final):,}\")\n",
    "print(f\"Com score:         {df_final['exposure_score'].notna().sum():,}\")\n",
    "print(f\"Cobertura:         {df_final['exposure_score'].notna().mean():.1%}\")\n",
    "print(f\"Colunas:           {df_final.shape[1]}\")\n",
    "print(f\"População:         {df_final['peso'].sum()/1e6:.1f} milhões\")\n",
    "print(f\"Salvo em:          {output_path}\")\n",
    "print(f\"Tamanho em disco:  {output_path.stat().st_size / 1e6:.1f} MB\")\n",
    "\n",
    "df_final.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
