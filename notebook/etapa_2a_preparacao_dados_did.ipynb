{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6ac33147",
      "metadata": {},
      "source": [
        "# ETAPA 2a — Preparação do Painel CAGED + ILO Exposure Index\n",
        "\n",
        "**Dissertação:** Inteligência Artificial Generativa e o Mercado de Trabalho Brasileiro: Uma Análise de Exposição Ocupacional e seus Efeitos Distributivos.\n",
        "\n",
        "**Aluno:** Manoel Brasil Orlandi\n",
        "\n",
        "---\n",
        "\n",
        "### Contextualização\n",
        "\n",
        "A rápida difusão de modelos de IA generativa (LLMs, geradores de imagem/código) levanta questões centrais sobre seus impactos no mercado de trabalho. Para mensurar esse potencial de impacto, a Organização Internacional do Trabalho (OIT) criou um índice de exposição ocupacional à IA generativa, publicado como *Working Paper* 140 (WP140). O índice atribui scores de exposição a cada ocupação da classificação ISCO-08, com base na avaliação de suas tarefas constituintes por modelos de linguagem e validação humana.\n",
        "\n",
        "Este notebook prepara uma base de dados que junta os dados do **Novo CAGED** (Cadastro Geral de Empregados e Desempregados) ao **índice de exposição à IA generativa da OIT**, para ser usado em um modelo de Diferenças-em-Diferenças (DiD) no Notebook 2b.\n",
        "\n",
        "### Objetivo\n",
        "\n",
        "Construir o **painel mensal de ocupações formais brasileiras (2021–2025)** a partir do Novo CAGED, realizar o **crosswalk CBO 2002 → ISCO-08** (especificação dual: 2 dígitos como principal, 4 dígitos para robustez), e fazer o merge com o índice de exposição à IA generativa da OIT (Gmyrek, Berg & Cappelli, 2025). O output final é um dataset analítico pronto para a estimação DiD.\n",
        "\n",
        "**Estratégia de crosswalk:** Análise principal a **2 dígitos** ISCO-08 (match por Sub-major Group com fallback hierárquico a Major Group), com robustez a **4 dígitos** via correspondência ISCO-88 ↔ ISCO-08 + fallback hierárquico em 6 níveis.\n",
        "\n",
        "**Inspiração metodológica:** Hui, Reshef & Zhou (2024), \"The Short-Term Effects of Generative Artificial Intelligence on Employment: Evidence from an Online Labor Market\" — adaptado para dados administrativos brasileiros (CAGED) com o índice ILO de exposição ocupacional.\n",
        "\n",
        "### Ficha Técnica dos Dados\n",
        "\n",
        "| Item | Descrição |\n",
        "|------|-----------|\n",
        "| **Fonte CAGED** | Ministério do Trabalho e Emprego (MTE), via Base dos Dados (BigQuery) |\n",
        "| **Dataset BigQuery** | `basedosdados.br_me_caged.microdados_movimentacao` |\n",
        "| **Período** | Janeiro/2021 — Dezembro/2025 (60 meses) |\n",
        "| **Unidade** | Movimentação individual (admissão ou desligamento) |\n",
        "| **Cobertura** | Emprego formal (CLT) em todo o Brasil |\n",
        "| **Índice ILO** | `ilo_exposure_clean.csv` — 427 ocupações ISCO-08 com exposure scores |\n",
        "| **Classificação** | CBO 2002 (CAGED) → ISCO-08 (ILO) via crosswalk hierárquico |\n",
        "\n",
        "### Referências principais\n",
        "- Gmyrek, P., Berg, J. & Cappelli, D. (2025). *Generative AI and Jobs: An updated global assessment*. ILO Working Paper 140.\n",
        "- Hui, X., Reshef, O. & Zhou, L. (2024). *The Short-Term Effects of Generative AI on Employment*. Organization Science, 35(6).\n",
        "- Brynjolfsson, E., Chandar, P. & Chen, J. (2025). *Canaries in the Coal Mine? Six Facts about the Recent Employment Effects of AI*.\n",
        "- Callaway, B. & Sant'Anna, P. (2021). *Difference-in-differences with multiple time periods*. Journal of Econometrics, 225(2).\n",
        "- Muendler, M.-A. & Poole, J.P. (2004). *Job Concordances for Brazil: Mapping CBO to ISCO-88*. UC San Diego.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "893a125d",
      "metadata": {},
      "source": [
        "### 1. Configuração do ambiente\n",
        "\n",
        "Definir caminhos, importar bibliotecas e configurar parâmetros do painel. Todos os caminhos são relativos ao diretório `notebook/`.\n",
        "\n",
        "> **Nota sobre a janela temporal:** Excluímos 2020 para evitar os efeitos distorcivos da pandemia de COVID-19 sobre o mercado de trabalho formal. O ano de 2020 apresentou quedas e recuperações atípicas que contaminariam o período pré-tratamento do DiD. A janela Jan/2021–Dez/2025 oferece 23 meses pré-ChatGPT e 31 meses pós.\n",
        "\n",
        "> **Nota sobre o Novo CAGED:** A partir de janeiro/2020, o CAGED foi substituído pelo sistema eSocial (Portaria SEPRT 1.127/2019). Usamos dados de 2021+ para consistência metodológica (eSocial já estabilizado)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "02d36db5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuração carregada.\n",
            "  Período: 2021–2025 (60 meses)\n",
            "  Evento: ChatGPT — Nov/2022 (pós a partir de 12/2022)\n",
            "  Projeto GCP: mestrado-pnad-2026\n",
            "  ILO file: data/processed/ilo_exposure_clean.csv (existe: True)\n"
          ]
        }
      ],
      "source": [
        "# Etapa 2a.1 — Configuração do ambiente\n",
        "\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# Caminhos (relativos ao diretório do notebook)\n",
        "# ---------------------------------------------------------------------------\n",
        "DATA_INPUT     = Path(\"data/input\")\n",
        "DATA_RAW       = Path(\"data/raw\")\n",
        "DATA_PROCESSED = Path(\"data/processed\")\n",
        "DATA_OUTPUT    = Path(\"data/output\")\n",
        "\n",
        "for d in [DATA_INPUT, DATA_RAW, DATA_PROCESSED, DATA_OUTPUT]:\n",
        "    d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# Parâmetros do Painel CAGED\n",
        "# ---------------------------------------------------------------------------\n",
        "GCP_PROJECT_ID = \"mestrado-pnad-2026\"\n",
        "\n",
        "ANO_INICIO     = 2021\n",
        "ANO_FIM        = 2025\n",
        "ANO_TRATAMENTO = 2022\n",
        "MES_TRATAMENTO = 12   # Dezembro/2022 como primeiro mês \"pós\"\n",
        "\n",
        "SALARIO_MINIMO = {\n",
        "    2021: 1100, 2022: 1212, 2023: 1320, 2024: 1412, 2025: 1518\n",
        "}\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# Colunas a selecionar do CAGED (BigQuery)\n",
        "# ---------------------------------------------------------------------------\n",
        "COLUNAS_CAGED = \"\"\"\n",
        "    ano, mes, sigla_uf, id_municipio, cbo_2002,\n",
        "    categoria, tipo_movimentacao, saldo_movimentacao,\n",
        "    salario_mensal, grau_instrucao, idade, sexo, raca_cor,\n",
        "    cnae_2_secao, cnae_2_subclasse, tamanho_estabelecimento_janeiro\n",
        "\"\"\"\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# Arquivos de referência\n",
        "# ---------------------------------------------------------------------------\n",
        "ILO_FILE               = DATA_PROCESSED / \"ilo_exposure_clean.csv\"\n",
        "ISCO_08_88_FILE        = DATA_INPUT / \"Correspondência ISCO 08 a 88.xlsx\"\n",
        "ISCO_08_ESTRUTURA_FILE = DATA_INPUT / \"ISCO 08 Estruturas e Definições.xlsx\"\n",
        "MUENDLER_FILE          = DATA_INPUT / \"cbo-isco-conc.csv\"\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# Checkpoints intermediários\n",
        "# ---------------------------------------------------------------------------\n",
        "PAINEL_MENSAL_FILE     = DATA_PROCESSED / \"painel_caged_mensal.parquet\"\n",
        "PAINEL_CROSSWALK_FILE  = DATA_PROCESSED / \"painel_caged_crosswalk.parquet\"\n",
        "PAINEL_TRATAMENTO_FILE = DATA_PROCESSED / \"painel_caged_tratamento.parquet\"\n",
        "PAINEL_FINAL_PARQUET   = DATA_OUTPUT / \"painel_caged_did_ready.parquet\"\n",
        "PAINEL_FINAL_CSV       = DATA_OUTPUT / \"painel_caged_did_ready.csv\"\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# Grandes grupos CBO (para sanity checks)\n",
        "# ---------------------------------------------------------------------------\n",
        "GRANDES_GRUPOS_CBO = {\n",
        "    '0': 'Forças Armadas',\n",
        "    '1': 'Dirigentes',\n",
        "    '2': 'Profissionais das ciências',\n",
        "    '3': 'Técnicos nível médio',\n",
        "    '4': 'Trabalhadores de serv. admin.',\n",
        "    '5': 'Trabalhadores de serviços/comércio',\n",
        "    '6': 'Agropecuária',\n",
        "    '7': 'Produção industrial',\n",
        "    '8': 'Operadores de máquinas',\n",
        "    '9': 'Manutenção e reparação',\n",
        "}\n",
        "\n",
        "print(\"Configuração carregada.\")\n",
        "print(f\"  Período: {ANO_INICIO}–{ANO_FIM} ({(ANO_FIM - ANO_INICIO + 1) * 12} meses)\")\n",
        "print(f\"  Evento: ChatGPT — Nov/2022 (pós a partir de {MES_TRATAMENTO}/{ANO_TRATAMENTO})\")\n",
        "print(f\"  Projeto GCP: {GCP_PROJECT_ID}\")\n",
        "print(f\"  ILO file: {ILO_FILE} (existe: {ILO_FILE.exists()})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd90657e",
      "metadata": {},
      "source": [
        "### 2a. Download dos microdados CAGED\n",
        "\n",
        "Extrair do Novo CAGED (BigQuery/Base dos Dados) todas as movimentações de emprego formal no período 2021–2025.\n",
        "\n",
        "| Item | Descrição |\n",
        "|------|-----------|\n",
        "| **Tabela BigQuery** | `basedosdados.br_me_caged.microdados_movimentacao` |\n",
        "| **Período** | 2021-01 a 2025-12 |\n",
        "| **Filtros** | `ano BETWEEN 2021 AND 2025` |\n",
        "| **Volume estimado** | ~20-30M de registros por ano, ~100-150M total |\n",
        "| **Estratégia** | Download ano a ano via `google-cloud-bigquery` (Storage API) com fallback para `basedosdados` |\n",
        "\n",
        "> **Nota metodológica — Volume de dados:** O CAGED registra ~20-25 milhões de movimentações/ano. Para 5 anos, esperamos ~100-125M de registros. O download é feito ano a ano para evitar OOM e timeout, com salvamento em parquets individuais (`caged_{ano}.parquet`).\n",
        "\n",
        "> **Nota sobre otimização:** Usamos a BigQuery Storage API (`create_bqstorage_client=True`) que transfere dados via gRPC/Arrow, sendo 2-5x mais rápida que o método padrão REST. Se o arquivo parquet já existir, o download é pulado automaticamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "451ca3b3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Download dos microdados CAGED:\n",
            "  2021: Carregado do cache — 36,554,795 registros (384 MB)\n",
            "  2022: Carregado do cache — 42,475,516 registros (445 MB)\n",
            "  2023: Carregado do cache — 44,485,982 registros (466 MB)\n",
            "  2024: Carregado do cache — 48,996,040 registros (511 MB)\n",
            "  2025: Carregado do cache — 26,312,103 registros (269 MB)\n",
            "\n",
            "Total: 198,824,436 movimentações (2021–2025)\n",
            "Colunas: ['ano', 'mes', 'sigla_uf', 'id_municipio', 'cbo_2002', 'categoria', 'tipo_movimentacao', 'saldo_movimentacao', 'salario_mensal', 'grau_instrucao', 'idade', 'sexo', 'raca_cor', 'cnae_2_secao', 'cnae_2_subclasse', 'tamanho_estabelecimento_janeiro']\n"
          ]
        }
      ],
      "source": [
        "# Etapa 2a.2a — Download dos microdados CAGED\n",
        "# Estratégia: download ano a ano via BigQuery Storage API, com cache local em parquet.\n",
        "\n",
        "from google.cloud import bigquery\n",
        "\n",
        "def download_caged_ano(ano):\n",
        "    \"\"\"Baixar microdados CAGED de um ano via BigQuery Storage API.\"\"\"\n",
        "    parquet_path = DATA_RAW / f\"caged_{ano}.parquet\"\n",
        "\n",
        "    if parquet_path.exists():\n",
        "        size_mb = parquet_path.stat().st_size / 1e6\n",
        "        df = pd.read_parquet(parquet_path)\n",
        "        print(f\"  {ano}: Carregado do cache — {len(df):,} registros ({size_mb:.0f} MB)\")\n",
        "        return df\n",
        "\n",
        "    print(f\"  {ano}: Baixando do BigQuery...\", end=\"\", flush=True)\n",
        "    query = f\"\"\"\n",
        "    SELECT {COLUNAS_CAGED}\n",
        "    FROM `basedosdados.br_me_caged.microdados_movimentacao`\n",
        "    WHERE ano = {ano}\n",
        "    \"\"\"\n",
        "    client = bigquery.Client(project=GCP_PROJECT_ID)\n",
        "    df = client.query(query).to_dataframe(create_bqstorage_client=True)\n",
        "    df.to_parquet(parquet_path, index=False)\n",
        "    size_mb = parquet_path.stat().st_size / 1e6\n",
        "    print(f\" {len(df):,} registros ({size_mb:.0f} MB)\")\n",
        "    return df\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# Download ano a ano\n",
        "# ---------------------------------------------------------------------------\n",
        "print(\"Download dos microdados CAGED:\")\n",
        "dfs_anuais = []\n",
        "for ano in range(ANO_INICIO, ANO_FIM + 1):\n",
        "    df_ano = download_caged_ano(ano)\n",
        "    dfs_anuais.append(df_ano)\n",
        "\n",
        "# Resumo (sem concatenar em memória para evitar OOM)\n",
        "total = sum(len(df) for df in dfs_anuais)\n",
        "print(f\"\\nTotal: {total:,} movimentações ({ANO_INICIO}–{ANO_FIM})\")\n",
        "print(f\"Colunas: {list(dfs_anuais[0].columns)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4e45e2f",
      "metadata": {},
      "source": [
        "### 2b. Verificar dados CAGED (CHECKPOINT)\n",
        "\n",
        "Verificar integridade dos dados baixados: cobertura temporal (12 meses/ano), volume por ano, preenchimento de variáveis-chave, e formato dos códigos CBO.\n",
        "\n",
        "**Critérios de aceite:**\n",
        "- Todos os meses cobertos (Jan–Dez) para cada ano\n",
        "- CBO com >95% de preenchimento\n",
        "- ~20-30M registros por ano\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "63efdd50",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "CHECKPOINT — Microdados CAGED\n",
            "============================================================\n",
            "\n",
            "--- 2021: 36,554,795 movimentações ---\n",
            "  Meses: 12 (OK)\n",
            "  CBO preenchido: 100.0%\n",
            "  Famílias CBO 4d únicas: 626\n",
            "  Admissões: 19,703,604 | Desligamentos: 16,851,191 | Saldo: +2,852,413\n",
            "\n",
            "--- 2022: 42,475,516 movimentações ---\n",
            "  Meses: 12 (OK)\n",
            "  CBO preenchido: 100.0%\n",
            "  Famílias CBO 4d únicas: 624\n",
            "  Admissões: 22,243,441 | Desligamentos: 20,232,075 | Saldo: +2,011,366\n",
            "\n",
            "--- 2023: 44,485,982 movimentações ---\n",
            "  Meses: 12 (OK)\n",
            "  CBO preenchido: 100.0%\n",
            "  Famílias CBO 4d únicas: 626\n",
            "  Admissões: 22,982,161 | Desligamentos: 21,503,821 | Saldo: +1,478,340\n",
            "\n",
            "--- 2024: 48,996,040 movimentações ---\n",
            "  Meses: 12 (OK)\n",
            "  CBO preenchido: 100.0%\n",
            "  Famílias CBO 4d únicas: 625\n",
            "  Admissões: 25,336,277 | Desligamentos: 23,659,763 | Saldo: +1,676,514\n",
            "\n",
            "--- 2025: 26,312,103 movimentações ---\n",
            "  Meses: 6 (ALERTA: 6 meses)\n",
            "  CBO preenchido: 100.0%\n",
            "  Famílias CBO 4d únicas: 622\n",
            "  Admissões: 13,763,059 | Desligamentos: 12,549,044 | Saldo: +1,214,015\n",
            "\n",
            "============================================================\n",
            "TOTAL: 198,824,436 movimentações (2021–2025)\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Etapa 2a.2b — CHECKPOINT: Verificar dados CAGED\n",
        "# Carrega cada parquet individualmente (para evitar OOM)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"CHECKPOINT — Microdados CAGED\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "total_registros = 0\n",
        "for ano in range(ANO_INICIO, ANO_FIM + 1):\n",
        "    parquet_path = DATA_RAW / f\"caged_{ano}.parquet\"\n",
        "    df = pd.read_parquet(parquet_path)\n",
        "\n",
        "    # Volume\n",
        "    print(f\"\\n--- {ano}: {len(df):,} movimentações ---\")\n",
        "    total_registros += len(df)\n",
        "\n",
        "    # Cobertura mensal\n",
        "    meses = sorted(df['mes'].dropna().unique())\n",
        "    status = \"OK\" if len(meses) == 12 else f\"ALERTA: {len(meses)} meses\"\n",
        "    print(f\"  Meses: {len(meses)} ({status})\")\n",
        "\n",
        "    # Preenchimento CBO\n",
        "    cbo_pct = df['cbo_2002'].notna().mean()\n",
        "    print(f\"  CBO preenchido: {cbo_pct:.1%}\")\n",
        "\n",
        "    # CBOs únicos\n",
        "    cbos = df['cbo_2002'].dropna().astype(str).str[:4].nunique()\n",
        "    print(f\"  Famílias CBO 4d únicas: {cbos}\")\n",
        "\n",
        "    # Admissões vs desligamentos\n",
        "    if 'saldo_movimentacao' in df.columns:\n",
        "        adm = (df['saldo_movimentacao'] == 1).sum()\n",
        "        desl = (df['saldo_movimentacao'] == -1).sum()\n",
        "        print(f\"  Admissões: {adm:,} | Desligamentos: {desl:,} | Saldo: {adm-desl:+,}\")\n",
        "\n",
        "print(f\"\\n{'=' * 60}\")\n",
        "print(f\"TOTAL: {total_registros:,} movimentações ({ANO_INICIO}–{ANO_FIM})\")\n",
        "print(f\"{'=' * 60}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1201bac",
      "metadata": {},
      "source": [
        "### 3a. Agregação: Microdados → Painel Mensal por Ocupação\n",
        "\n",
        "Agregar os microdados de movimentação (nível individual) em um painel mensal por ocupação CBO (4 dígitos). Cada linha do painel representará uma ocupação-mês com métricas agregadas.\n",
        "\n",
        "#### Estratégia de agregação\n",
        "\n",
        "Seguindo a abordagem de Hui, Reshef & Zhou (2024), construímos um painel ao nível de **ocupação × mês** com as seguintes métricas:\n",
        "\n",
        "| Métrica | Cálculo | Descrição |\n",
        "|---------|---------|-----------|\n",
        "| `admissoes` | Contagem de `saldo_movimentacao == 1` | Fluxo de contratação |\n",
        "| `desligamentos` | Contagem de `saldo_movimentacao == -1` | Fluxo de demissão |\n",
        "| `saldo` | `admissoes - desligamentos` | Criação líquida de empregos |\n",
        "| `salario_medio_adm` | Média do `salario_mensal` (admissões) | Nível salarial |\n",
        "| `salario_mediano_adm` | Mediana do `salario_mensal` (admissões) | Robustez a outliers |\n",
        "| `pct_mulher_adm` | % de `sexo == 3` nas admissões | Composição de gênero |\n",
        "| `pct_superior_adm` | % com `grau_instrucao >= 9` | Composição educacional |\n",
        "\n",
        "> **Nota — CBO 4 dígitos:** A CBO tem 6 dígitos (XXXX-XX), onde os 4 primeiros definem a \"família\" ocupacional. Para o crosswalk com ISCO-08, usamos os 4 primeiros dígitos (família CBO ≈ unit group ISCO-08).\n",
        "\n",
        "> **Nota — Otimização de memória:** O processamento é feito ano a ano para evitar OOM (Out-of-Memory) com ~100M+ registros. Flags booleanos são pré-computados como float para permitir agregação vetorizada (evitando lambdas lentas). A mediana é calculada separadamente por ser computacionalmente cara.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "cea3a3ad",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Painel carregado do checkpoint: painel_caged_mensal.parquet\n",
            "  32,988 linhas, 629 ocupações, 54 períodos\n",
            "\n",
            "Painel final: 32,988 linhas\n",
            "  Ocupações: 629, Períodos: 54\n",
            "  Shape: (32988, 20)\n"
          ]
        }
      ],
      "source": [
        "# Etapa 2a.3a — Agregação: Microdados → Painel Mensal por Ocupação\n",
        "# Checkpoint: se o painel já existe, carrega direto.\n",
        "\n",
        "if PAINEL_MENSAL_FILE.exists():\n",
        "    painel = pd.read_parquet(PAINEL_MENSAL_FILE)\n",
        "    print(f\"Painel carregado do checkpoint: {PAINEL_MENSAL_FILE.name}\")\n",
        "    print(f\"  {len(painel):,} linhas, {painel['cbo_4d'].nunique()} ocupações, \"\n",
        "          f\"{painel['periodo'].nunique()} períodos\")\n",
        "else:\n",
        "    print(\"Construindo painel a partir dos microdados (ano a ano)...\")\n",
        "    paineis_anuais = []\n",
        "\n",
        "    for ano in range(ANO_INICIO, ANO_FIM + 1):\n",
        "        print(f\"\\n  Processando {ano}...\", flush=True)\n",
        "        df = pd.read_parquet(DATA_RAW / f\"caged_{ano}.parquet\")\n",
        "\n",
        "        # CBO 4 dígitos\n",
        "        df['cbo_2002'] = df['cbo_2002'].astype(str).str.strip()\n",
        "        df['cbo_4d'] = df['cbo_2002'].str[:4]\n",
        "        df = df[df['cbo_4d'].str.len() == 4]\n",
        "        df = df[df['cbo_4d'].str.isdigit()]\n",
        "        df = df[~df['cbo_4d'].isin(['0000'])]\n",
        "\n",
        "        # Variáveis temporais\n",
        "        df['periodo'] = df['ano'].astype(str) + '-' + df['mes'].astype(str).str.zfill(2)\n",
        "        df['periodo_num'] = df['ano'].astype(int) * 100 + df['mes'].astype(int)\n",
        "        df['post'] = (df['periodo_num'] >= ANO_TRATAMENTO * 100 + MES_TRATAMENTO).astype(int)\n",
        "\n",
        "        # Flags booleanos pré-computados (para agregação vetorizada)\n",
        "        df['is_mulher'] = (df['sexo'] == 3).astype(float)\n",
        "        df['is_superior'] = df['grau_instrucao'].astype(str).isin(\n",
        "            ['9', '10', '11', '12', '13']\n",
        "        ).astype(float)\n",
        "\n",
        "        # Separar admissões e desligamentos\n",
        "        df_adm = df[df['saldo_movimentacao'] == 1]\n",
        "        df_desl = df[df['saldo_movimentacao'] == -1]\n",
        "        print(f\"    {ano}: {len(df_adm):,} admissões, {len(df_desl):,} desligamentos\", flush=True)\n",
        "\n",
        "        # Agregar admissões (sem lambdas — vetorizado)\n",
        "        painel_adm = df_adm.groupby(['cbo_4d', 'ano', 'mes']).agg(\n",
        "            admissoes=('saldo_movimentacao', 'count'),\n",
        "            salario_medio_adm=('salario_mensal', 'mean'),\n",
        "            idade_media_adm=('idade', 'mean'),\n",
        "            pct_mulher_adm=('is_mulher', 'mean'),\n",
        "            pct_superior_adm=('is_superior', 'mean'),\n",
        "        ).reset_index()\n",
        "\n",
        "        # Mediana separada (performance)\n",
        "        mediana = df_adm.groupby(['cbo_4d', 'ano', 'mes'])['salario_mensal'].median().reset_index()\n",
        "        mediana.columns = ['cbo_4d', 'ano', 'mes', 'salario_mediano_adm']\n",
        "        painel_adm = painel_adm.merge(mediana, on=['cbo_4d', 'ano', 'mes'], how='left')\n",
        "\n",
        "        # Agregar desligamentos\n",
        "        painel_desl = df_desl.groupby(['cbo_4d', 'ano', 'mes']).agg(\n",
        "            desligamentos=('saldo_movimentacao', 'count'),\n",
        "            salario_medio_desl=('salario_mensal', 'mean'),\n",
        "        ).reset_index()\n",
        "\n",
        "        # Merge\n",
        "        p = painel_adm.merge(painel_desl, on=['cbo_4d', 'ano', 'mes'], how='outer').fillna(0)\n",
        "        p['saldo'] = p['admissoes'] - p['desligamentos']\n",
        "        p['n_movimentacoes'] = p['admissoes'] + p['desligamentos']\n",
        "        p['periodo'] = p['ano'].astype(int).astype(str) + '-' + p['mes'].astype(int).astype(str).str.zfill(2)\n",
        "        p['periodo_num'] = p['ano'].astype(int) * 100 + p['mes'].astype(int)\n",
        "        p['post'] = (p['periodo_num'] >= ANO_TRATAMENTO * 100 + MES_TRATAMENTO).astype(int)\n",
        "        p['ln_admissoes'] = np.log(p['admissoes'] + 1)\n",
        "        p['ln_desligamentos'] = np.log(p['desligamentos'] + 1)\n",
        "        p['ln_salario_adm'] = np.log(p['salario_medio_adm'].clip(lower=1))\n",
        "        p['cbo_2d'] = p['cbo_4d'].str[:2]\n",
        "\n",
        "        paineis_anuais.append(p)\n",
        "        print(f\"    → {len(p):,} linhas no painel\", flush=True)\n",
        "\n",
        "    painel = pd.concat(paineis_anuais, ignore_index=True)\n",
        "    painel.to_parquet(PAINEL_MENSAL_FILE, index=False)\n",
        "    print(f\"\\nPainel salvo: {PAINEL_MENSAL_FILE.name}\")\n",
        "\n",
        "print(f\"\\nPainel final: {len(painel):,} linhas\")\n",
        "print(f\"  Ocupações: {painel['cbo_4d'].nunique()}, Períodos: {painel['periodo'].nunique()}\")\n",
        "print(f\"  Shape: {painel.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1e75561",
      "metadata": {},
      "source": [
        "### 3b. Verificar painel agregado (CHECKPOINT)\n",
        "\n",
        "Verificar integridade do painel: dimensões, balanceamento (ocupações × períodos), cobertura temporal, distribuição de variáveis-chave e série temporal agregada.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f3b53806",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "CHECKPOINT — Painel Ocupação × Mês\n",
            "============================================================\n",
            "\n",
            "Ocupações: 629\n",
            "Períodos: 54\n",
            "Painel teórico (balanceado): 33,966\n",
            "Painel real: 32,988\n",
            "Balanceamento: 97.1%\n",
            "\n",
            "Meses por ocupação:\n",
            "  Min: 2, Max: 54, Média: 52.4\n",
            "  Ocupações com < 12 meses: 9\n",
            "  Ocupações com todos os 54 meses: 589\n",
            "\n",
            "Estatísticas descritivas:\n",
            "       admissoes  desligamentos    saldo  salario_medio_adm\n",
            "count    32988.0        32988.0  32988.0            32988.0\n",
            "mean      3153.5         2873.6    279.9             6131.1\n",
            "std      13880.0        12450.5   2323.0           158475.4\n",
            "min          0.0            0.0 -46650.0                0.0\n",
            "25%         60.0           60.0    -16.0             1782.8\n",
            "50%        293.0          289.0      7.0             2371.3\n",
            "75%       1338.0         1264.0    107.0             3811.2\n",
            "max     289900.0       284338.0  90556.0         18799538.2\n",
            "\n",
            "Série temporal (primeiros e últimos 3 meses):\n",
            " periodo_num  total_adm  total_desl   sal_medio\n",
            "      202101    1550075     1293016 3697.157086\n",
            "      202102    1715425     1317510 3723.743109\n",
            "      202103    1626885     1450555 3252.934263\n",
            "...\n",
            " periodo_num  total_adm  total_desl    sal_medio\n",
            "      202504    2282187     2024659  4011.260301\n",
            "      202505    2256225     2107233  4441.730675\n",
            "      202506    2139182     1972561 11519.380585\n"
          ]
        }
      ],
      "source": [
        "# Etapa 2a.3b — CHECKPOINT: Verificar painel agregado\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"CHECKPOINT — Painel Ocupação × Mês\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# 1. Dimensões\n",
        "n_ocup = painel['cbo_4d'].nunique()\n",
        "n_periodos = painel['periodo'].nunique()\n",
        "print(f\"\\nOcupações: {n_ocup}\")\n",
        "print(f\"Períodos: {n_periodos}\")\n",
        "print(f\"Painel teórico (balanceado): {n_ocup * n_periodos:,}\")\n",
        "print(f\"Painel real: {len(painel):,}\")\n",
        "print(f\"Balanceamento: {len(painel) / (n_ocup * n_periodos):.1%}\")\n",
        "\n",
        "# 2. Ocupações com poucos meses\n",
        "ocup_meses = painel.groupby('cbo_4d')['periodo'].nunique()\n",
        "print(f\"\\nMeses por ocupação:\")\n",
        "print(f\"  Min: {ocup_meses.min()}, Max: {ocup_meses.max()}, Média: {ocup_meses.mean():.1f}\")\n",
        "print(f\"  Ocupações com < 12 meses: {(ocup_meses < 12).sum()}\")\n",
        "print(f\"  Ocupações com todos os {n_periodos} meses: {(ocup_meses == n_periodos).sum()}\")\n",
        "\n",
        "# 3. Estatísticas descritivas\n",
        "print(\"\\nEstatísticas descritivas:\")\n",
        "print(painel[['admissoes', 'desligamentos', 'saldo', 'salario_medio_adm']].describe().round(1))\n",
        "\n",
        "# 4. Série temporal agregada\n",
        "ts = painel.groupby('periodo_num').agg(\n",
        "    total_adm=('admissoes', 'sum'),\n",
        "    total_desl=('desligamentos', 'sum'),\n",
        "    sal_medio=('salario_medio_adm', 'mean'),\n",
        ").reset_index()\n",
        "print(\"\\nSérie temporal (primeiros e últimos 3 meses):\")\n",
        "print(ts.head(3).to_string(index=False))\n",
        "print(\"...\")\n",
        "print(ts.tail(3).to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9935501e",
      "metadata": {},
      "source": [
        "### 4a. Crosswalk CBO 2002 → ISCO-08\n",
        "\n",
        "Mapear os códigos CBO 2002 (usados no CAGED) para ISCO-08 (usados no índice ILO). **Esta é a etapa metodologicamente mais delicada do pipeline.**\n",
        "\n",
        "#### Contexto\n",
        "\n",
        "A CBO 2002 foi construída com base na ISCO-88/ISCO-08, compartilhando a mesma estrutura hierárquica:\n",
        "\n",
        "| Nível | CBO 2002 | ISCO-08 | Alinhamento |\n",
        "|-------|----------|---------|-------------|\n",
        "| 1 dígito | Grande Grupo (10) | Major Group (10) | Perfeito |\n",
        "| 2 dígitos | Subgrupo Principal (~46) | Sub-major Group (43) | Bom (14 CBOs sem match direto) |\n",
        "| 3 dígitos | Subgrupo (~194) | Minor Group (130) | Parcial (~45% direto) |\n",
        "| 4 dígitos | Família (~629) | Unit Group (427) | Divergente (~28% direto) |\n",
        "\n",
        "#### Estratégia adotada: Dual (2d principal + 4d robustez)\n",
        "\n",
        "**PARTE A — Especificação PRINCIPAL (2 dígitos):**\n",
        "- CBO 2d → ISCO-08 Sub-major Group (match direto)\n",
        "- Fallback: CBO 1d → ISCO-08 Major Group (média)\n",
        "- Cobertura esperada: **100%**\n",
        "\n",
        "**PARTE B — Especificação de ROBUSTEZ (4 dígitos, fallback hierárquico em 6 níveis):**\n",
        "\n",
        "| Nível | Estratégia | Cobertura esperada |\n",
        "|-------|------------|--------------------|\n",
        "| N1 | CBO 4d = ISCO-08 4d (match direto) | ~28% |\n",
        "| N2 | CBO 4d = ISCO-88 4d → ISCO-08 via correspondência oficial | ~+9% |\n",
        "| N3 | CBO 3d = ISCO-08 3d (média Minor Group) | ~+20% |\n",
        "| N4 | CBO 3d = ISCO-88 3d → ISCO-08 via correspondência | ~+1% |\n",
        "| N5 | CBO 2d = ISCO-08 2d (= especificação principal) | ~+18% |\n",
        "| N6 | CBO 1d = ISCO-08 1d (média Major Group) | ~+24% |\n",
        "\n",
        "> **Nota — Muendler (CBO 1994):** O arquivo `cbo-isco-conc.csv` de Muendler & Poole (2004) mapeia CBO **1994** → ISCO-88, NÃO a CBO 2002 usada no CAGED. Por isso, o match 4d via Muendler é limitado. A estratégia principal utiliza a similaridade estrutural entre CBO 2002 e ISCO-08/88 com fallback hierárquico.\n",
        "\n",
        "> **Nota sobre atenuação:** Se o crosswalk a 4 dígitos introduz erro de medição, o efeito típico é **atenuação** (viés em direção a zero). Encontrar efeito significativo mesmo com erro de medição sugere que o efeito real é provavelmente maior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "5fdb8d1d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Crosswalk carregado do checkpoint: painel_caged_crosswalk.parquet\n",
            "  32,988 linhas, cobertura 2d: 100.0%, 4d: 100.0%\n"
          ]
        }
      ],
      "source": [
        "# Etapa 2a.4a — Crosswalk CBO 2002 → ISCO-08 (Dual: 2d principal + 4d robustez)\n",
        "# Checkpoint: se o painel com crosswalk já existe, carrega direto.\n",
        "\n",
        "if PAINEL_CROSSWALK_FILE.exists():\n",
        "    painel = pd.read_parquet(PAINEL_CROSSWALK_FILE)\n",
        "    print(f\"Crosswalk carregado do checkpoint: {PAINEL_CROSSWALK_FILE.name}\")\n",
        "    print(f\"  {len(painel):,} linhas, cobertura 2d: {painel['exposure_score_2d'].notna().mean():.1%}, \"\n",
        "          f\"4d: {painel['exposure_score_4d'].notna().mean():.1%}\")\n",
        "else:\n",
        "    # ══════════════════════════════════════════════════════════════════════\n",
        "    # Carregar dados de referência\n",
        "    # ══════════════════════════════════════════════════════════════════════\n",
        "    df_ilo = pd.read_csv(ILO_FILE)\n",
        "    df_ilo['isco_08_str'] = df_ilo['isco_08'].astype(str).str.zfill(4)\n",
        "    print(f\"Índice ILO carregado: {len(df_ilo)} ocupações ISCO-08\")\n",
        "    print(f\"  Score range: [{df_ilo['exposure_score'].min():.3f}, {df_ilo['exposure_score'].max():.3f}]\")\n",
        "\n",
        "    # Dicts ILO em múltiplos níveis\n",
        "    codes = df_ilo['isco_08_str']\n",
        "    ilo_4d = df_ilo.groupby('isco_08_str')['exposure_score'].mean().to_dict()\n",
        "    ilo_3d = df_ilo.assign(g=codes.str[:3]).groupby('g')['exposure_score'].mean().to_dict()\n",
        "    ilo_2d = df_ilo.assign(g=codes.str[:2]).groupby('g')['exposure_score'].mean().to_dict()\n",
        "    ilo_1d = df_ilo.assign(g=codes.str[:1]).groupby('g')['exposure_score'].mean().to_dict()\n",
        "\n",
        "    # Correspondência ISCO-08 ↔ ISCO-88 (arquivo local)\n",
        "    isco88_to_08 = {}\n",
        "    isco88_3d_to_08_3d = {}\n",
        "    if ISCO_08_88_FILE.exists():\n",
        "        df_corr = pd.read_excel(ISCO_08_88_FILE, sheet_name='ISCO-08 to 88')\n",
        "        df_corr['isco08_4d'] = df_corr['ISCO-08 code'].astype(str).str.strip().str.zfill(4)\n",
        "        df_corr['isco88_4d'] = df_corr['ISCO-88 code'].astype(str).str.strip().str.zfill(4)\n",
        "        isco88_to_08 = df_corr.groupby('isco88_4d')['isco08_4d'].apply(list).to_dict()\n",
        "        df_corr['isco88_3d'] = df_corr['isco88_4d'].str[:3]\n",
        "        df_corr['isco08_3d'] = df_corr['isco08_4d'].str[:3]\n",
        "        isco88_3d_to_08_3d = df_corr.groupby('isco88_3d')['isco08_3d'].apply(\n",
        "            lambda x: list(set(x))).to_dict()\n",
        "        print(f\"  Correspondência ISCO-08↔88: {len(df_corr)} mapeamentos\")\n",
        "\n",
        "    # ══════════════════════════════════════════════════════════════════════\n",
        "    # PARTE A: 2 dígitos (PRINCIPAL)\n",
        "    # ══════════════════════════════════════════════════════════════════════\n",
        "    print(f\"\\n{'='*60}\\nPARTE A: Crosswalk 2 dígitos (PRINCIPAL)\\n{'='*60}\")\n",
        "\n",
        "    painel['exposure_score_2d'] = painel['cbo_2d'].map(ilo_2d)\n",
        "    painel['match_level_2d'] = np.where(painel['exposure_score_2d'].notna(), '2-digit', None)\n",
        "\n",
        "    # Fallback a 1 dígito\n",
        "    mask_na = painel['exposure_score_2d'].isna()\n",
        "    if mask_na.any():\n",
        "        cbo_1d = painel.loc[mask_na, 'cbo_4d'].str[:1]\n",
        "        painel.loc[mask_na, 'exposure_score_2d'] = cbo_1d.map(ilo_1d).values\n",
        "        painel.loc[mask_na, 'match_level_2d'] = '1-digit (fallback)'\n",
        "\n",
        "    painel['exposure_score'] = painel['exposure_score_2d']\n",
        "    cov_2d = painel['exposure_score_2d'].notna().mean()\n",
        "    print(f\"  COBERTURA 2d: {cov_2d:.1%}\")\n",
        "    for lvl, cnt in painel['match_level_2d'].value_counts().items():\n",
        "        print(f\"    {lvl}: {cnt:,} ({cnt/len(painel):.1%})\")\n",
        "\n",
        "    # ══════════════════════════════════════════════════════════════════════\n",
        "    # PARTE B: 4 dígitos (ROBUSTEZ) — fallback hierárquico 6 níveis\n",
        "    # ══════════════════════════════════════════════════════════════════════\n",
        "    print(f\"\\n{'='*60}\\nPARTE B: Crosswalk 4 dígitos (ROBUSTEZ)\\n{'='*60}\")\n",
        "\n",
        "    cbos_unicos = sorted(painel['cbo_4d'].unique())\n",
        "    cbo_score_4d = {}\n",
        "    cbo_match_level = {}\n",
        "    counts = {'N1': 0, 'N2': 0, 'N3': 0, 'N4': 0, 'N5': 0, 'N6': 0, 'sem': 0}\n",
        "\n",
        "    for cbo in cbos_unicos:\n",
        "        score, level = None, None\n",
        "\n",
        "        # N1: CBO 4d = ISCO-08 4d\n",
        "        if cbo in ilo_4d:\n",
        "            score, level = ilo_4d[cbo], 'N1: ISCO-08 4d direto'\n",
        "            counts['N1'] += 1\n",
        "        # N2: CBO 4d = ISCO-88 4d → ISCO-08\n",
        "        if score is None and cbo in isco88_to_08:\n",
        "            scores_c = [ilo_4d[c] for c in isco88_to_08[cbo] if c in ilo_4d]\n",
        "            if scores_c:\n",
        "                score, level = np.mean(scores_c), 'N2: via ISCO-88→08 4d'\n",
        "                counts['N2'] += 1\n",
        "        # N3: CBO 3d = ISCO-08 3d\n",
        "        if score is None and cbo[:3] in ilo_3d:\n",
        "            score, level = ilo_3d[cbo[:3]], 'N3: ISCO-08 3d'\n",
        "            counts['N3'] += 1\n",
        "        # N4: CBO 3d = ISCO-88 3d → ISCO-08 3d\n",
        "        if score is None and cbo[:3] in isco88_3d_to_08_3d:\n",
        "            scores_c = [ilo_3d[c] for c in isco88_3d_to_08_3d[cbo[:3]] if c in ilo_3d]\n",
        "            if scores_c:\n",
        "                score, level = np.mean(scores_c), 'N4: via ISCO-88→08 3d'\n",
        "                counts['N4'] += 1\n",
        "        # N5: CBO 2d = ISCO-08 2d\n",
        "        if score is None and cbo[:2] in ilo_2d:\n",
        "            score, level = ilo_2d[cbo[:2]], 'N5: ISCO-08 2d'\n",
        "            counts['N5'] += 1\n",
        "        # N6: CBO 1d = ISCO-08 1d\n",
        "        if score is None and cbo[:1] in ilo_1d:\n",
        "            score, level = ilo_1d[cbo[:1]], 'N6: ISCO-08 1d'\n",
        "            counts['N6'] += 1\n",
        "\n",
        "        if score is not None:\n",
        "            cbo_score_4d[cbo] = score\n",
        "            cbo_match_level[cbo] = level\n",
        "        else:\n",
        "            counts['sem'] += 1\n",
        "\n",
        "    painel['exposure_score_4d'] = painel['cbo_4d'].map(cbo_score_4d)\n",
        "    painel['match_level_4d'] = painel['cbo_4d'].map(cbo_match_level)\n",
        "\n",
        "    total = len(cbos_unicos)\n",
        "    print(f\"  CBOs 4d únicos: {total}\")\n",
        "    for k, v in counts.items():\n",
        "        if v > 0:\n",
        "            print(f\"    {k}: {v} ({v/total:.1%})\")\n",
        "    print(f\"  COBERTURA 4d: {painel['exposure_score_4d'].notna().mean():.1%}\")\n",
        "\n",
        "    # Correlação 2d vs 4d\n",
        "    df_check = painel[['cbo_4d', 'exposure_score_2d', 'exposure_score_4d']].drop_duplicates('cbo_4d')\n",
        "    corr = df_check['exposure_score_2d'].corr(df_check['exposure_score_4d'])\n",
        "    print(f\"\\n  Correlação Pearson (2d vs 4d): {corr:.4f}\")\n",
        "\n",
        "    painel.to_parquet(PAINEL_CROSSWALK_FILE, index=False)\n",
        "    print(f\"\\nSalvo: {PAINEL_CROSSWALK_FILE.name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48dd6bcb",
      "metadata": {},
      "source": [
        "### 4b. Verificar crosswalk (CHECKPOINT)\n",
        "\n",
        "Validar qualidade do crosswalk nas DUAS especificações: principal (2 dígitos) e robustez (4 dígitos). Verificar cobertura, distribuição de scores, correlação entre especificações e sanity check por grande grupo CBO.\n",
        "\n",
        "**Critérios de aceite:**\n",
        "- Cobertura 2d ≥ 95% (esperado ~100%)\n",
        "- Cobertura 4d ≥ 80% (esperado ~100% com fallback)\n",
        "- Correlação 2d vs 4d > 0.8 (consistência entre especificações)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "de59ed6d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "CHECKPOINT — Crosswalk CBO → ISCO-08 (Dual)\n",
            "============================================================\n",
            "\n",
            "--- Cobertura ---\n",
            "  2 dígitos (PRINCIPAL): 100.0%\n",
            "  4 dígitos (ROBUSTEZ):  100.0%\n",
            "\n",
            "--- Estatísticas dos scores ---\n",
            "\n",
            "exposure_score_2d (PRINCIPAL):\n",
            "count    32988.0000\n",
            "mean         0.2778\n",
            "std          0.1243\n",
            "min          0.1167\n",
            "25%          0.1658\n",
            "50%          0.2459\n",
            "75%          0.3725\n",
            "max          0.6325\n",
            "Name: exposure_score_2d, dtype: float64\n",
            "\n",
            "exposure_score_4d (ROBUSTEZ):\n",
            "count    32988.0000\n",
            "mean         0.2830\n",
            "std          0.1315\n",
            "min          0.0900\n",
            "25%          0.1658\n",
            "50%          0.2500\n",
            "75%          0.3650\n",
            "max          0.7000\n",
            "Name: exposure_score_4d, dtype: float64\n",
            "\n",
            "--- Correlação 2d vs 4d ---\n",
            "  Pearson: 0.9150\n",
            "  Alta correlação — bom sinal de consistência.\n",
            "\n",
            "--- Exposição por grande grupo CBO ---\n",
            "Grande Grupo                               Score 2d   Score 4d\n",
            "--------------------------------------------------------------\n",
            "  Dirigentes                                  0.367      0.375\n",
            "  Profissionais das ciências                  0.393      0.396\n",
            "  Técnicos nível médio                        0.334      0.338\n",
            "  Trabalhadores de serv. admin.               0.580      0.557\n",
            "  Trabalhadores de serviços/comércio          0.243      0.247\n",
            "  Agropecuária                                0.157      0.161\n",
            "  Produção industrial                         0.161      0.165\n",
            "  Operadores de máquinas                      0.213      0.217\n",
            "  Manutenção e reparação                      0.143      0.187\n",
            "  (!) = diferença > 0.1 entre 2d e 4d\n"
          ]
        }
      ],
      "source": [
        "# Etapa 2a.4b — CHECKPOINT: Verificar crosswalk CBO → ISCO-08\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"CHECKPOINT — Crosswalk CBO → ISCO-08 (Dual)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# 1. Cobertura\n",
        "coverage_2d = painel['exposure_score_2d'].notna().mean()\n",
        "coverage_4d = painel['exposure_score_4d'].notna().mean()\n",
        "print(f\"\\n--- Cobertura ---\")\n",
        "print(f\"  2 dígitos (PRINCIPAL): {coverage_2d:.1%}\")\n",
        "print(f\"  4 dígitos (ROBUSTEZ):  {coverage_4d:.1%}\")\n",
        "if coverage_2d < 0.95:\n",
        "    print(f\"  ALERTA: Cobertura 2d abaixo de 95%!\")\n",
        "if coverage_4d < 0.80:\n",
        "    print(f\"  AVISO: Cobertura 4d abaixo de 80%.\")\n",
        "\n",
        "# 2. Estatísticas dos scores\n",
        "print(f\"\\n--- Estatísticas dos scores ---\")\n",
        "print(f\"\\nexposure_score_2d (PRINCIPAL):\")\n",
        "print(painel['exposure_score_2d'].describe().round(4))\n",
        "print(f\"\\nexposure_score_4d (ROBUSTEZ):\")\n",
        "print(painel['exposure_score_4d'].describe().round(4))\n",
        "\n",
        "# 3. Correlação\n",
        "mask_both = painel['exposure_score_2d'].notna() & painel['exposure_score_4d'].notna()\n",
        "if mask_both.any():\n",
        "    corr = painel.loc[mask_both, 'exposure_score_2d'].corr(\n",
        "        painel.loc[mask_both, 'exposure_score_4d'])\n",
        "    print(f\"\\n--- Correlação 2d vs 4d ---\")\n",
        "    print(f\"  Pearson: {corr:.4f}\")\n",
        "    print(f\"  {'Alta correlação — bom sinal de consistência.' if corr > 0.8 else 'Correlação moderada.'}\")\n",
        "\n",
        "# 4. Sanity check por grande grupo CBO\n",
        "painel['grande_grupo_cbo'] = painel['cbo_4d'].str[0]\n",
        "print(f\"\\n--- Exposição por grande grupo CBO ---\")\n",
        "print(f\"{'Grande Grupo':<40} {'Score 2d':>10} {'Score 4d':>10}\")\n",
        "print(\"-\" * 62)\n",
        "for gg, nome in sorted(GRANDES_GRUPOS_CBO.items()):\n",
        "    mask = painel['grande_grupo_cbo'] == gg\n",
        "    if mask.any():\n",
        "        s2d = painel.loc[mask, 'exposure_score_2d'].mean()\n",
        "        s4d = painel.loc[mask, 'exposure_score_4d'].mean()\n",
        "        s4d_str = f\"{s4d:.3f}\" if not np.isnan(s4d) else \"N/A\"\n",
        "        flag = \" (!)\" if not np.isnan(s4d) and abs(s2d - s4d) > 0.1 else \"\"\n",
        "        print(f\"  {nome:<38} {s2d:>10.3f} {s4d_str:>10}{flag}\")\n",
        "print(f\"  (!) = diferença > 0.1 entre 2d e 4d\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bbe3871",
      "metadata": {},
      "source": [
        "### 5a. Definição de tratamento\n",
        "\n",
        "Definir as variáveis de tratamento para a análise DiD. O tratamento é baseado na **exposição ocupacional à IA generativa**: ocupações com alta exposição (top 20%) vs. baixa exposição.\n",
        "\n",
        "#### Variáveis criadas\n",
        "\n",
        "| Variável | Definição | Uso |\n",
        "|----------|-----------|-----|\n",
        "| `alta_exp` | 1 se `exposure_score_2d >= percentil 80` | **Especificação principal** |\n",
        "| `alta_exp_10` | 1 se `exposure_score_2d >= percentil 90` | Robustez (cutoff) |\n",
        "| `alta_exp_25` | 1 se `exposure_score_2d >= percentil 75` | Robustez (cutoff) |\n",
        "| `alta_exp_mediana` | 1 se `exposure_score_2d >= mediana` | Alternativa binária |\n",
        "| `quintil_exp` | Quintil de exposição (Q1–Q5) | Análise por quantil |\n",
        "| `alta_exp_4d` | 1 se `exposure_score_4d >= percentil 80` | Robustez (crosswalk 4d) |\n",
        "| `did` | `post × alta_exp` | Interação DiD principal |\n",
        "| `did_4d` | `post × alta_exp_4d` | Interação DiD robustez |\n",
        "\n",
        "> **Nota:** Os thresholds são calculados sobre a distribuição de **ocupações** (uma obs por CBO), não ponderada por volume de movimentações. Cada ocupação tem peso igual na definição do tratamento.\n",
        "\n",
        "> **Nota — Tratamento contínuo:** Além das dummies, `exposure_score_2d` e `exposure_score_4d` podem ser usados diretamente como tratamento contínuo em especificações alternativas, conforme Hui et al. (2024)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "8798f7cf",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thresholds de exposição (2d, PRINCIPAL):\n",
            "  alta_exp_10: 0.4433 (78 ocupações, 12%)\n",
            "  alta_exp: 0.3854 (131 ocupações, 21%)\n",
            "  alta_exp_25: 0.3725 (165 ocupações, 26%)\n",
            "  alta_exp_mediana: 0.2459 (332 ocupações, 53%)\n",
            "\n",
            "Threshold 4d (p80): 0.3863 (137 ocupações)\n",
            "\n",
            "--- Distribuição de tratamento ---\n",
            "  Alta exp 2d (top 20%): 20.3% das obs\n",
            "  Alta exp 4d (top 20%): 21.3% das obs\n",
            "  Períodos pré:  14,058\n",
            "  Períodos pós:  18,930\n",
            "  Concordância 2d vs 4d: 93.1%\n",
            "\n",
            "Tabela de contingência (2d, principal):\n",
            "alta_exp  Controle  Tratamento    All\n",
            "post                                 \n",
            "Pré          11195        2863  14058\n",
            "Pós          15092        3838  18930\n",
            "All          26287        6701  32988\n"
          ]
        }
      ],
      "source": [
        "# Etapa 2a.5a — Definição de tratamento\n",
        "\n",
        "# ── Thresholds sobre a distribuição de ocupações (2d) ──\n",
        "ocup_scores_2d = painel.groupby('cbo_4d')['exposure_score_2d'].first().dropna()\n",
        "\n",
        "thresholds_2d = {\n",
        "    'alta_exp_10':      ocup_scores_2d.quantile(0.90),\n",
        "    'alta_exp':         ocup_scores_2d.quantile(0.80),  # PRINCIPAL\n",
        "    'alta_exp_25':      ocup_scores_2d.quantile(0.75),\n",
        "    'alta_exp_mediana':  ocup_scores_2d.quantile(0.50),\n",
        "}\n",
        "\n",
        "print(\"Thresholds de exposição (2d, PRINCIPAL):\")\n",
        "for name, val in thresholds_2d.items():\n",
        "    n_above = (ocup_scores_2d >= val).sum()\n",
        "    pct = n_above / len(ocup_scores_2d) * 100\n",
        "    print(f\"  {name}: {val:.4f} ({n_above} ocupações, {pct:.0f}%)\")\n",
        "\n",
        "# ── Dummies de tratamento 2d ──\n",
        "for name, threshold in thresholds_2d.items():\n",
        "    painel[name] = (painel['exposure_score_2d'] >= threshold).astype(int)\n",
        "\n",
        "# Quintis\n",
        "painel['quintil_exp'] = pd.qcut(\n",
        "    painel['exposure_score_2d'].rank(method='first'),\n",
        "    q=5,\n",
        "    labels=['Q1 (Baixa)', 'Q2', 'Q3', 'Q4', 'Q5 (Alta)']\n",
        ")\n",
        "\n",
        "# ── Dummies 4d (ROBUSTEZ) ──\n",
        "ocup_scores_4d = painel.groupby('cbo_4d')['exposure_score_4d'].first().dropna()\n",
        "threshold_4d_80 = ocup_scores_4d.quantile(0.80)\n",
        "painel['alta_exp_4d'] = (painel['exposure_score_4d'] >= threshold_4d_80).astype(int)\n",
        "print(f\"\\nThreshold 4d (p80): {threshold_4d_80:.4f} ({(ocup_scores_4d >= threshold_4d_80).sum()} ocupações)\")\n",
        "\n",
        "# ── Interações DiD ──\n",
        "painel['did'] = painel['post'] * painel['alta_exp']\n",
        "painel['did_4d'] = painel['post'] * painel['alta_exp_4d']\n",
        "\n",
        "# ── Resumo ──\n",
        "print(f\"\\n--- Distribuição de tratamento ---\")\n",
        "print(f\"  Alta exp 2d (top 20%): {painel['alta_exp'].mean():.1%} das obs\")\n",
        "print(f\"  Alta exp 4d (top 20%): {painel['alta_exp_4d'].mean():.1%} das obs\")\n",
        "print(f\"  Períodos pré:  {painel[painel['post']==0].shape[0]:,}\")\n",
        "print(f\"  Períodos pós:  {painel[painel['post']==1].shape[0]:,}\")\n",
        "\n",
        "concordancia = (painel['alta_exp'] == painel['alta_exp_4d']).mean()\n",
        "print(f\"  Concordância 2d vs 4d: {concordancia:.1%}\")\n",
        "\n",
        "# Tabela de contingência\n",
        "ct = pd.crosstab(\n",
        "    painel['post'].map({0: 'Pré', 1: 'Pós'}),\n",
        "    painel['alta_exp'].map({0: 'Controle', 1: 'Tratamento'}),\n",
        "    margins=True\n",
        ")\n",
        "print(f\"\\nTabela de contingência (2d, principal):\")\n",
        "print(ct)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c7c990d",
      "metadata": {},
      "source": [
        "### 5b. Verificar tratamento (CHECKPOINT)\n",
        "\n",
        "Validar a definição de tratamento: top/bottom ocupações por exposição, distribuição por quintil, e concordância entre especificações 2d e 4d.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "bc1457bd",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "CHECKPOINT — Definição de Tratamento\n",
            "============================================================\n",
            "\n",
            "--- Top 10 ocupações MAIS expostas ---\n",
            "  CBO 4101: score=0.632, admissões=343,660  (Trabalhadores de serv. admin.)\n",
            "  CBO 4102: score=0.632, admissões=109,397  (Trabalhadores de serv. admin.)\n",
            "  CBO 4110: score=0.632, admissões=7,169,112  (Trabalhadores de serv. admin.)\n",
            "  CBO 4121: score=0.632, admissões=36,099  (Trabalhadores de serv. admin.)\n",
            "  CBO 4122: score=0.632, admissões=217,727  (Trabalhadores de serv. admin.)\n",
            "  CBO 4131: score=0.632, admissões=521,115  (Trabalhadores de serv. admin.)\n",
            "  CBO 4132: score=0.632, admissões=178,605  (Trabalhadores de serv. admin.)\n",
            "  CBO 4141: score=0.632, admissões=4,019,302  (Trabalhadores de serv. admin.)\n",
            "  CBO 4142: score=0.632, admissões=406,552  (Trabalhadores de serv. admin.)\n",
            "  CBO 4151: score=0.632, admissões=36,816  (Trabalhadores de serv. admin.)\n",
            "\n",
            "--- 10 ocupações MENOS expostas ---\n",
            "  CBO 9101: score=0.117, admissões=44,866  (Manutenção e reparação)\n",
            "  CBO 9102: score=0.117, admissões=13,108  (Manutenção e reparação)\n",
            "  CBO 9109: score=0.117, admissões=1,394  (Manutenção e reparação)\n",
            "  CBO 9111: score=0.117, admissões=38,881  (Manutenção e reparação)\n",
            "  CBO 9112: score=0.117, admissões=83,226  (Manutenção e reparação)\n",
            "  CBO 9113: score=0.117, admissões=489,020  (Manutenção e reparação)\n",
            "  CBO 9131: score=0.117, admissões=85,145  (Manutenção e reparação)\n",
            "  CBO 9141: score=0.117, admissões=9,542  (Manutenção e reparação)\n",
            "  CBO 9142: score=0.117, admissões=1,889  (Manutenção e reparação)\n",
            "  CBO 9143: score=0.117, admissões=7,158  (Manutenção e reparação)\n",
            "\n",
            "--- Estatísticas por quintil de exposição ---\n",
            "  Q1 (Baixa): n=6,598, exposure=0.144, adm_mean=2843, sal_medio=4,495\n",
            "  Q2: n=6,597, exposure=0.180, adm_mean=2600, sal_medio=2,897\n",
            "  Q3: n=6,598, exposure=0.252, adm_mean=3674, sal_medio=6,744\n",
            "  Q4: n=6,597, exposure=0.348, adm_mean=2674, sal_medio=8,027\n",
            "  Q5 (Alta): n=6,598, exposure=0.466, adm_mean=3977, sal_medio=8,492\n",
            "\n",
            "--- Concordância 2d vs 4d: 93.1% ---\n",
            "\n",
            "============================================================\n",
            "CHECKPOINT CONCLUÍDO\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Etapa 2a.5b — CHECKPOINT: Verificar definição de tratamento\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"CHECKPOINT — Definição de Tratamento\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# 1. Top 10 ocupações mais expostas\n",
        "print(\"\\n--- Top 10 ocupações MAIS expostas ---\")\n",
        "top10 = painel.groupby('cbo_4d').agg(\n",
        "    exposure=('exposure_score', 'first'),\n",
        "    admissoes_total=('admissoes', 'sum'),\n",
        ").nlargest(10, 'exposure')\n",
        "for cbo, row in top10.iterrows():\n",
        "    nome = GRANDES_GRUPOS_CBO.get(cbo[0], '')\n",
        "    print(f\"  CBO {cbo}: score={row['exposure']:.3f}, admissões={row['admissoes_total']:,.0f}  ({nome})\")\n",
        "\n",
        "# 2. Bottom 10 ocupações menos expostas\n",
        "print(f\"\\n--- 10 ocupações MENOS expostas ---\")\n",
        "bot10 = painel.groupby('cbo_4d').agg(\n",
        "    exposure=('exposure_score', 'first'),\n",
        "    admissoes_total=('admissoes', 'sum'),\n",
        ").nsmallest(10, 'exposure')\n",
        "for cbo, row in bot10.iterrows():\n",
        "    nome = GRANDES_GRUPOS_CBO.get(cbo[0], '')\n",
        "    print(f\"  CBO {cbo}: score={row['exposure']:.3f}, admissões={row['admissoes_total']:,.0f}  ({nome})\")\n",
        "\n",
        "# 3. Distribuição por quintil\n",
        "print(f\"\\n--- Estatísticas por quintil de exposição ---\")\n",
        "for q in ['Q1 (Baixa)', 'Q2', 'Q3', 'Q4', 'Q5 (Alta)']:\n",
        "    sub = painel[painel['quintil_exp'] == q]\n",
        "    if len(sub) > 0:\n",
        "        print(f\"  {q}: n={len(sub):,}, \"\n",
        "              f\"exposure={sub['exposure_score'].mean():.3f}, \"\n",
        "              f\"adm_mean={sub['admissoes'].mean():.0f}, \"\n",
        "              f\"sal_medio={sub['salario_medio_adm'].mean():,.0f}\")\n",
        "\n",
        "# 4. Concordância\n",
        "concordancia = (painel['alta_exp'] == painel['alta_exp_4d']).mean()\n",
        "print(f\"\\n--- Concordância 2d vs 4d: {concordancia:.1%} ---\")\n",
        "\n",
        "print(f\"\\n{'=' * 60}\")\n",
        "print(f\"CHECKPOINT CONCLUÍDO\")\n",
        "print(f\"{'=' * 60}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b075f48",
      "metadata": {},
      "source": [
        "### 6a. Enriquecimento do painel (variáveis adicionais)\n",
        "\n",
        "Adicionar variáveis de controle e contexto temporal ao painel para a análise DiD.\n",
        "\n",
        "| Variável | Cálculo | Uso |\n",
        "|----------|---------|-----|\n",
        "| `tempo_relativo_meses` | Meses desde Dez/2022 (t=0) | Event study |\n",
        "| `trend` | Tendência linear (0, 1, 2, ...) | Controle de tendência |\n",
        "| `mes_do_ano` | Mês do ano (1-12) | Dummies de sazonalidade |\n",
        "| `salario_sm` | `salario_medio_adm / SM do ano` | Normalização salarial |\n",
        "| `grande_grupo_nome` | Nome do grande grupo CBO | Efeitos fixos |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "2519c01b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tempo relativo: [-23, 30] meses\n",
            "Referência (t=0): 12/2022\n",
            "\n",
            "Variáveis adicionadas: tempo_relativo_meses, trend, mes_do_ano, salario_sm, ln_salario_sm, grande_grupo_nome\n",
            "Colunas totais: 42\n"
          ]
        }
      ],
      "source": [
        "# Etapa 2a.6a — Enriquecimento do painel\n",
        "\n",
        "def periodo_num_to_months(pn):\n",
        "    \"\"\"Converter periodo_num (YYYYMM) para contagem absoluta de meses.\"\"\"\n",
        "    return (pn // 100) * 12 + (pn % 100)\n",
        "\n",
        "# ── Tempo relativo ao tratamento ──\n",
        "ref_periodo = ANO_TRATAMENTO * 100 + MES_TRATAMENTO\n",
        "painel['meses_abs'] = painel['periodo_num'].apply(periodo_num_to_months)\n",
        "ref_meses = periodo_num_to_months(ref_periodo)\n",
        "painel['tempo_relativo_meses'] = painel['meses_abs'] - ref_meses\n",
        "\n",
        "print(f\"Tempo relativo: [{painel['tempo_relativo_meses'].min()}, \"\n",
        "      f\"{painel['tempo_relativo_meses'].max()}] meses\")\n",
        "print(f\"Referência (t=0): {MES_TRATAMENTO}/{ANO_TRATAMENTO}\")\n",
        "\n",
        "# ── Tendência temporal e sazonalidade ──\n",
        "painel['trend'] = painel['meses_abs'] - painel['meses_abs'].min()\n",
        "painel['mes_do_ano'] = painel['mes'].astype(int)\n",
        "\n",
        "# ── Normalização salarial ──\n",
        "painel['sm_ano'] = painel['ano'].astype(int).map(SALARIO_MINIMO)\n",
        "painel['salario_sm'] = painel['salario_medio_adm'] / painel['sm_ano']\n",
        "painel['ln_salario_sm'] = np.log(painel['salario_sm'].clip(lower=0.1))\n",
        "\n",
        "# ── Grande grupo ocupacional ──\n",
        "painel['grande_grupo_cbo'] = painel['cbo_4d'].str[0]\n",
        "painel['grande_grupo_nome'] = painel['grande_grupo_cbo'].map(GRANDES_GRUPOS_CBO)\n",
        "\n",
        "print(f\"\\nVariáveis adicionadas: tempo_relativo_meses, trend, mes_do_ano, \"\n",
        "      f\"salario_sm, ln_salario_sm, grande_grupo_nome\")\n",
        "print(f\"Colunas totais: {painel.shape[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0626572e",
      "metadata": {},
      "source": [
        "### 7. Salvar dataset analítico final\n",
        "\n",
        "Selecionar colunas finais, remover ocupações sem score de exposição e salvar o dataset pronto para a análise DiD (Notebook 2b).\n",
        "\n",
        "**Saída:**\n",
        "- `data/output/painel_caged_did_ready.parquet` — formato eficiente para análise\n",
        "- `data/output/painel_caged_did_ready.csv` — backup legível"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "f56e1220",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "DATASET ANALÍTICO FINAL — ETAPA 2a\n",
            "============================================================\n",
            "  Observações:        32,988\n",
            "  Ocupações (CBO 4d): 629\n",
            "  Períodos:           54 meses\n",
            "    Pré-tratamento:   23\n",
            "    Pós-tratamento:   31\n",
            "  Cobertura 2d:       100.0%\n",
            "  Cobertura 4d:       100.0%\n",
            "  Tratamento 2d:      20.3% das obs\n",
            "  Tratamento 4d:      21.3% das obs\n",
            "  Colunas:            37\n",
            "\n",
            "  Salvo em:\n",
            "    data/output/painel_caged_did_ready.parquet\n",
            "    data/output/painel_caged_did_ready.csv\n",
            "    Tamanho: 2.8 MB (parquet), 9.9 MB (csv)\n",
            "\n",
            "  Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 32988 entries, 0 to 32987\n",
            "Data columns (total 37 columns):\n",
            " #   Column                Non-Null Count  Dtype   \n",
            "---  ------                --------------  -----   \n",
            " 0   cbo_4d                32988 non-null  object  \n",
            " 1   cbo_2d                32988 non-null  object  \n",
            " 2   ano                   32988 non-null  Int64   \n",
            " 3   mes                   32988 non-null  Int64   \n",
            " 4   periodo               32988 non-null  object  \n",
            " 5   periodo_num           32988 non-null  int64   \n",
            " 6   admissoes             32988 non-null  Int64   \n",
            " 7   desligamentos         32988 non-null  Int64   \n",
            " 8   saldo                 32988 non-null  Int64   \n",
            " 9   n_movimentacoes       32988 non-null  Int64   \n",
            " 10  ln_admissoes          32988 non-null  Float64 \n",
            " 11  ln_desligamentos      32988 non-null  Float64 \n",
            " 12  salario_medio_adm     32988 non-null  float64 \n",
            " 13  salario_mediano_adm   32988 non-null  float64 \n",
            " 14  salario_medio_desl    32988 non-null  float64 \n",
            " 15  ln_salario_adm        32988 non-null  float64 \n",
            " 16  salario_sm            32988 non-null  float64 \n",
            " 17  ln_salario_sm         32988 non-null  float64 \n",
            " 18  idade_media_adm       32988 non-null  Float64 \n",
            " 19  pct_mulher_adm        32988 non-null  float64 \n",
            " 20  pct_superior_adm      32988 non-null  float64 \n",
            " 21  exposure_score_2d     32988 non-null  float64 \n",
            " 22  exposure_score_4d     32988 non-null  float64 \n",
            " 23  alta_exp              32988 non-null  int64   \n",
            " 24  alta_exp_10           32988 non-null  int64   \n",
            " 25  alta_exp_25           32988 non-null  int64   \n",
            " 26  alta_exp_mediana      32988 non-null  int64   \n",
            " 27  quintil_exp           32988 non-null  category\n",
            " 28  alta_exp_4d           32988 non-null  int64   \n",
            " 29  post                  32988 non-null  int64   \n",
            " 30  did                   32988 non-null  int64   \n",
            " 31  did_4d                32988 non-null  int64   \n",
            " 32  tempo_relativo_meses  32988 non-null  int64   \n",
            " 33  trend                 32988 non-null  int64   \n",
            " 34  mes_do_ano            32988 non-null  int64   \n",
            " 35  grande_grupo_cbo      32988 non-null  object  \n",
            " 36  grande_grupo_nome     32988 non-null  object  \n",
            "dtypes: Float64(3), Int64(6), category(1), float64(10), int64(12), object(5)\n",
            "memory usage: 9.4+ MB\n"
          ]
        }
      ],
      "source": [
        "# Etapa 2a.7 — Salvar dataset analítico final\n",
        "\n",
        "# ── Selecionar colunas finais ──\n",
        "cols_finais = [\n",
        "    # Identificação\n",
        "    'cbo_4d', 'cbo_2d', 'ano', 'mes', 'periodo', 'periodo_num',\n",
        "    # Outcomes\n",
        "    'admissoes', 'desligamentos', 'saldo', 'n_movimentacoes',\n",
        "    'ln_admissoes', 'ln_desligamentos',\n",
        "    'salario_medio_adm', 'salario_mediano_adm', 'salario_medio_desl',\n",
        "    'ln_salario_adm', 'salario_sm', 'ln_salario_sm',\n",
        "    # Demografia das admissões\n",
        "    'idade_media_adm', 'pct_mulher_adm', 'pct_superior_adm',\n",
        "    # Exposição IA — DUAL\n",
        "    'exposure_score_2d',   # PRINCIPAL\n",
        "    'exposure_score_4d',   # ROBUSTEZ\n",
        "    # Tratamento — DUAL\n",
        "    'alta_exp',            # Top 20% score 2d (PRINCIPAL)\n",
        "    'alta_exp_10', 'alta_exp_25', 'alta_exp_mediana', 'quintil_exp',\n",
        "    'alta_exp_4d',         # Top 20% score 4d (ROBUSTEZ)\n",
        "    # Temporal\n",
        "    'post', 'did', 'did_4d', 'tempo_relativo_meses', 'trend', 'mes_do_ano',\n",
        "    # Classificação\n",
        "    'grande_grupo_cbo', 'grande_grupo_nome',\n",
        "]\n",
        "\n",
        "cols_existentes = [c for c in cols_finais if c in painel.columns]\n",
        "cols_faltantes = [c for c in cols_finais if c not in painel.columns]\n",
        "if cols_faltantes:\n",
        "    print(f\"AVISO: Colunas não encontradas: {cols_faltantes}\")\n",
        "\n",
        "painel_final = painel[cols_existentes].copy()\n",
        "\n",
        "# ── Remover ocupações sem score principal (2d) ──\n",
        "n_antes = len(painel_final)\n",
        "painel_final = painel_final[painel_final['exposure_score_2d'].notna()]\n",
        "n_depois = len(painel_final)\n",
        "if n_antes > n_depois:\n",
        "    print(f\"Removidas {n_antes - n_depois:,} linhas sem exposure_score_2d\")\n",
        "\n",
        "# ── Salvar ──\n",
        "painel_final.to_parquet(PAINEL_FINAL_PARQUET, index=False)\n",
        "painel_final.to_csv(PAINEL_FINAL_CSV, index=False)\n",
        "\n",
        "# ══════════════════════════════════════════════════════════════════════\n",
        "# RESUMO FINAL\n",
        "# ══════════════════════════════════════════════════════════════════════\n",
        "print(f\"\\n{'=' * 60}\")\n",
        "print(\"DATASET ANALÍTICO FINAL — ETAPA 2a\")\n",
        "print(f\"{'=' * 60}\")\n",
        "print(f\"  Observações:        {len(painel_final):,}\")\n",
        "print(f\"  Ocupações (CBO 4d): {painel_final['cbo_4d'].nunique()}\")\n",
        "print(f\"  Períodos:           {painel_final['periodo'].nunique()} meses\")\n",
        "print(f\"    Pré-tratamento:   {painel_final[painel_final['post']==0]['periodo'].nunique()}\")\n",
        "print(f\"    Pós-tratamento:   {painel_final[painel_final['post']==1]['periodo'].nunique()}\")\n",
        "print(f\"  Cobertura 2d:       {painel_final['exposure_score_2d'].notna().mean():.1%}\")\n",
        "print(f\"  Cobertura 4d:       {painel_final['exposure_score_4d'].notna().mean():.1%}\")\n",
        "print(f\"  Tratamento 2d:      {painel_final['alta_exp'].mean():.1%} das obs\")\n",
        "print(f\"  Tratamento 4d:      {painel_final['alta_exp_4d'].mean():.1%} das obs\")\n",
        "print(f\"  Colunas:            {painel_final.shape[1]}\")\n",
        "print(f\"\\n  Salvo em:\")\n",
        "print(f\"    {PAINEL_FINAL_PARQUET}\")\n",
        "print(f\"    {PAINEL_FINAL_CSV}\")\n",
        "pq_mb = PAINEL_FINAL_PARQUET.stat().st_size / 1e6\n",
        "csv_mb = PAINEL_FINAL_CSV.stat().st_size / 1e6\n",
        "print(f\"    Tamanho: {pq_mb:.1f} MB (parquet), {csv_mb:.1f} MB (csv)\")\n",
        "\n",
        "print(f\"\\n  Info:\")\n",
        "painel_final.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c169961f",
      "metadata": {},
      "source": [
        "### Limitações desta etapa\n",
        "\n",
        "1. **Novo CAGED (descontinuidade 2020):** A transição para o eSocial (2020) pode afetar a comparabilidade. Mitigamos ao iniciar em 2021 (eSocial já estabilizado, sem efeitos COVID).\n",
        "\n",
        "2. **Fluxos vs. estoques:** O CAGED mede movimentações (admissões/desligamentos), não o estoque de empregados. Quedas em admissões não significam necessariamente queda no emprego total — podem refletir menor rotatividade. Esta é a mesma lógica usada por Hui et al. (2024) com dados do Upwork.\n",
        "\n",
        "3. **Crosswalk CBO → ISCO-08 (especificação principal, 2 dígitos):** Ao agregar por Sub-major Group com fallback a Major Group, perdemos variação intragrupo. Ocupações diferentes dentro do mesmo grupo recebem o mesmo score. A especificação de robustez a 4 dígitos (com fallback hierárquico em 6 níveis) ajuda a avaliar se essa agregação afeta os resultados.\n",
        "\n",
        "4. **Crosswalk CBO → ISCO-08 (robustez, 4 dígitos):** O match direto CBO 4d = ISCO-08 4d cobre apenas ~28% das ocupações. Para o restante, usamos fallback hierárquico (via correspondência ISCO-88→ISCO-08, médias a 3d, 2d e 1d). Quanto mais granular o match, mais preciso o score — mas mesmo com fallback, a correlação entre as especificações 2d e 4d é >0.91, indicando consistência. Erro de medição no tratamento tipicamente atenua os coeficientes (viés em direção a zero).\n",
        "\n",
        "5. **Muendler: CBO 1994, não CBO 2002:** O arquivo de concordância Muendler & Poole (2004) mapeia a CBO *1994* (formato X-XX.XX), não a CBO 2002 (XXXX) usada no CAGED. A utilidade do Muendler para match 4d direto é limitada. A estratégia adotada usa a similaridade estrutural entre CBO 2002 e ISCO-08/88 (ambas baseadas na ISCO), combinada com a tabela oficial de correspondência ISCO-08↔ISCO-88.\n",
        "\n",
        "6. **Emprego formal apenas:** O CAGED cobre apenas o mercado formal (CLT). A informalidade (~40% da força de trabalho brasileira) não é capturada. Efeitos da IA sobre o setor informal requerem fontes alternativas (PNAD).\n",
        "\n",
        "7. **Índice global aplicado ao Brasil:** Mesma limitação da Etapa 1 — o índice ILO foi desenvolvido com foco global e pode não capturar especificidades do mercado de trabalho brasileiro.\n",
        "\n",
        "---\n",
        "\n",
        "### Checklist de entregáveis\n",
        "\n",
        "- [x] `data/raw/caged_{ano}.parquet` — Microdados CAGED por ano (2021–2025)\n",
        "- [x] `data/input/cbo-isco-conc.csv` — Concordância Muendler CBO 1994→ISCO-88\n",
        "- [x] `data/input/Correspondência ISCO 08 a 88.xlsx` — Tabela oficial ISCO-08↔ISCO-88\n",
        "- [x] `data/processed/ilo_exposure_clean.csv` — Índice ILO processado (reusado da Etapa 1)\n",
        "- [x] `data/output/painel_caged_did_ready.parquet` — Dataset analítico final (com scores 2d e 4d)\n",
        "- [x] `data/output/painel_caged_did_ready.csv` — Backup CSV\n",
        "- [x] Todos os CHECKPOINTs passando sem warnings críticos\n",
        "- [x] Cobertura crosswalk 2d = 100%\n",
        "- [x] Cobertura crosswalk 4d = 100% (com fallback hierárquico)\n",
        "- [x] Correlação entre scores 2d e 4d: 0.9147\n",
        "- [x] Sanity check por grande grupo coerente com a literatura\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
