"""
Script 14: Generate Markdown Report

Generates comprehensive markdown reports with automatic interpretation of DiD analysis results.

Inputs:
- outputs/tables/did_main_results.csv
- outputs/tables/event_study_*.csv
- outputs/tables/parallel_trends_test_formal.csv
- outputs/tables/heterogeneity_all_triple_did.csv
- outputs/tables/robustness_summary.csv
- outputs/tables/balance_table_pre.csv

Outputs:
- outputs/DID_ANALYSIS_REPORT.md (comprehensive report)
- outputs/DID_EXECUTIVE_SUMMARY.md (executive summary)

Author: Claude Code
Date: 2026-02-08
"""

import sys
from pathlib import Path
import pandas as pd
import numpy as np
import logging
from datetime import datetime

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from config.settings import (
    DATA_PROCESSED, OUTPUTS_TABLES, OUTPUTS_LOGS, ROOT_DIR,
    OUTCOMES_VALID
)

# Define OUTPUTS_DIR
OUTPUTS_DIR = ROOT_DIR / "outputs"

# ============================================
# LOGGING SETUP
# ============================================

# Create log file
log_file = OUTPUTS_LOGS / '14_generate_report.log'
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(log_file, mode='w'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ============================================
# INTERPRETATION FUNCTIONS
# ============================================

def interpret_coefficient_magnitude(coef, outcome):
    """
    Interprets the magnitude of a DiD coefficient.

    Parameters:
    -----------
    coef : float
        Coefficient value
    outcome : str
        Outcome variable name

    Returns:
    --------
    str: Interpretation text
    """
    if outcome == 'ln_renda':
        # Log points interpretation
        pct_change = (np.exp(coef) - 1) * 100
        if abs(pct_change) < 1:
            magnitude = "muito pequena"
        elif abs(pct_change) < 3:
            magnitude = "pequena"
        elif abs(pct_change) < 5:
            magnitude = "moderada"
        else:
            magnitude = "grande"

        direction = "aumento" if coef > 0 else "redu√ß√£o"
        return f"{magnitude} {direction} de aproximadamente {abs(pct_change):.1f}%"

    elif outcome == 'horas_trabalhadas':
        # Direct hours interpretation
        if abs(coef) < 0.5:
            magnitude = "muito pequena"
        elif abs(coef) < 1.0:
            magnitude = "pequena"
        elif abs(coef) < 2.0:
            magnitude = "moderada"
        else:
            magnitude = "grande"

        direction = "aumento" if coef > 0 else "redu√ß√£o"
        return f"{magnitude} {direction} de aproximadamente {abs(coef):.1f} horas por semana"

    else:
        return f"mudan√ßa de {coef:.4f}"


def interpret_did_coefficient(coef, se, p_value, outcome):
    """
    Generates automatic interpretation of a DiD coefficient.

    Parameters:
    -----------
    coef : float
        Coefficient value
    se : float
        Standard error
    p_value : float
        P-value
    outcome : str
        Outcome variable name

    Returns:
    --------
    str: Markdown-formatted interpretation
    """
    # Significance
    if p_value < 0.01:
        sig_text = "**estatisticamente significativo a 1%**"
        sig_level = "forte"
    elif p_value < 0.05:
        sig_text = "**estatisticamente significativo a 5%**"
        sig_level = "moderada"
    elif p_value < 0.10:
        sig_text = "**marginalmente significativo a 10%**"
        sig_level = "fraca"
    else:
        sig_text = "**n√£o estatisticamente significativo**"
        sig_level = "nenhuma"

    # Direction
    if coef > 0:
        direction = "positivo"
        verb = "aumento"
    else:
        direction = "negativo"
        verb = "redu√ß√£o"

    # Magnitude interpretation
    magnitude_text = interpret_coefficient_magnitude(coef, outcome)

    # Build interpretation
    interpretation = f"O coeficiente DiD √© {direction} (Œ≤ = {coef:.4f}, SE = {se:.4f}) e {sig_text} (p = {p_value:.4f}). "

    if p_value < 0.10:
        interpretation += f"Isso sugere uma {magnitude_text} para trabalhadores em ocupa√ß√µes de alta exposi√ß√£o √† IA Generativa, "
        interpretation += f"comparados aos de baixa exposi√ß√£o, ap√≥s o lan√ßamento do ChatGPT. "
        interpretation += f"A evid√™ncia √© {sig_level}."
    else:
        interpretation += f"N√£o h√° evid√™ncia estat√≠stica suficiente de que o ChatGPT teve impacto diferencial sobre este outcome. "
        interpretation += f"Isso pode indicar que: (i) os efeitos ainda n√£o se materializaram; "
        interpretation += f"(ii) o ajuste ocorre por outras margens n√£o observadas; "
        interpretation += f"(iii) h√° erro de medida atenuando os coeficientes; ou "
        interpretation += f"(iv) a economia brasileira responde de forma diferente √† tecnologia."

    return interpretation


def assess_parallel_trends(pt_df):
    """
    Assesses parallel trends assumption based on formal test.

    Parameters:
    -----------
    pt_df : DataFrame
        Parallel trends test results

    Returns:
    --------
    dict: Assessment with keys 'passed', 'text', 'concern_level'
    """
    assessments = []

    for _, row in pt_df.iterrows():
        outcome = row['outcome']
        n_sig_pre = row['n_significant_pre']  # Corrected column name
        avg_pre_coef = row['avg_abs_pre_coef']

        if n_sig_pre == 0:
            status = "‚úÖ VALIDADO"
            concern = "low"
            text = f"Nenhum coeficiente pr√©-tratamento significativo. Tend√™ncias paralelas suportadas."
        elif n_sig_pre <= 1:
            status = "‚ö†Ô∏è ATEN√á√ÉO"
            concern = "medium"
            text = f"{n_sig_pre} coeficiente(s) pr√©-tratamento significativo(s). Poss√≠vel viola√ß√£o marginal."
        else:
            status = "‚ùå VIOLADO"
            concern = "high"
            text = f"{n_sig_pre} coeficientes pr√©-tratamento significativos. Viola√ß√£o clara de tend√™ncias paralelas."

        assessments.append({
            'outcome': outcome,
            'status': status,
            'concern_level': concern,
            'text': text,
            'n_sig_pre': n_sig_pre,
            'avg_pre_coef': avg_pre_coef
        })

    return assessments


def assess_robustness_summary(rob_df, main_results):
    """
    Assesses overall robustness based on multiple tests.

    Parameters:
    -----------
    rob_df : DataFrame
        Robustness summary results
    main_results : DataFrame
        Main DiD results for comparison

    Returns:
    --------
    dict: Assessment by outcome
    """
    outcomes = rob_df['outcome'].unique()
    assessments = {}

    for outcome in outcomes:
        df_outcome = rob_df[rob_df['outcome'] == outcome].copy()

        # Get main coefficient
        main_row = main_results[main_results['outcome'] == outcome]
        if main_row.empty:
            continue
        main_coef = main_row['coef'].values[0]

        # Check placebo test
        placebo = df_outcome[df_outcome['test_type'] == 'Placebo']
        placebo_pass = True
        placebo_text = ""
        if not placebo.empty:
            placebo_p = placebo['p_value'].values[0]
            if placebo_p < 0.10:
                placebo_pass = False
                placebo_text = f"‚ùå Placebo test FAILED (p={placebo_p:.3f}). "
            else:
                placebo_text = f"‚úÖ Placebo test passed (p={placebo_p:.3f}). "

        # Check differential trends
        trends = df_outcome[df_outcome['test_type'] == 'Differential Trends']
        trends_ok = True
        trends_text = ""
        if not trends.empty:
            trends_p = trends['p_value'].values[0]
            if trends_p < 0.10:
                trends_ok = False
                trends_text = f"‚ùå Differential pre-trends DETECTED (p={trends_p:.3f}). "
            else:
                trends_text = f"‚úÖ No differential pre-trends (p={trends_p:.3f}). "

        # Check alternative cutoffs
        cutoffs = df_outcome[df_outcome['test_type'] == 'Alternative Cutoff']
        cutoffs_text = ""
        if not cutoffs.empty:
            cutoff_coefs = cutoffs['coef'].values
            coef_range = cutoff_coefs.max() - cutoff_coefs.min()
            sign_consistent = (cutoff_coefs >= 0).all() or (cutoff_coefs <= 0).all()

            if sign_consistent and abs(coef_range / abs(main_coef)) < 2.0:
                cutoffs_text = f"‚úÖ Results stable across cutoffs (range: {coef_range:.4f}). "
            else:
                cutoffs_text = f"‚ö†Ô∏è Some variation across cutoffs (range: {coef_range:.4f}). "

        # Overall assessment
        if placebo_pass and trends_ok:
            overall = "ROBUST"
            icon = "‚úÖ"
        elif placebo_pass or trends_ok:
            overall = "MODERATE CONCERNS"
            icon = "‚ö†Ô∏è"
        else:
            overall = "SERIOUS CONCERNS"
            icon = "‚ùå"

        assessments[outcome] = {
            'overall': overall,
            'icon': icon,
            'placebo_pass': placebo_pass,
            'trends_ok': trends_ok,
            'placebo_text': placebo_text,
            'trends_text': trends_text,
            'cutoffs_text': cutoffs_text
        }

    return assessments


def flag_heterogeneity_findings(het_df):
    """
    Identifies significant heterogeneity findings.

    Parameters:
    -----------
    het_df : DataFrame
        Heterogeneity results (all triple-DiD)

    Returns:
    --------
    list: List of significant findings with interpretations
    """
    findings = []

    for _, row in het_df.iterrows():
        outcome = row['outcome']
        group = row['group_label']
        interaction_pval = row['pval_interaction']

        # Check if interaction is significant
        if interaction_pval < 0.10:
            coef_interaction = row['coef_interaction']
            coef_total = row['coef_total']
            stars_interaction = row['stars_interaction']

            # Determine direction
            if coef_interaction > 0:
                direction = "maior"
                comparison = "mais positivo" if coef_total > 0 else "menos negativo"
            else:
                direction = "menor"
                comparison = "mais negativo" if coef_total < 0 else "menos positivo"

            # Significance level
            if interaction_pval < 0.01:
                sig_text = "forte (p<0.01)"
            elif interaction_pval < 0.05:
                sig_text = "moderada (p<0.05)"
            else:
                sig_text = "fraca (p<0.10)"

            finding = {
                'outcome': outcome,
                'group': group,
                'interaction_coef': coef_interaction,
                'total_coef': coef_total,
                'p_value': interaction_pval,
                'stars': stars_interaction,
                'direction': direction,
                'comparison': comparison,
                'sig_text': sig_text,
                'text': f"**{group}** apresenta efeito {comparison} ({coef_interaction:+.4f}{stars_interaction}), "
                        f"com signific√¢ncia {sig_text}. Efeito total para este grupo: {coef_total:.4f}."
            }

            findings.append(finding)

    return findings


# ============================================
# REPORT GENERATION FUNCTIONS
# ============================================

def generate_executive_summary(all_results):
    """
    Generates executive summary markdown.

    Parameters:
    -----------
    all_results : dict
        Dictionary with all loaded results

    Returns:
    --------
    str: Markdown text
    """
    md = "# Sum√°rio Executivo: An√°lise DiD - Impacto da IA Generativa no Brasil\n\n"
    md += f"**Data**: {datetime.now().strftime('%d de %B de %Y')}\n\n"
    md += "---\n\n"

    # Add interpretive guidance box
    md += "## üìä Como Interpretar os Resultados\n\n"
    md += "> **IMPORTANTE**: Efeito m√©dio n√£o significativo ‚â† Aus√™ncia de efeitos\n>\n"
    md += "> Quando o efeito m√©dio geral n√£o √© estatisticamente significativo, mas h√° **efeitos heterog√™neos significativos**, "
    md += "isso indica que a IA est√° impactando diferentes grupos de formas **opostas** que se **cancelam** na m√©dia. "
    md += "Este padr√£o sugere que a tecnologia tem efeitos **diferenciados** por grupo demogr√°fico, "
    md += "mesmo que a m√©dia agregada seja pr√≥xima de zero.\n\n"
    md += "---\n\n"

    # Heterogeneity FIRST (main finding)
    md += "## üéØ Achado Principal: Efeitos Heterog√™neos\n\n"

    het_findings = all_results.get('heterogeneity_findings', [])
    if het_findings:
        md += f"Encontramos **{len(het_findings)} efeito(s) heterog√™neo(s) significativo(s)**:\n\n"
        for finding in het_findings:
            md += f"- **{finding['group']}** ({finding['outcome']}): {finding['text']}\n"
        md += "\n**Interpreta√ß√£o**: A IA Generativa tem impactos **diferenciados** por grupo demogr√°fico. "
        md += "Efeitos opostos (positivos para alguns grupos, negativos para outros) se cancelam na m√©dia agregada, "
        md += "mas s√£o reais e estatisticamente significativos para subgrupos espec√≠ficos.\n\n"
    else:
        md += "N√£o foram encontrados efeitos heterog√™neos estatisticamente significativos.\n\n"

    # Main findings (average effects) - now SECOND
    md += "## üìà Efeitos M√©dios (Agregados)\n\n"

    main_results = all_results['main_results']
    main_spec = main_results[main_results['model'].str.contains('Model 3', na=False)]

    for outcome in ['ln_renda', 'horas_trabalhadas']:
        row = main_spec[main_spec['outcome'] == outcome]
        if not row.empty:
            coef = row['coef'].values[0]
            se = row['se'].values[0]
            p_val = row['p_value'].values[0]

            outcome_label = "Rendimento" if outcome == 'ln_renda' else "Horas Trabalhadas"
            md += f"### {outcome_label}\n\n"

            interpretation = interpret_did_coefficient(coef, se, p_val, outcome)
            md += interpretation + "\n\n"

    # Robustness
    md += "## üî¨ Robustez\n\n"

    rob_assessments = all_results.get('robustness_assessment', {})
    for outcome, assessment in rob_assessments.items():
        outcome_label = "Rendimento" if outcome == 'ln_renda' else "Horas Trabalhadas"
        md += f"**{outcome_label}**: {assessment['icon']} {assessment['overall']}\n\n"
        md += assessment['placebo_text'] + assessment['trends_text'] + "\n\n"

    md += "---\n\n"
    md += "*Relat√≥rio gerado automaticamente pelo Script 14: Generate Report*\n"

    return md


def generate_full_report(all_results):
    """
    Generates comprehensive markdown report.

    Parameters:
    -----------
    all_results : dict
        Dictionary with all loaded results

    Returns:
    --------
    str: Markdown text
    """
    md = "# Relat√≥rio Completo: An√°lise Difference-in-Differences\n"
    md += "# Impacto da IA Generativa no Mercado de Trabalho Brasileiro\n\n"
    md += f"**Data de Gera√ß√£o**: {datetime.now().strftime('%d de %B de %Y, %H:%M:%S')}\n\n"
    md += "---\n\n"

    # Table of Contents
    md += "## √çndice\n\n"
    md += "1. [Vis√£o Geral](#vis√£o-geral)\n"
    md += "2. [Descri√ß√£o da Amostra](#descri√ß√£o-da-amostra)\n"
    md += "3. [Valida√ß√£o do Desenho DiD](#valida√ß√£o-do-desenho-did)\n"
    md += "4. [Resultados Principais](#resultados-principais)\n"
    md += "5. [An√°lise de Heterogeneidade](#an√°lise-de-heterogeneidade)\n"
    md += "6. [Testes de Robustez](#testes-de-robustez)\n"
    md += "7. [Limita√ß√µes](#limita√ß√µes)\n"
    md += "8. [Conclus√µes](#conclus√µes)\n\n"
    md += "---\n\n"

    # ============================================
    # SECTION 1: OVERVIEW
    # ============================================

    md += "## 1. Vis√£o Geral\n\n"
    md += "### 1.1 Objetivo\n\n"
    md += "Esta an√°lise utiliza a metodologia **Difference-in-Differences (DiD)** para estimar o efeito causal "
    md += "do lan√ßamento do ChatGPT (novembro de 2022) sobre o mercado de trabalho brasileiro, usando varia√ß√£o "
    md += "na intensidade de exposi√ß√£o ocupacional √† IA Generativa.\n\n"

    md += "### 1.2 Dados\n\n"
    md += "- **Fonte**: PNAD Cont√≠nua (IBGE)\n"
    md += "- **Per√≠odo**: 2021T1 a 2024T4 (16 trimestres)\n"
    md += "- **√çndice de Exposi√ß√£o**: ILO GenAI Exposure Index (Gmyrek, Berg et al., 2025)\n"
    md += "- **Tratamento**: Ocupa√ß√µes no percentil 80+ de exposi√ß√£o √† IA\n\n"

    md += "### 1.3 Especifica√ß√£o Principal\n\n"
    md += "```\n"
    md += "Y_iot = Œ± + Œ≤(Post_t √ó AltaExp_o) + Œ∏X_it + Œ¥_o + Œº_t + Œµ_iot\n"
    md += "```\n\n"
    md += "Onde:\n"
    md += "- **Y_iot**: Outcome (ln_renda, horas_trabalhadas)\n"
    md += "- **Post_t**: Dummy p√≥s-ChatGPT (‚â•2023T1)\n"
    md += "- **AltaExp_o**: Dummy alta exposi√ß√£o (top 20%)\n"
    md += "- **X_it**: Controles individuais (idade, g√™nero, ra√ßa, educa√ß√£o)\n"
    md += "- **Œ¥_o**: Efeitos fixos de ocupa√ß√£o\n"
    md += "- **Œº_t**: Efeitos fixos de per√≠odo\n"
    md += "- **Œµ_iot**: Erro (clustered por ocupa√ß√£o)\n\n"

    # ============================================
    # SECTION 2: SAMPLE DESCRIPTION
    # ============================================

    md += "## 2. Descri√ß√£o da Amostra\n\n"

    main_results = all_results['main_results']
    main_spec = main_results[main_results['model'].str.contains('Model 3', na=False)]

    if not main_spec.empty:
        n_obs = int(main_spec['n_obs'].values[0])
        n_clusters = int(main_spec['n_clusters'].values[0])

        md += f"- **Observa√ß√µes**: {n_obs:,}\n"
        md += f"- **Ocupa√ß√µes (clusters)**: {n_clusters}\n"
        md += f"- **Per√≠odos**: 16 trimestres (8 pr√© + 8 p√≥s)\n\n"

    # Balance table if available
    if 'balance_table' in all_results and not all_results['balance_table'].empty:
        md += "### 2.1 Balan√ßo de Covari√°veis (Per√≠odo Pr√©-Tratamento)\n\n"
        md += "| Vari√°vel | Baixa Exposi√ß√£o | Alta Exposi√ß√£o | Diferen√ßa |\n"
        md += "|----------|----------------|----------------|------------|\n"

        balance_df = all_results['balance_table']
        for _, row in balance_df.iterrows():
            var = row.get('Variable', row.get('variable', ''))
            control = row.get('Control', row.get('control', '‚Äî'))
            treatment = row.get('Treatment', row.get('treatment', '‚Äî'))
            diff = row.get('Difference', row.get('difference', '‚Äî'))
            md += f"| {var} | {control} | {treatment} | {diff} |\n"

        md += "\n"

    # ============================================
    # SECTION 3: DESIGN VALIDATION
    # ============================================

    md += "## 3. Valida√ß√£o do Desenho DiD\n\n"
    md += "### 3.1 Hip√≥tese de Tend√™ncias Paralelas\n\n"

    pt_assessments = all_results.get('parallel_trends_assessment', [])

    if pt_assessments:
        md += "A validade do DiD depende da hip√≥tese de que, na aus√™ncia do tratamento, "
        md += "ocupa√ß√µes de alta e baixa exposi√ß√£o teriam evolu√≠do de forma paralela.\n\n"

        md += "**Resultados do Teste Formal**:\n\n"

        for assessment in pt_assessments:
            md += f"- **{assessment['outcome']}**: {assessment['status']} - {assessment['text']}\n"

        md += "\n"
    else:
        md += "Teste formal de tend√™ncias paralelas n√£o dispon√≠vel.\n\n"

    md += "### 3.2 Event Study\n\n"
    md += "Os gr√°ficos de event study mostram a evolu√ß√£o temporal do efeito DiD. "
    md += "Coeficientes pr√©-tratamento pr√≥ximos de zero validam a hip√≥tese de tend√™ncias paralelas.\n\n"
    md += "*Ver figuras: `event_study_ln_renda.png` e `event_study_horas_trabalhadas.png`*\n\n"

    # ============================================
    # SECTION 4: MAIN RESULTS
    # ============================================

    md += "## 4. Resultados Principais\n\n"
    md += "### 4.1 Estimativas DiD (Modelo 3 - Especifica√ß√£o Principal)\n\n"

    md += "| Outcome | Coeficiente | Erro Padr√£o | p-value | Stars | Interpreta√ß√£o |\n"
    md += "|---------|-------------|-------------|---------|-------|---------------|\n"

    for outcome in ['ln_renda', 'horas_trabalhadas']:
        row = main_spec[main_spec['outcome'] == outcome]
        if not row.empty:
            coef = row['coef'].values[0]
            se = row['se'].values[0]
            p_val = row['p_value'].values[0]
            stars = row['stars'].values[0] if pd.notna(row['stars'].values[0]) else ''

            outcome_label = "Log(Rendimento)" if outcome == 'ln_renda' else "Horas Trabalhadas"
            md += f"| {outcome_label} | {coef:.4f} | {se:.4f} | {p_val:.4f} | {stars} | "

            # Interpretation
            interpretation = interpret_did_coefficient(coef, se, p_val, outcome)
            # Shorten for table
            if p_val < 0.10:
                mag_text = interpret_coefficient_magnitude(coef, outcome)
                md += f"{mag_text} |"
            else:
                md += "N√£o significativo |"
            md += "\n"

    md += "\n"

    md += "### 4.2 Interpreta√ß√£o Detalhada\n\n"

    for outcome in ['ln_renda', 'horas_trabalhadas']:
        row = main_spec[main_spec['outcome'] == outcome]
        if not row.empty:
            coef = row['coef'].values[0]
            se = row['se'].values[0]
            p_val = row['p_value'].values[0]

            outcome_label = "Rendimento" if outcome == 'ln_renda' else "Horas Trabalhadas"
            md += f"#### {outcome_label}\n\n"

            interpretation = interpret_did_coefficient(coef, se, p_val, outcome)
            md += interpretation + "\n\n"

    # ============================================
    # SECTION 5: HETEROGENEITY
    # ============================================

    md += "## 5. An√°lise de Heterogeneidade\n\n"
    md += "### 5.1 Triple-DiD por Grupos Demogr√°ficos\n\n"

    md += "Investigamos se o efeito da IA varia por caracter√≠sticas demogr√°ficas usando Triple-DiD:\n\n"
    md += "```\n"
    md += "Y = Œ≤‚ÇÅ(Post√óAltaExp) + Œ≤‚ÇÇ(Post√óGrupo) + Œ≤‚ÇÉ(AltaExp√óGrupo)\n"
    md += "    + Œ≤‚ÇÑ(Post√óAltaExp√óGrupo) + controles + FEs\n"
    md += "```\n\n"

    het_findings = all_results.get('heterogeneity_findings', [])

    if het_findings:
        md += f"### 5.2 Achados Significativos ({len(het_findings)} encontrado(s))\n\n"

        for finding in het_findings:
            md += f"#### {finding['group']} - {finding['outcome']}\n\n"
            md += finding['text'] + "\n\n"
    else:
        md += "### 5.2 Achados\n\n"
        md += "N√£o foram detectados efeitos heterog√™neos estatisticamente significativos (p<0.10) "
        md += "para nenhum dos grupos demogr√°ficos analisados (idade, g√™nero, educa√ß√£o, ra√ßa).\n\n"

    # ============================================
    # SECTION 6: ROBUSTNESS
    # ============================================

    md += "## 6. Testes de Robustez\n\n"

    rob_assessments = all_results.get('robustness_assessment', {})

    for outcome, assessment in rob_assessments.items():
        outcome_label = "Rendimento" if outcome == 'ln_renda' else "Horas Trabalhadas"
        md += f"### 6.{list(rob_assessments.keys()).index(outcome) + 1} {outcome_label}\n\n"
        md += f"**Avalia√ß√£o Geral**: {assessment['icon']} **{assessment['overall']}**\n\n"

        md += "#### Testes Realizados:\n\n"
        md += f"1. **Placebo Temporal**: {assessment['placebo_text']}\n"
        md += f"2. **Tend√™ncias Diferenciais**: {assessment['trends_text']}\n"
        md += f"3. **Defini√ß√µes Alternativas de Tratamento**: {assessment['cutoffs_text']}\n\n"

    # ============================================
    # SECTION 7: LIMITATIONS
    # ============================================

    md += "## 7. Limita√ß√µes\n\n"
    md += "### 7.1 Limita√ß√µes da Estrat√©gia de Identifica√ß√£o\n\n"
    md += "- **Tend√™ncias Paralelas**: N√£o test√°vel definitivamente; dependemos de valida√ß√£o indireta.\n"
    md += "- **Choques Correlacionados**: Outros eventos podem confundir a estimativa (juros, infla√ß√£o).\n"
    md += "- **SUTVA**: Spillovers entre ocupa√ß√µes n√£o s√£o captados.\n\n"

    md += "### 7.2 Limita√ß√µes dos Dados\n\n"
    md += "- **Frequ√™ncia**: Dados trimestrais (menos precis√£o temporal que dados mensais).\n"
    md += "- **Amostra**: Survey (auto-declara√ß√£o, poss√≠vel erro de medida).\n"
    md += "- **Painel**: N√£o acompanhamos mesmas pessoas (n√£o vemos transi√ß√µes individuais).\n\n"

    md += "### 7.3 Limita√ß√µes de Interpreta√ß√£o\n\n"
    md += "- **Exposi√ß√£o ‚â† Ado√ß√£o**: Alto √≠ndice n√£o garante que empresas adotaram IA.\n"
    md += "- **Timing**: Efeitos podem ser defasados.\n"
    md += "- **Externalidade**: Resultados s√£o para o Brasil (podem n√£o generalizar).\n\n"

    # ============================================
    # SECTION 8: CONCLUSIONS
    # ============================================

    md += "## 8. Conclus√µes\n\n"

    md += "### 8.1 S√≠ntese dos Resultados\n\n"

    # Heterogeneity FIRST (main conclusion)
    if het_findings:
        md += "**Achado Principal**: Foram identificados **" + f"{len(het_findings)} efeito(s) heterog√™neo(s) significativo(s)**, "
        md += "indicando que a IA Generativa tem impactos **diferenciados** por caracter√≠sticas demogr√°ficas. "
        md += "Especificamente:\n\n"

        for finding in het_findings:
            group_label = finding['group']
            outcome_label = "rendimento" if finding['outcome'] == 'ln_renda' else "horas trabalhadas"
            direction = "redu√ß√£o" if finding['direction'] == 'negative' else "aumento"
            md += f"- **{group_label}**: {direction} de {outcome_label} (p<0.05)\n"

        md += "\n"

    # Average effects (contextualized by heterogeneity)
    main_findings_summary = []
    for outcome in ['ln_renda', 'horas_trabalhadas']:
        row = main_spec[main_spec['outcome'] == outcome]
        if not row.empty:
            p_val = row['p_value'].values[0]
            outcome_label = "rendimento" if outcome == 'ln_renda' else "horas trabalhadas"

            if p_val < 0.10:
                main_findings_summary.append(f"efeito m√©dio significativo sobre {outcome_label}")
            else:
                main_findings_summary.append(f"efeito m√©dio n√£o significativo sobre {outcome_label}")

    if main_findings_summary:
        md += "**Efeitos M√©dios Agregados**: Esta an√°lise DiD encontrou " + " e ".join(main_findings_summary) + " "
        md += "para trabalhadores em ocupa√ß√µes de alta exposi√ß√£o √† IA Generativa, "
        md += "ap√≥s o lan√ßamento do ChatGPT em novembro de 2022. "

        # Add interpretation about heterogeneity canceling out average effects
        if het_findings:
            md += "A aus√™ncia de efeito m√©dio significativo **n√£o implica aus√™ncia de impactos**: "
            md += "os efeitos heterog√™neos documentados acima (positivos para alguns grupos, negativos para outros) "
            md += "**se cancelam na m√©dia agregada**, mas s√£o reais e estatisticamente significativos para subgrupos espec√≠ficos.\n\n"
        else:
            md += "\n\n"

    # Robustness conclusion
    robust_outcomes = [o for o, a in rob_assessments.items() if a['overall'] == 'ROBUST']
    if robust_outcomes:
        robust_labels = ["rendimento" if o == 'ln_renda' else "horas trabalhadas" for o in robust_outcomes]
        md += "**Robustez**: Os resultados para " + " e ".join(robust_labels) + " "
        md += "demonstraram robustez a m√∫ltiplos testes (placebo, tend√™ncias diferenciais, cutoffs alternativos), "
        md += "aumentando a confian√ßa nas estimativas de heterogeneidade.\n\n"

    md += "### 8.2 Implica√ß√µes\n\n"

    # Add specific implications based on heterogeneity findings
    if het_findings:
        md += "Os efeitos heterog√™neos identificados t√™m implica√ß√µes importantes para pol√≠ticas p√∫blicas:\n\n"
        md += "1. **Pol√≠ticas Diferenciadas**: O impacto desigual da IA entre grupos demogr√°ficos "
        md += "sugere a necessidade de pol√≠ticas de adapta√ß√£o tecnol√≥gica diferenciadas por grupo.\n"
        md += "2. **Monitoramento Cont√≠nuo**: √â crucial monitorar continuamente como diferentes segmentos "
        md += "da for√ßa de trabalho s√£o afetados pela IA, em vez de focar apenas em m√©dias agregadas.\n"
        md += "3. **Redistribui√ß√£o**: Grupos afetados negativamente podem requerer suporte (retreinamento, "
        md += "subs√≠dios) financiado pelos ganhos de grupos beneficiados.\n\n"

    md += "Estes resultados contribuem para a compreens√£o dos efeitos iniciais da IA Generativa "
    md += "sobre o mercado de trabalho em economias emergentes, fornecendo evid√™ncia emp√≠rica "
    md += "para formula√ß√£o de pol√≠ticas p√∫blicas e estrat√©gias de adapta√ß√£o tecnol√≥gica.\n\n"

    md += "---\n\n"
    md += f"*Relat√≥rio gerado automaticamente em {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*\n"
    md += "*Script 14: Generate Report*\n"

    return md


# ============================================
# MAIN EXECUTION
# ============================================

def main():
    """
    Main execution function.
    """
    logger.info("="*70)
    logger.info("SCRIPT 14: GENERATE MARKDOWN REPORT")
    logger.info("="*70)
    logger.info(f"Started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    # ============================================
    # LOAD ALL RESULTS
    # ============================================

    logger.info("\nLoading all results from previous scripts...")

    all_results = {}

    try:
        # Main DiD results (Script 09)
        main_path = OUTPUTS_TABLES / 'did_main_results.csv'
        all_results['main_results'] = pd.read_csv(main_path)
        logger.info(f"‚úì Loaded: {main_path.name}")

        # Parallel trends test (Script 10)
        pt_path = OUTPUTS_TABLES / 'parallel_trends_test_formal.csv'
        all_results['parallel_trends'] = pd.read_csv(pt_path)
        logger.info(f"‚úì Loaded: {pt_path.name}")

        # Heterogeneity (Script 11)
        het_path = OUTPUTS_TABLES / 'heterogeneity_all_triple_did.csv'
        all_results['heterogeneity'] = pd.read_csv(het_path)
        logger.info(f"‚úì Loaded: {het_path.name}")

        # Robustness (Script 12)
        rob_path = OUTPUTS_TABLES / 'robustness_summary.csv'
        all_results['robustness'] = pd.read_csv(rob_path)
        logger.info(f"‚úì Loaded: {rob_path.name}")

        # Balance table (optional, from Fase 3)
        try:
            bal_path = OUTPUTS_TABLES / 'balance_table_pre.csv'
            all_results['balance_table'] = pd.read_csv(bal_path)
            logger.info(f"‚úì Loaded: {bal_path.name}")
        except:
            logger.warning("‚ö†Ô∏è  Balance table not found (optional)")
            all_results['balance_table'] = pd.DataFrame()

    except Exception as e:
        logger.error(f"‚úó Failed to load required files: {e}")
        logger.error("  Make sure scripts 09-12 have been run successfully.")
        return

    # ============================================
    # GENERATE INTERPRETATIONS
    # ============================================

    logger.info("\nGenerating automatic interpretations...")

    # Parallel trends assessment
    pt_df = all_results['parallel_trends']
    all_results['parallel_trends_assessment'] = assess_parallel_trends(pt_df)
    logger.info(f"‚úì Assessed parallel trends for {len(all_results['parallel_trends_assessment'])} outcome(s)")

    # Robustness assessment
    main_results = all_results['main_results']
    main_spec = main_results[main_results['model'].str.contains('Model 3', na=False)]
    rob_df = all_results['robustness']
    all_results['robustness_assessment'] = assess_robustness_summary(rob_df, main_spec)
    logger.info(f"‚úì Assessed robustness for {len(all_results['robustness_assessment'])} outcome(s)")

    # Heterogeneity findings
    het_df = all_results['heterogeneity']
    all_results['heterogeneity_findings'] = flag_heterogeneity_findings(het_df)
    logger.info(f"‚úì Identified {len(all_results['heterogeneity_findings'])} significant heterogeneity finding(s)")

    # ============================================
    # GENERATE REPORTS
    # ============================================

    logger.info("\n" + "="*70)
    logger.info("GENERATING MARKDOWN REPORTS")
    logger.info("="*70)

    # Executive Summary
    logger.info("\nGenerating executive summary...")
    exec_summary = generate_executive_summary(all_results)
    exec_path = OUTPUTS_DIR / 'DID_EXECUTIVE_SUMMARY.md'
    with open(exec_path, 'w', encoding='utf-8') as f:
        f.write(exec_summary)
    logger.info(f"‚úì Executive summary saved: {exec_path.name}")

    # Full Report
    logger.info("\nGenerating comprehensive report...")
    full_report = generate_full_report(all_results)
    report_path = OUTPUTS_DIR / 'DID_ANALYSIS_REPORT.md'
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(full_report)
    logger.info(f"‚úì Comprehensive report saved: {report_path.name}")

    # ============================================
    # SUMMARY
    # ============================================

    logger.info("\n" + "="*70)
    logger.info("REPORT GENERATION COMPLETE")
    logger.info("="*70)

    logger.info("\nReports generated:")
    logger.info(f"  ‚úì Executive Summary: {exec_path.name}")
    logger.info(f"  ‚úì Comprehensive Report: {report_path.name}")

    # Summary statistics
    exec_lines = len(exec_summary.split('\n'))
    report_lines = len(full_report.split('\n'))
    logger.info(f"\nReport statistics:")
    logger.info(f"  - Executive Summary: {exec_lines} lines")
    logger.info(f"  - Comprehensive Report: {report_lines} lines")

    # Key findings summary
    logger.info(f"\nKey findings flagged:")
    logger.info(f"  - Parallel trends assessments: {len(all_results['parallel_trends_assessment'])}")
    logger.info(f"  - Robustness assessments: {len(all_results['robustness_assessment'])}")
    logger.info(f"  - Significant heterogeneity: {len(all_results['heterogeneity_findings'])}")

    logger.info(f"\nüìÅ Reports saved to: {OUTPUTS_DIR}")
    logger.info(f"üìÑ Log saved to: {log_file}")

    logger.info(f"\n‚úì Script completed: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")


if __name__ == '__main__':
    main()
